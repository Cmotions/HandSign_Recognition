{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The program applies Transfer Learning to this existing model and re-trains it to classify a new set of images.\n",
    "\n",
    "This example shows how to take a Inception v3 architecture model trained on ImageNet images,\n",
    "and train a new top layer that can recognize other classes of images.\n",
    "\n",
    "You can replace the image_dir argument with any folder containing subfolders of\n",
    "images. The label for each image is taken from the name of the subfolder it's in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import struct\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the directory where the images are saved you want to use to train the model\n",
    "default_image_dir = 'C:/GitHub/HandSign_Recognition/00 Data/generated'\n",
    "\n",
    "# make sure the FLAGS variable exists, it will get a value later in the script\n",
    "FLAGS = None\n",
    "\n",
    "# These are all parameters that are tied to the particular model architecture\n",
    "# we're using for Inception v3. These include things like tensor names and their\n",
    "# sizes. If you want to adapt this script to work with another model, you will\n",
    "# need to update these to reflect the values in the network you're using.\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "MODEL_INPUT_WIDTH = 64 #299\n",
    "MODEL_INPUT_HEIGHT = 64 #299\n",
    "MODEL_INPUT_DEPTH = 3\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Builds a list of training images from the file system.\n",
    "        Analyzes the sub folders in the image directory, splits them into stable\n",
    "        training, testing, and validation sets, and returns a data structure\n",
    "        describing the lists of images for each label and their paths.\n",
    "    Args:\n",
    "        image_dir: String path to a folder containing subfolders of images.\n",
    "        testing_percentage: Integer percentage of the images to reserve for tests.\n",
    "        validation_percentage: Integer percentage of images reserved for validation.\n",
    "    Returns:\n",
    "        A dictionary containing an entry for each label subfolder, with images split\n",
    "        into training, testing, and validation sets within each label.\n",
    "    \"\"\"\n",
    "    if not gfile.Exists(image_dir):\n",
    "        print(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "        return None\n",
    "    result = {}\n",
    "    sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n",
    "    # The root directory comes first, so skip it.\n",
    "    is_root_dir = True\n",
    "    for sub_dir in sub_dirs:\n",
    "        if is_root_dir:\n",
    "            is_root_dir = False\n",
    "            continue\n",
    "        extensions = ['jpg', 'jpeg', 'JPG', 'JPEG' 'png', 'PNG']\n",
    "        file_list = []\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        if dir_name == image_dir:\n",
    "            continue\n",
    "        print(\"\\nLooking for images in '\" + dir_name + \"'\")\n",
    "        for extension in extensions:\n",
    "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "            file_list.extend(gfile.Glob(file_glob))\n",
    "        if not file_list:\n",
    "            print('No files found')\n",
    "            continue\n",
    "        if len(file_list) < 20:\n",
    "            print('WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "            print('WARNING: Folder {} has more than {} images. Some images will '\n",
    "                  'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "        training_images = []\n",
    "        testing_images = []\n",
    "        validation_images = []\n",
    "        for file_name in file_list:\n",
    "            base_name = os.path.basename(file_name)\n",
    "            # We want to ignore anything after '_nohash_' in the file name when\n",
    "            # deciding which set to put an image in, the data set creator has a way of\n",
    "            # grouping photos that are close variations of each other. For example\n",
    "            # this is used in the plant disease data set to group multiple pictures of\n",
    "            # the same leaf.\n",
    "            hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "            # This looks a bit magical, but we need to decide whether this file should\n",
    "            # go into the training, testing, or validation sets, and we want to keep\n",
    "            # existing files in the same set even if more files are subsequently\n",
    "            # added.\n",
    "            # To do that, we need a stable way of deciding based on just the file name\n",
    "            # itself, so we do a hash of that and then use that to generate a\n",
    "            # probability value that we use to assign it.\n",
    "            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "            percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                                (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n",
    "                             (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "            if percentage_hash < validation_percentage:\n",
    "                #print(str(round(percentage_hash, 2)) + \" --> added to validation\")\n",
    "                validation_images.append(base_name)\n",
    "            elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "                #print(str(round(percentage_hash, 2)) + \" --> added to testing\")\n",
    "                testing_images.append(base_name)\n",
    "            else:\n",
    "                #print(str(round(percentage_hash, 2)) + \" --> added to training\")\n",
    "                training_images.append(base_name)\n",
    "        result[label_name] = {\n",
    "            'dir': dir_name,\n",
    "            'training': training_images,\n",
    "            'testing': testing_images,\n",
    "            'validation': validation_images,\n",
    "            }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "    \"\"\"\"\n",
    "    Brief:\n",
    "        Returns a path to an image for a label at the given index.\n",
    "    Args:\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        label_name: Label string we want to get an image for.\n",
    "        index: Int offset of the image we want. This will be moduloed by the\n",
    "        available number of images for the label, so it can be arbitrarily large.\n",
    "        image_dir: Root folder string of the subfolders containing the training images.\n",
    "        category: Name string of set to pull images from - training, testing, or validation.\n",
    "    Returns:\n",
    "        File system path string to an image that meets the requested parameters.\n",
    "    \"\"\"\n",
    "    if label_name not in image_lists:\n",
    "        tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "    label_lists = image_lists[label_name]\n",
    "    if category not in label_lists:\n",
    "        tf.logging.fatal('Category does not exist %s.', category)\n",
    "    category_list = label_lists[category]\n",
    "    if not category_list:\n",
    "        tf.logging.fatal('Label %s has no images in the category %s.', label_name, category)\n",
    "    mod_index = index % len(category_list)\n",
    "    base_name = category_list[mod_index]\n",
    "    sub_dir = label_lists['dir']\n",
    "    full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "    #print(full_path)\n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category):\n",
    "    \"\"\"\"\n",
    "    Brief:\n",
    "        Returns a path to a bottleneck file for a label at the given index.\n",
    "    Args:\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        label_name: Label string we want to get an image for.\n",
    "        index: Integer offset of the image we want. This will be moduloed by the\n",
    "                available number of images for the label, so it can be arbitrarily large.\n",
    "        bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "        category: Name string of set to pull images from - training, testing, or validation.\n",
    "    Returns:\n",
    "        File system path string to an image that meets the requested parameters.\n",
    "    \"\"\"\n",
    "    return get_image_path(image_lists, label_name, index, bottleneck_dir,\n",
    "                        category) + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_inception_graph():\n",
    "    \"\"\"\"\n",
    "    Brief:\n",
    "        Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "    Returns:\n",
    "        Graph holding the trained Inception network, and various tensors we'll be\n",
    "        manipulating.\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_filename = os.path.join(FLAGS.model_dir, 'classify_image_graph_def.pb')\n",
    "        with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "                tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "                    BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n",
    "                    RESIZED_INPUT_TENSOR_NAME]))\n",
    "    return graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor, bottleneck_tensor):\n",
    "    \"\"\"\"\n",
    "    Brief:\n",
    "        Runs inference on an image to extract the 'bottleneck' summary layer.\n",
    "    Args:\n",
    "        sess: Current active TensorFlow Session.\n",
    "        image_data: String of raw JPEG data.\n",
    "        image_data_tensor: Input data layer in the graph.\n",
    "        bottleneck_tensor: Layer before the final softmax.\n",
    "    Returns:\n",
    "        Numpy array of bottleneck values.\n",
    "    \"\"\"\n",
    "    bottleneck_values = sess.run(\n",
    "        bottleneck_tensor,\n",
    "        {image_data_tensor: image_data})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Download and extract model tar file.\n",
    "        If the pretrained model we're using doesn't already exist, this function\n",
    "        downloads it from the TensorFlow.org website and unpacks it into a directory.\n",
    "    \"\"\"\n",
    "    dest_directory = FLAGS.model_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                       (filename,\n",
    "                        float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir_exists(dir_name):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Makes sure the folder exists on disk.\n",
    "    Args:\n",
    "        dir_name: Path string to the folder we want to create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_list_of_floats_to_file(list_of_floats, file_path):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Writes a given list of floats to a binary file.\n",
    "    Args:\n",
    "        list_of_floats: List of floats we want to write to a file.\n",
    "        file_path: Path to a file where list of floats will be stored.\n",
    "    \"\"\"\n",
    "    s = struct.pack('d' * BOTTLENECK_TENSOR_SIZE, *list_of_floats)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_list_of_floats_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Reads list of floats from a given file.\n",
    "    Args:\n",
    "        file_path: Path to a file where list of floats was stored.\n",
    "    Returns:\n",
    "        Array of bottleneck values (list of floats).\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        s = struct.unpack('d' * BOTTLENECK_TENSOR_SIZE, f.read())\n",
    "        return list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_path_2_bottleneck_values = {}\n",
    "\n",
    "\n",
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           bottleneck_tensor):\n",
    "    \"\"\"Create a single bottleneck file.\"\"\"\n",
    "    #print('Creating bottleneck at ' + bottleneck_path)\n",
    "    image_path = get_image_path(image_lists, label_name, index,\n",
    "                              image_dir, category)\n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fatal('File does not exist %s', image_path)\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    try:\n",
    "        bottleneck_values = run_bottleneck_on_image(\n",
    "            sess, image_data, jpeg_data_tensor, bottleneck_tensor)\n",
    "    except:\n",
    "        raise RuntimeError('Error during processing file %s' % image_path)\n",
    "\n",
    "    bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "    with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "        bottleneck_file.write(bottleneck_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\n",
    "                             category, bottleneck_dir, jpeg_data_tensor,\n",
    "                             bottleneck_tensor):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Retrieves or calculates bottleneck values for an image.\n",
    "\n",
    "      If a cached version of the bottleneck data exists on-disk, return that,\n",
    "      otherwise calculate the data and save it to disk for future use.\n",
    "    Args:\n",
    "        sess: The current active TensorFlow Session.\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        label_name: Label string we want to get an image for.\n",
    "        index: Integer offset of the image we want. This will be modulo-ed by the\n",
    "        available number of images for the label, so it can be arbitrarily large.\n",
    "        image_dir: Root folder string  of the subfolders containing the training\n",
    "        images.\n",
    "        category: Name string of which  set to pull images from - training, testing,\n",
    "        or validation.\n",
    "        bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "        jpeg_data_tensor: The tensor to feed loaded jpeg data into.\n",
    "        bottleneck_tensor: The output tensor for the bottleneck values.\n",
    "    Returns:\n",
    "        Numpy array of values produced by the bottleneck layer for the image.\n",
    "    \"\"\"\n",
    "    label_lists = image_lists[label_name]\n",
    "    sub_dir = label_lists['dir']\n",
    "    sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "    ensure_dir_exists(sub_dir_path)\n",
    "    bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n",
    "                                        bottleneck_dir, category)\n",
    "    if not os.path.exists(bottleneck_path):\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           bottleneck_tensor)\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "        bottleneck_string = bottleneck_file.read()\n",
    "    did_hit_error = False\n",
    "    try:\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    except ValueError:\n",
    "        print('Invalid float found, recreating bottleneck')\n",
    "        did_hit_error = True\n",
    "    if did_hit_error:\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           bottleneck_tensor)\n",
    "        with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "            bottleneck_string = bottleneck_file.read()\n",
    "        # Allow exceptions to propagate here, since they shouldn't happen after a\n",
    "        # fresh creation\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n",
    "                      jpeg_data_tensor, bottleneck_tensor):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Ensures all the training, testing, and validation bottlenecks are cached.\n",
    "\n",
    "        Because we're likely to read the same image multiple times (if there are no\n",
    "        distortions applied during training) it can speed things up a lot if we\n",
    "        calculate the bottleneck layer values once for each image during\n",
    "        preprocessing, and then just read those cached values repeatedly during\n",
    "        training. Here we go through all the images we've found, calculate those\n",
    "        values, and save them off.\n",
    "    Args:\n",
    "        sess: The current active TensorFlow Session.\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        image_dir: Root folder string of the subfolders containing the training\n",
    "        images.\n",
    "        bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "        jpeg_data_tensor: Input tensor for jpeg data from file.\n",
    "        bottleneck_tensor: The penultimate output layer of the graph.\n",
    "    Returns:\n",
    "        Nothing.\n",
    "    \"\"\"\n",
    "    how_many_bottlenecks = 0\n",
    "    ensure_dir_exists(bottleneck_dir)\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(sess, image_lists, label_name, index,\n",
    "                                 image_dir, category, bottleneck_dir,\n",
    "                                 jpeg_data_tensor, bottleneck_tensor)\n",
    "\n",
    "                how_many_bottlenecks += 1\n",
    "                if how_many_bottlenecks % 100 == 0:\n",
    "                    print(str(how_many_bottlenecks) + ' bottleneck files created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category,\n",
    "                                  bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                                  bottleneck_tensor):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Retrieves bottleneck values for cached images.\n",
    "\n",
    "        If no distortions are being applied, this function can retrieve the cached\n",
    "        bottleneck values directly from disk for images. It picks a random set of\n",
    "        images from the specified category.\n",
    "    Args:\n",
    "        sess: Current TensorFlow Session.\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        how_many: If positive, a random sample of this size will be chosen.\n",
    "        If negative, all bottlenecks will be retrieved.\n",
    "        category: Name string of which set to pull from - training, testing, or\n",
    "        validation.\n",
    "        bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "        image_dir: Root folder string of the subfolders containing the training\n",
    "        images.\n",
    "        jpeg_data_tensor: The layer to feed jpeg image data into.\n",
    "        bottleneck_tensor: The bottleneck output layer of the CNN graph.\n",
    "    Returns:\n",
    "        List of bottleneck arrays, their corresponding ground truths, and the\n",
    "        relevant filenames.\n",
    "    \"\"\"\n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    filenames = []\n",
    "    if how_many >= 0:\n",
    "        # Retrieve a random sample of bottlenecks.\n",
    "        for unused_i in range(how_many):\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = list(image_lists.keys())[label_index]\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "            image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                  image_dir, category)\n",
    "            bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n",
    "                                            image_index, image_dir, category,\n",
    "                                            bottleneck_dir, jpeg_data_tensor,\n",
    "                                            bottleneck_tensor)\n",
    "            ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "            ground_truth[label_index] = 1.0\n",
    "            bottlenecks.append(bottleneck)\n",
    "            ground_truths.append(ground_truth)\n",
    "            filenames.append(image_name)\n",
    "    else:\n",
    "        # Retrieve all bottlenecks.\n",
    "        for label_index, label_name in enumerate(image_lists.keys()):\n",
    "            for image_index, image_name in enumerate(\n",
    "                image_lists[label_name][category]):\n",
    "                image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                    image_dir, category)\n",
    "                bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n",
    "                                              image_index, image_dir, category,\n",
    "                                              bottleneck_dir, jpeg_data_tensor,\n",
    "                                              bottleneck_tensor)\n",
    "                ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "                ground_truth[label_index] = 1.0\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(ground_truth)\n",
    "                filenames.append(image_name)\n",
    "    return bottlenecks, ground_truths, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_distorted_bottlenecks(\n",
    "    sess, image_lists, how_many, category, image_dir, input_jpeg_tensor,\n",
    "    distorted_image, resized_input_tensor, bottleneck_tensor):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Retrieves bottleneck values for training images, after distortions.\n",
    "\n",
    "        If we're training with distortions like crops, scales, or flips, we have to\n",
    "        recalculate the full model for every image, and so we can't use cached\n",
    "        bottleneck values. Instead we find random images for the requested category,\n",
    "        run them through the distortion graph, and then the full graph to get the\n",
    "        bottleneck results for each.\n",
    "    Args:\n",
    "        sess: Current TensorFlow Session.\n",
    "        image_lists: Dictionary of training images for each label.\n",
    "        how_many: The integer number of bottleneck values to return.\n",
    "        category: Name string of which set of images to fetch - training, testing,\n",
    "        or validation.\n",
    "        image_dir: Root folder string of the subfolders containing the training\n",
    "        images.\n",
    "        input_jpeg_tensor: The input layer we feed the image data to.\n",
    "        distorted_image: The output node of the distortion graph.\n",
    "        resized_input_tensor: The input node of the recognition graph.\n",
    "        bottleneck_tensor: The bottleneck output layer of the CNN graph.\n",
    "    Returns:\n",
    "        List of bottleneck arrays and their corresponding ground truths.\n",
    "    \"\"\"\n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    for unused_i in range(how_many):\n",
    "        label_index = random.randrange(class_count)\n",
    "        label_name = list(image_lists.keys())[label_index]\n",
    "        image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "        image_path = get_image_path(image_lists, label_name, image_index, image_dir,\n",
    "                                category)\n",
    "        if not gfile.Exists(image_path):\n",
    "            tf.logging.fatal('File does not exist %s', image_path)\n",
    "        jpeg_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "        # Note that we materialize the distorted_image_data as a numpy array before\n",
    "        # sending running inference on the image. This involves 2 memory copies and\n",
    "        # might be optimized in other implementations.\n",
    "        distorted_image_data = sess.run(distorted_image,\n",
    "                                    {input_jpeg_tensor: jpeg_data})\n",
    "        bottleneck = run_bottleneck_on_image(sess, distorted_image_data,\n",
    "                                         resized_input_tensor,\n",
    "                                         bottleneck_tensor)\n",
    "        ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "        ground_truth[label_index] = 1.0\n",
    "        bottlenecks.append(bottleneck)\n",
    "        ground_truths.append(ground_truth)\n",
    "    return bottlenecks, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def should_distort_images(flip_left_right, random_crop, random_scale,\n",
    "                          random_brightness):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Whether any distortions are enabled, from the input flags.\n",
    "    Args:\n",
    "        flip_left_right: Boolean whether to randomly mirror images horizontally.\n",
    "        random_crop: Integer percentage setting the total margin used around the\n",
    "        crop box.\n",
    "        random_scale: Integer percentage of how much to vary the scale by.\n",
    "        random_brightness: Integer range to randomly multiply the pixel values by.\n",
    "    Returns:\n",
    "        Boolean value indicating whether any distortions should be applied.\n",
    "    \"\"\"\n",
    "    return (flip_left_right or (random_crop != 0) or (random_scale != 0) or\n",
    "          (random_brightness != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_input_distortions(flip_left_right, random_crop, random_scale,\n",
    "                          random_brightness):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Creates the operations to apply the specified distortions.\n",
    "\n",
    "        During training it can help to improve the results if we run the images\n",
    "        through simple distortions like crops, scales, and flips. These reflect the\n",
    "        kind of variations we expect in the real world, and so can help train the\n",
    "        model to cope with natural data more effectively. Here we take the supplied\n",
    "        parameters and construct a network of operations to apply them to an image.\n",
    "\n",
    "      Cropping\n",
    "\n",
    "      Cropping is done by placing a bounding box at a random position in the full\n",
    "      image. The cropping parameter controls the size of that box relative to the\n",
    "      input image. If it's zero, then the box is the same size as the input and no\n",
    "      cropping is performed. If the value is 50%, then the crop box will be half the\n",
    "      width and height of the input. In a diagram it looks like this:\n",
    "\n",
    "        <       width         >\n",
    "        +---------------------+\n",
    "        |                     |\n",
    "        |   width - crop%     |\n",
    "        |    <      >         |\n",
    "        |    +------+         |\n",
    "        |    |      |         |\n",
    "        |    |      |         |\n",
    "        |    |      |         |\n",
    "        |    +------+         |\n",
    "        |                     |\n",
    "        |                     |\n",
    "        +---------------------+\n",
    "\n",
    "      Scaling\n",
    "\n",
    "      Scaling is a lot like cropping, except that the bounding box is always\n",
    "      centered and its size varies randomly within the given range. For example if\n",
    "      the scale percentage is zero, then the bounding box is the same size as the\n",
    "      input and no scaling is applied. If it's 50%, then the bounding box will be in\n",
    "      a random range between half the width and height and full size.\n",
    "    Args:\n",
    "        flip_left_right: Boolean whether to randomly mirror images horizontally.\n",
    "        random_crop: Integer percentage setting the total margin used around the\n",
    "        crop box.\n",
    "        random_scale: Integer percentage of how much to vary the scale by.\n",
    "        random_brightness: Integer range to randomly multiply the pixel values by.\n",
    "        graph.\n",
    "    Returns:\n",
    "        The jpeg input layer and the distorted result tensor.\n",
    "  \"\"\"\n",
    "\n",
    "    jpeg_data = tf.placeholder(tf.string, name='DistortJPGInput')\n",
    "    decoded_image = tf.image.decode_jpeg(jpeg_data, channels=MODEL_INPUT_DEPTH)\n",
    "    decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "    decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "    margin_scale = 1.0 + (random_crop / 100.0)\n",
    "    resize_scale = 1.0 + (random_scale / 100.0)\n",
    "    margin_scale_value = tf.constant(margin_scale)\n",
    "    resize_scale_value = tf.random_uniform(tensor_shape.scalar(),\n",
    "                                         minval=1.0,\n",
    "                                         maxval=resize_scale)\n",
    "    scale_value = tf.multiply(margin_scale_value, resize_scale_value)\n",
    "    precrop_width = tf.multiply(scale_value, MODEL_INPUT_WIDTH)\n",
    "    precrop_height = tf.multiply(scale_value, MODEL_INPUT_HEIGHT)\n",
    "    precrop_shape = tf.stack([precrop_height, precrop_width])\n",
    "    precrop_shape_as_int = tf.cast(precrop_shape, dtype=tf.int32)\n",
    "    precropped_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                              precrop_shape_as_int)\n",
    "    precropped_image_3d = tf.squeeze(precropped_image, squeeze_dims=[0])\n",
    "    cropped_image = tf.random_crop(precropped_image_3d,\n",
    "                                 [MODEL_INPUT_HEIGHT, MODEL_INPUT_WIDTH,\n",
    "                                  MODEL_INPUT_DEPTH])\n",
    "    if flip_left_right:\n",
    "        flipped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        flipped_image = cropped_image\n",
    "    brightness_min = 1.0 - (random_brightness / 100.0)\n",
    "    brightness_max = 1.0 + (random_brightness / 100.0)\n",
    "    brightness_value = tf.random_uniform(tensor_shape.scalar(),\n",
    "                                       minval=brightness_min,\n",
    "                                       maxval=brightness_max)\n",
    "    brightened_image = tf.multiply(flipped_image, brightness_value)\n",
    "    distort_result = tf.expand_dims(brightened_image, 0, name='DistortResult')\n",
    "    return jpeg_data, distort_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Adds a new softmax and fully-connected layer for training.\n",
    "\n",
    "        We need to retrain the top layer to identify our new classes, so this function\n",
    "        adds the right operations to the graph, along with some variables to hold the\n",
    "        weights, and then sets up all the gradients for the backward pass.\n",
    "\n",
    "        The set up for the softmax and fully-connected layers is based on:\n",
    "        https://tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\n",
    "    Args:\n",
    "        class_count: Integer of how many categories of things we're trying to\n",
    "        recognize.\n",
    "        final_tensor_name: Name string for the new final node that produces results.\n",
    "        bottleneck_tensor: The output of the main CNN graph.\n",
    "    Returns:\n",
    "        The tensors for the training and cross entropy results, and tensors for the\n",
    "        bottleneck input and ground truth input.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(\n",
    "                bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],\n",
    "                name='BottleneckInputPlaceholder')\n",
    "\n",
    "        ground_truth_input = tf.placeholder(tf.float32,\n",
    "                                        [None, class_count],\n",
    "                                        name='GroundTruthInput')\n",
    "\n",
    "    # Organizing the following ops as `final_training_ops` so they're easier\n",
    "    # to see in TensorBoard\n",
    "    layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, class_count],\n",
    "                                          stddev=0.001)\n",
    "\n",
    "            layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "\n",
    "            variable_summaries(layer_weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "            variable_summaries(layer_biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "            tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "    tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=ground_truth_input, logits=logits)\n",
    "        with tf.name_scope('total'):\n",
    "            cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "\n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n",
    "              final_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "    \"\"\"\n",
    "    Brief:\n",
    "        Inserts the operations we need to evaluate the accuracy of our results.\n",
    "    Args:\n",
    "        result_tensor: The new final node that produces results.\n",
    "        ground_truth_tensor: The node we feed ground truth data\n",
    "        into.\n",
    "    Returns:\n",
    "        Tuple of (evaluation step, prediction).\n",
    "    \"\"\"\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(\n",
    "                    prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', evaluation_step)\n",
    "    return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    # Setup the directory we'll write summaries to for TensorBoard\n",
    "    if tf.gfile.Exists(FLAGS.summaries_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.summaries_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.summaries_dir)\n",
    "\n",
    "    # Set up the pre-trained graph.\n",
    "    maybe_download_and_extract()\n",
    "    graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (\n",
    "            create_inception_graph())\n",
    "\n",
    "    # Look at the folder structure, and create lists of all the images.\n",
    "    image_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,\n",
    "                                   FLAGS.validation_percentage)\n",
    "    class_count = len(image_lists.keys())\n",
    "    \n",
    "    if class_count == 0:\n",
    "        print('No valid folders of images found at ' + FLAGS.image_dir)\n",
    "        return -1\n",
    "    if class_count == 1:\n",
    "        print('Only one valid folder of images found at ' + FLAGS.image_dir +\n",
    "              ' - multiple classes are needed for classification.')\n",
    "        return -1\n",
    "\n",
    "    # See if the command-line flags mean we're applying any distortions.\n",
    "    do_distort_images = should_distort_images(\n",
    "            FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n",
    "            FLAGS.random_brightness)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "\n",
    "        if do_distort_images:\n",
    "            # We will be applying distortions, so setup the operations we'll need.\n",
    "            (distorted_jpeg_data_tensor,\n",
    "             distorted_image_tensor) = add_input_distortions(\n",
    "                     FLAGS.flip_left_right, FLAGS.random_crop,\n",
    "                     FLAGS.random_scale, FLAGS.random_brightness)\n",
    "        else:\n",
    "            # We'll make sure we've calculated the 'bottleneck' image summaries and\n",
    "            # cached them on disk.\n",
    "            cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\n",
    "                        FLAGS.bottleneck_dir, jpeg_data_tensor,\n",
    "                        bottleneck_tensor)\n",
    "\n",
    "        # Add the new layer that we'll be training.\n",
    "        (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n",
    "         final_tensor) = add_final_training_ops(len(image_lists.keys()),\n",
    "                                            FLAGS.final_tensor_name,\n",
    "                                            bottleneck_tensor)\n",
    "\n",
    "        # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "        evaluation_step, prediction = add_evaluation_step(\n",
    "                final_tensor, ground_truth_input)\n",
    "\n",
    "        # Merge all the summaries and write them out to the summaries_dir\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                         sess.graph)\n",
    "\n",
    "        validation_writer = tf.summary.FileWriter(\n",
    "                FLAGS.summaries_dir + '/validation')\n",
    "\n",
    "        # Set up all our weights to their initial default values.\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Run the training for as many cycles as requested on the command line.\n",
    "        for i in range(FLAGS.how_many_training_steps):\n",
    "            print(\"trainingstep = \", str(i))\n",
    "            # Get a batch of input bottleneck values, either calculated fresh every\n",
    "            # time with distortions applied, or from the cache stored on disk.\n",
    "            if do_distort_images:\n",
    "                (train_bottlenecks,\n",
    "                 train_ground_truth) = get_random_distorted_bottlenecks(\n",
    "                         sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "                         FLAGS.image_dir, distorted_jpeg_data_tensor,\n",
    "                         distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n",
    "            else:\n",
    "                (train_bottlenecks,\n",
    "                 train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "                         sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "                         FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "                         bottleneck_tensor)\n",
    "            # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "            # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "\n",
    "            train_summary, _ = sess.run(\n",
    "                    [merged, train_step],\n",
    "                    feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                               ground_truth_input: train_ground_truth})\n",
    "            train_writer.add_summary(train_summary, i)\n",
    "\n",
    "            # Every so often, print out how well the graph is training.\n",
    "            is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n",
    "            if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "                train_accuracy, cross_entropy_value = sess.run(\n",
    "                        [evaluation_step, cross_entropy],\n",
    "                        feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                                   ground_truth_input: train_ground_truth})\n",
    "                validation_bottlenecks, validation_ground_truth, _ = (\n",
    "                        get_random_cached_bottlenecks(\n",
    "                                sess, image_lists, FLAGS.validation_batch_size, 'validation',\n",
    "                                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "                                bottleneck_tensor))\n",
    "                # Run a validation step and capture training summaries for TensorBoard\n",
    "                # with the `merged` op.\n",
    "                validation_summary, validation_accuracy = sess.run(\n",
    "                        [merged, evaluation_step],\n",
    "                        feed_dict={bottleneck_input: validation_bottlenecks,\n",
    "                                   ground_truth_input: validation_ground_truth})\n",
    "                validation_writer.add_summary(validation_summary, i)\n",
    "                print('Step: %d, Train accuracy: %.4f%%, Cross entropy: %f, Validation accuracy: %.1f%% (N=%d)' % (i,\n",
    "                        train_accuracy * 100, cross_entropy_value, validation_accuracy * 100, len(validation_bottlenecks)))\n",
    "                print(str(time.ctime()))\n",
    "\n",
    "        # We've completed all our training, so run a final test evaluation on\n",
    "        # some new images we haven't used before.\n",
    "        test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "                get_random_cached_bottlenecks(sess, image_lists, FLAGS.test_batch_size,\n",
    "                                      'testing', FLAGS.bottleneck_dir,\n",
    "                                      FLAGS.image_dir, jpeg_data_tensor,\n",
    "                                      bottleneck_tensor))\n",
    "        test_accuracy, predictions = sess.run(\n",
    "                [evaluation_step, prediction],\n",
    "                feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                           ground_truth_input: test_ground_truth})\n",
    "        print('Final test accuracy = %.1f%% (N=%d)' % (\n",
    "                test_accuracy * 100, len(test_bottlenecks)))\n",
    "        print(str(time.ctime()))\n",
    "\n",
    "        if FLAGS.print_misclassified_test_images:\n",
    "            print('=== MISCLASSIFIED TEST IMAGES ===')\n",
    "            for i, test_filename in enumerate(test_filenames):\n",
    "                if predictions[i] != test_ground_truth[i].argmax():\n",
    "                    print('%70s  %s' % (test_filename,\n",
    "                              list(image_lists.keys())[predictions[i]]))\n",
    "\n",
    "        # Write out the trained graph and labels with the weights stored as\n",
    "        # constants.\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "                sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\n",
    "        \n",
    "        with gfile.FastGFile(FLAGS.output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        \n",
    "        with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n",
    "            f.write('\\n'.join(image_lists.keys()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Wed May 16 15:00:20 2018 \n",
      "\n",
      "\n",
      "Looking for images in 'A'\n",
      "\n",
      "Looking for images in 'B'\n",
      "100 bottleneck files created.\n",
      "200 bottleneck files created.\n",
      "300 bottleneck files created.\n",
      "400 bottleneck files created.\n",
      "500 bottleneck files created.\n",
      "600 bottleneck files created.\n",
      "700 bottleneck files created.\n",
      "800 bottleneck files created.\n",
      "900 bottleneck files created.\n",
      "1000 bottleneck files created.\n",
      "1100 bottleneck files created.\n",
      "1200 bottleneck files created.\n",
      "1300 bottleneck files created.\n",
      "1400 bottleneck files created.\n",
      "1500 bottleneck files created.\n",
      "1600 bottleneck files created.\n",
      "1700 bottleneck files created.\n",
      "1800 bottleneck files created.\n",
      "1900 bottleneck files created.\n",
      "2000 bottleneck files created.\n",
      "2100 bottleneck files created.\n",
      "2200 bottleneck files created.\n",
      "2300 bottleneck files created.\n",
      "2400 bottleneck files created.\n",
      "2500 bottleneck files created.\n",
      "2600 bottleneck files created.\n",
      "2700 bottleneck files created.\n",
      "2800 bottleneck files created.\n",
      "2900 bottleneck files created.\n",
      "WARNING:tensorflow:From <ipython-input-20-2810ccd5b595>:53: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "trainingstep =  0\n",
      "Step: 0, Train accuracy: 58.0000%, Cross entropy: 0.521094, Validation accuracy: 54.0% (N=100)\n",
      "trainingstep =  1\n",
      "trainingstep =  2\n",
      "trainingstep =  3\n",
      "trainingstep =  4\n",
      "trainingstep =  5\n",
      "trainingstep =  6\n",
      "trainingstep =  7\n",
      "trainingstep =  8\n",
      "trainingstep =  9\n",
      "trainingstep =  10\n",
      "trainingstep =  11\n",
      "trainingstep =  12\n",
      "trainingstep =  13\n",
      "trainingstep =  14\n",
      "trainingstep =  15\n",
      "trainingstep =  16\n",
      "trainingstep =  17\n",
      "trainingstep =  18\n",
      "trainingstep =  19\n",
      "trainingstep =  20\n",
      "trainingstep =  21\n",
      "trainingstep =  22\n",
      "trainingstep =  23\n",
      "trainingstep =  24\n",
      "trainingstep =  25\n",
      "trainingstep =  26\n",
      "trainingstep =  27\n",
      "trainingstep =  28\n",
      "trainingstep =  29\n",
      "trainingstep =  30\n",
      "trainingstep =  31\n",
      "trainingstep =  32\n",
      "trainingstep =  33\n",
      "trainingstep =  34\n",
      "trainingstep =  35\n",
      "trainingstep =  36\n",
      "trainingstep =  37\n",
      "trainingstep =  38\n",
      "trainingstep =  39\n",
      "trainingstep =  40\n",
      "trainingstep =  41\n",
      "trainingstep =  42\n",
      "trainingstep =  43\n",
      "trainingstep =  44\n",
      "trainingstep =  45\n",
      "trainingstep =  46\n",
      "trainingstep =  47\n",
      "trainingstep =  48\n",
      "trainingstep =  49\n",
      "trainingstep =  50\n",
      "trainingstep =  51\n",
      "trainingstep =  52\n",
      "trainingstep =  53\n",
      "trainingstep =  54\n",
      "trainingstep =  55\n",
      "trainingstep =  56\n",
      "trainingstep =  57\n",
      "trainingstep =  58\n",
      "trainingstep =  59\n",
      "trainingstep =  60\n",
      "trainingstep =  61\n",
      "trainingstep =  62\n",
      "trainingstep =  63\n",
      "trainingstep =  64\n",
      "trainingstep =  65\n",
      "trainingstep =  66\n",
      "trainingstep =  67\n",
      "trainingstep =  68\n",
      "trainingstep =  69\n",
      "trainingstep =  70\n",
      "trainingstep =  71\n",
      "trainingstep =  72\n",
      "trainingstep =  73\n",
      "trainingstep =  74\n",
      "trainingstep =  75\n",
      "trainingstep =  76\n",
      "trainingstep =  77\n",
      "trainingstep =  78\n",
      "trainingstep =  79\n",
      "trainingstep =  80\n",
      "trainingstep =  81\n",
      "trainingstep =  82\n",
      "trainingstep =  83\n",
      "trainingstep =  84\n",
      "trainingstep =  85\n",
      "trainingstep =  86\n",
      "trainingstep =  87\n",
      "trainingstep =  88\n",
      "trainingstep =  89\n",
      "trainingstep =  90\n",
      "trainingstep =  91\n",
      "trainingstep =  92\n",
      "trainingstep =  93\n",
      "trainingstep =  94\n",
      "trainingstep =  95\n",
      "trainingstep =  96\n",
      "trainingstep =  97\n",
      "trainingstep =  98\n",
      "trainingstep =  99\n",
      "trainingstep =  100\n",
      "Step: 100, Train accuracy: 99.0000%, Cross entropy: 0.045397, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  101\n",
      "trainingstep =  102\n",
      "trainingstep =  103\n",
      "trainingstep =  104\n",
      "trainingstep =  105\n",
      "trainingstep =  106\n",
      "trainingstep =  107\n",
      "trainingstep =  108\n",
      "trainingstep =  109\n",
      "trainingstep =  110\n",
      "trainingstep =  111\n",
      "trainingstep =  112\n",
      "trainingstep =  113\n",
      "trainingstep =  114\n",
      "trainingstep =  115\n",
      "trainingstep =  116\n",
      "trainingstep =  117\n",
      "trainingstep =  118\n",
      "trainingstep =  119\n",
      "trainingstep =  120\n",
      "trainingstep =  121\n",
      "trainingstep =  122\n",
      "trainingstep =  123\n",
      "trainingstep =  124\n",
      "trainingstep =  125\n",
      "trainingstep =  126\n",
      "trainingstep =  127\n",
      "trainingstep =  128\n",
      "trainingstep =  129\n",
      "trainingstep =  130\n",
      "trainingstep =  131\n",
      "trainingstep =  132\n",
      "trainingstep =  133\n",
      "trainingstep =  134\n",
      "trainingstep =  135\n",
      "trainingstep =  136\n",
      "trainingstep =  137\n",
      "trainingstep =  138\n",
      "trainingstep =  139\n",
      "trainingstep =  140\n",
      "trainingstep =  141\n",
      "trainingstep =  142\n",
      "trainingstep =  143\n",
      "trainingstep =  144\n",
      "trainingstep =  145\n",
      "trainingstep =  146\n",
      "trainingstep =  147\n",
      "trainingstep =  148\n",
      "trainingstep =  149\n",
      "trainingstep =  150\n",
      "trainingstep =  151\n",
      "trainingstep =  152\n",
      "trainingstep =  153\n",
      "trainingstep =  154\n",
      "trainingstep =  155\n",
      "trainingstep =  156\n",
      "trainingstep =  157\n",
      "trainingstep =  158\n",
      "trainingstep =  159\n",
      "trainingstep =  160\n",
      "trainingstep =  161\n",
      "trainingstep =  162\n",
      "trainingstep =  163\n",
      "trainingstep =  164\n",
      "trainingstep =  165\n",
      "trainingstep =  166\n",
      "trainingstep =  167\n",
      "trainingstep =  168\n",
      "trainingstep =  169\n",
      "trainingstep =  170\n",
      "trainingstep =  171\n",
      "trainingstep =  172\n",
      "trainingstep =  173\n",
      "trainingstep =  174\n",
      "trainingstep =  175\n",
      "trainingstep =  176\n",
      "trainingstep =  177\n",
      "trainingstep =  178\n",
      "trainingstep =  179\n",
      "trainingstep =  180\n",
      "trainingstep =  181\n",
      "trainingstep =  182\n",
      "trainingstep =  183\n",
      "trainingstep =  184\n",
      "trainingstep =  185\n",
      "trainingstep =  186\n",
      "trainingstep =  187\n",
      "trainingstep =  188\n",
      "trainingstep =  189\n",
      "trainingstep =  190\n",
      "trainingstep =  191\n",
      "trainingstep =  192\n",
      "trainingstep =  193\n",
      "trainingstep =  194\n",
      "trainingstep =  195\n",
      "trainingstep =  196\n",
      "trainingstep =  197\n",
      "trainingstep =  198\n",
      "trainingstep =  199\n",
      "trainingstep =  200\n",
      "Step: 200, Train accuracy: 99.0000%, Cross entropy: 0.044546, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  201\n",
      "trainingstep =  202\n",
      "trainingstep =  203\n",
      "trainingstep =  204\n",
      "trainingstep =  205\n",
      "trainingstep =  206\n",
      "trainingstep =  207\n",
      "trainingstep =  208\n",
      "trainingstep =  209\n",
      "trainingstep =  210\n",
      "trainingstep =  211\n",
      "trainingstep =  212\n",
      "trainingstep =  213\n",
      "trainingstep =  214\n",
      "trainingstep =  215\n",
      "trainingstep =  216\n",
      "trainingstep =  217\n",
      "trainingstep =  218\n",
      "trainingstep =  219\n",
      "trainingstep =  220\n",
      "trainingstep =  221\n",
      "trainingstep =  222\n",
      "trainingstep =  223\n",
      "trainingstep =  224\n",
      "trainingstep =  225\n",
      "trainingstep =  226\n",
      "trainingstep =  227\n",
      "trainingstep =  228\n",
      "trainingstep =  229\n",
      "trainingstep =  230\n",
      "trainingstep =  231\n",
      "trainingstep =  232\n",
      "trainingstep =  233\n",
      "trainingstep =  234\n",
      "trainingstep =  235\n",
      "trainingstep =  236\n",
      "trainingstep =  237\n",
      "trainingstep =  238\n",
      "trainingstep =  239\n",
      "trainingstep =  240\n",
      "trainingstep =  241\n",
      "trainingstep =  242\n",
      "trainingstep =  243\n",
      "trainingstep =  244\n",
      "trainingstep =  245\n",
      "trainingstep =  246\n",
      "trainingstep =  247\n",
      "trainingstep =  248\n",
      "trainingstep =  249\n",
      "trainingstep =  250\n",
      "trainingstep =  251\n",
      "trainingstep =  252\n",
      "trainingstep =  253\n",
      "trainingstep =  254\n",
      "trainingstep =  255\n",
      "trainingstep =  256\n",
      "trainingstep =  257\n",
      "trainingstep =  258\n",
      "trainingstep =  259\n",
      "trainingstep =  260\n",
      "trainingstep =  261\n",
      "trainingstep =  262\n",
      "trainingstep =  263\n",
      "trainingstep =  264\n",
      "trainingstep =  265\n",
      "trainingstep =  266\n",
      "trainingstep =  267\n",
      "trainingstep =  268\n",
      "trainingstep =  269\n",
      "trainingstep =  270\n",
      "trainingstep =  271\n",
      "trainingstep =  272\n",
      "trainingstep =  273\n",
      "trainingstep =  274\n",
      "trainingstep =  275\n",
      "trainingstep =  276\n",
      "trainingstep =  277\n",
      "trainingstep =  278\n",
      "trainingstep =  279\n",
      "trainingstep =  280\n",
      "trainingstep =  281\n",
      "trainingstep =  282\n",
      "trainingstep =  283\n",
      "trainingstep =  284\n",
      "trainingstep =  285\n",
      "trainingstep =  286\n",
      "trainingstep =  287\n",
      "trainingstep =  288\n",
      "trainingstep =  289\n",
      "trainingstep =  290\n",
      "trainingstep =  291\n",
      "trainingstep =  292\n",
      "trainingstep =  293\n",
      "trainingstep =  294\n",
      "trainingstep =  295\n",
      "trainingstep =  296\n",
      "trainingstep =  297\n",
      "trainingstep =  298\n",
      "trainingstep =  299\n",
      "trainingstep =  300\n",
      "Step: 300, Train accuracy: 100.0000%, Cross entropy: 0.028113, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  301\n",
      "trainingstep =  302\n",
      "trainingstep =  303\n",
      "trainingstep =  304\n",
      "trainingstep =  305\n",
      "trainingstep =  306\n",
      "trainingstep =  307\n",
      "trainingstep =  308\n",
      "trainingstep =  309\n",
      "trainingstep =  310\n",
      "trainingstep =  311\n",
      "trainingstep =  312\n",
      "trainingstep =  313\n",
      "trainingstep =  314\n",
      "trainingstep =  315\n",
      "trainingstep =  316\n",
      "trainingstep =  317\n",
      "trainingstep =  318\n",
      "trainingstep =  319\n",
      "trainingstep =  320\n",
      "trainingstep =  321\n",
      "trainingstep =  322\n",
      "trainingstep =  323\n",
      "trainingstep =  324\n",
      "trainingstep =  325\n",
      "trainingstep =  326\n",
      "trainingstep =  327\n",
      "trainingstep =  328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  329\n",
      "trainingstep =  330\n",
      "trainingstep =  331\n",
      "trainingstep =  332\n",
      "trainingstep =  333\n",
      "trainingstep =  334\n",
      "trainingstep =  335\n",
      "trainingstep =  336\n",
      "trainingstep =  337\n",
      "trainingstep =  338\n",
      "trainingstep =  339\n",
      "trainingstep =  340\n",
      "trainingstep =  341\n",
      "trainingstep =  342\n",
      "trainingstep =  343\n",
      "trainingstep =  344\n",
      "trainingstep =  345\n",
      "trainingstep =  346\n",
      "trainingstep =  347\n",
      "trainingstep =  348\n",
      "trainingstep =  349\n",
      "trainingstep =  350\n",
      "trainingstep =  351\n",
      "trainingstep =  352\n",
      "trainingstep =  353\n",
      "trainingstep =  354\n",
      "trainingstep =  355\n",
      "trainingstep =  356\n",
      "trainingstep =  357\n",
      "trainingstep =  358\n",
      "trainingstep =  359\n",
      "trainingstep =  360\n",
      "trainingstep =  361\n",
      "trainingstep =  362\n",
      "trainingstep =  363\n",
      "trainingstep =  364\n",
      "trainingstep =  365\n",
      "trainingstep =  366\n",
      "trainingstep =  367\n",
      "trainingstep =  368\n",
      "trainingstep =  369\n",
      "trainingstep =  370\n",
      "trainingstep =  371\n",
      "trainingstep =  372\n",
      "trainingstep =  373\n",
      "trainingstep =  374\n",
      "trainingstep =  375\n",
      "trainingstep =  376\n",
      "trainingstep =  377\n",
      "trainingstep =  378\n",
      "trainingstep =  379\n",
      "trainingstep =  380\n",
      "trainingstep =  381\n",
      "trainingstep =  382\n",
      "trainingstep =  383\n",
      "trainingstep =  384\n",
      "trainingstep =  385\n",
      "trainingstep =  386\n",
      "trainingstep =  387\n",
      "trainingstep =  388\n",
      "trainingstep =  389\n",
      "trainingstep =  390\n",
      "trainingstep =  391\n",
      "trainingstep =  392\n",
      "trainingstep =  393\n",
      "trainingstep =  394\n",
      "trainingstep =  395\n",
      "trainingstep =  396\n",
      "trainingstep =  397\n",
      "trainingstep =  398\n",
      "trainingstep =  399\n",
      "trainingstep =  400\n",
      "Step: 400, Train accuracy: 99.0000%, Cross entropy: 0.027793, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  401\n",
      "trainingstep =  402\n",
      "trainingstep =  403\n",
      "trainingstep =  404\n",
      "trainingstep =  405\n",
      "trainingstep =  406\n",
      "trainingstep =  407\n",
      "trainingstep =  408\n",
      "trainingstep =  409\n",
      "trainingstep =  410\n",
      "trainingstep =  411\n",
      "trainingstep =  412\n",
      "trainingstep =  413\n",
      "trainingstep =  414\n",
      "trainingstep =  415\n",
      "trainingstep =  416\n",
      "trainingstep =  417\n",
      "trainingstep =  418\n",
      "trainingstep =  419\n",
      "trainingstep =  420\n",
      "trainingstep =  421\n",
      "trainingstep =  422\n",
      "trainingstep =  423\n",
      "trainingstep =  424\n",
      "trainingstep =  425\n",
      "trainingstep =  426\n",
      "trainingstep =  427\n",
      "trainingstep =  428\n",
      "trainingstep =  429\n",
      "trainingstep =  430\n",
      "trainingstep =  431\n",
      "trainingstep =  432\n",
      "trainingstep =  433\n",
      "trainingstep =  434\n",
      "trainingstep =  435\n",
      "trainingstep =  436\n",
      "trainingstep =  437\n",
      "trainingstep =  438\n",
      "trainingstep =  439\n",
      "trainingstep =  440\n",
      "trainingstep =  441\n",
      "trainingstep =  442\n",
      "trainingstep =  443\n",
      "trainingstep =  444\n",
      "trainingstep =  445\n",
      "trainingstep =  446\n",
      "trainingstep =  447\n",
      "trainingstep =  448\n",
      "trainingstep =  449\n",
      "trainingstep =  450\n",
      "trainingstep =  451\n",
      "trainingstep =  452\n",
      "trainingstep =  453\n",
      "trainingstep =  454\n",
      "trainingstep =  455\n",
      "trainingstep =  456\n",
      "trainingstep =  457\n",
      "trainingstep =  458\n",
      "trainingstep =  459\n",
      "trainingstep =  460\n",
      "trainingstep =  461\n",
      "trainingstep =  462\n",
      "trainingstep =  463\n",
      "trainingstep =  464\n",
      "trainingstep =  465\n",
      "trainingstep =  466\n",
      "trainingstep =  467\n",
      "trainingstep =  468\n",
      "trainingstep =  469\n",
      "trainingstep =  470\n",
      "trainingstep =  471\n",
      "trainingstep =  472\n",
      "trainingstep =  473\n",
      "trainingstep =  474\n",
      "trainingstep =  475\n",
      "trainingstep =  476\n",
      "trainingstep =  477\n",
      "trainingstep =  478\n",
      "trainingstep =  479\n",
      "trainingstep =  480\n",
      "trainingstep =  481\n",
      "trainingstep =  482\n",
      "trainingstep =  483\n",
      "trainingstep =  484\n",
      "trainingstep =  485\n",
      "trainingstep =  486\n",
      "trainingstep =  487\n",
      "trainingstep =  488\n",
      "trainingstep =  489\n",
      "trainingstep =  490\n",
      "trainingstep =  491\n",
      "trainingstep =  492\n",
      "trainingstep =  493\n",
      "trainingstep =  494\n",
      "trainingstep =  495\n",
      "trainingstep =  496\n",
      "trainingstep =  497\n",
      "trainingstep =  498\n",
      "trainingstep =  499\n",
      "trainingstep =  500\n",
      "Step: 500, Train accuracy: 100.0000%, Cross entropy: 0.016318, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  501\n",
      "trainingstep =  502\n",
      "trainingstep =  503\n",
      "trainingstep =  504\n",
      "trainingstep =  505\n",
      "trainingstep =  506\n",
      "trainingstep =  507\n",
      "trainingstep =  508\n",
      "trainingstep =  509\n",
      "trainingstep =  510\n",
      "trainingstep =  511\n",
      "trainingstep =  512\n",
      "trainingstep =  513\n",
      "trainingstep =  514\n",
      "trainingstep =  515\n",
      "trainingstep =  516\n",
      "trainingstep =  517\n",
      "trainingstep =  518\n",
      "trainingstep =  519\n",
      "trainingstep =  520\n",
      "trainingstep =  521\n",
      "trainingstep =  522\n",
      "trainingstep =  523\n",
      "trainingstep =  524\n",
      "trainingstep =  525\n",
      "trainingstep =  526\n",
      "trainingstep =  527\n",
      "trainingstep =  528\n",
      "trainingstep =  529\n",
      "trainingstep =  530\n",
      "trainingstep =  531\n",
      "trainingstep =  532\n",
      "trainingstep =  533\n",
      "trainingstep =  534\n",
      "trainingstep =  535\n",
      "trainingstep =  536\n",
      "trainingstep =  537\n",
      "trainingstep =  538\n",
      "trainingstep =  539\n",
      "trainingstep =  540\n",
      "trainingstep =  541\n",
      "trainingstep =  542\n",
      "trainingstep =  543\n",
      "trainingstep =  544\n",
      "trainingstep =  545\n",
      "trainingstep =  546\n",
      "trainingstep =  547\n",
      "trainingstep =  548\n",
      "trainingstep =  549\n",
      "trainingstep =  550\n",
      "trainingstep =  551\n",
      "trainingstep =  552\n",
      "trainingstep =  553\n",
      "trainingstep =  554\n",
      "trainingstep =  555\n",
      "trainingstep =  556\n",
      "trainingstep =  557\n",
      "trainingstep =  558\n",
      "trainingstep =  559\n",
      "trainingstep =  560\n",
      "trainingstep =  561\n",
      "trainingstep =  562\n",
      "trainingstep =  563\n",
      "trainingstep =  564\n",
      "trainingstep =  565\n",
      "trainingstep =  566\n",
      "trainingstep =  567\n",
      "trainingstep =  568\n",
      "trainingstep =  569\n",
      "trainingstep =  570\n",
      "trainingstep =  571\n",
      "trainingstep =  572\n",
      "trainingstep =  573\n",
      "trainingstep =  574\n",
      "trainingstep =  575\n",
      "trainingstep =  576\n",
      "trainingstep =  577\n",
      "trainingstep =  578\n",
      "trainingstep =  579\n",
      "trainingstep =  580\n",
      "trainingstep =  581\n",
      "trainingstep =  582\n",
      "trainingstep =  583\n",
      "trainingstep =  584\n",
      "trainingstep =  585\n",
      "trainingstep =  586\n",
      "trainingstep =  587\n",
      "trainingstep =  588\n",
      "trainingstep =  589\n",
      "trainingstep =  590\n",
      "trainingstep =  591\n",
      "trainingstep =  592\n",
      "trainingstep =  593\n",
      "trainingstep =  594\n",
      "trainingstep =  595\n",
      "trainingstep =  596\n",
      "trainingstep =  597\n",
      "trainingstep =  598\n",
      "trainingstep =  599\n",
      "trainingstep =  600\n",
      "Step: 600, Train accuracy: 100.0000%, Cross entropy: 0.014675, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  601\n",
      "trainingstep =  602\n",
      "trainingstep =  603\n",
      "trainingstep =  604\n",
      "trainingstep =  605\n",
      "trainingstep =  606\n",
      "trainingstep =  607\n",
      "trainingstep =  608\n",
      "trainingstep =  609\n",
      "trainingstep =  610\n",
      "trainingstep =  611\n",
      "trainingstep =  612\n",
      "trainingstep =  613\n",
      "trainingstep =  614\n",
      "trainingstep =  615\n",
      "trainingstep =  616\n",
      "trainingstep =  617\n",
      "trainingstep =  618\n",
      "trainingstep =  619\n",
      "trainingstep =  620\n",
      "trainingstep =  621\n",
      "trainingstep =  622\n",
      "trainingstep =  623\n",
      "trainingstep =  624\n",
      "trainingstep =  625\n",
      "trainingstep =  626\n",
      "trainingstep =  627\n",
      "trainingstep =  628\n",
      "trainingstep =  629\n",
      "trainingstep =  630\n",
      "trainingstep =  631\n",
      "trainingstep =  632\n",
      "trainingstep =  633\n",
      "trainingstep =  634\n",
      "trainingstep =  635\n",
      "trainingstep =  636\n",
      "trainingstep =  637\n",
      "trainingstep =  638\n",
      "trainingstep =  639\n",
      "trainingstep =  640\n",
      "trainingstep =  641\n",
      "trainingstep =  642\n",
      "trainingstep =  643\n",
      "trainingstep =  644\n",
      "trainingstep =  645\n",
      "trainingstep =  646\n",
      "trainingstep =  647\n",
      "trainingstep =  648\n",
      "trainingstep =  649\n",
      "trainingstep =  650\n",
      "trainingstep =  651\n",
      "trainingstep =  652\n",
      "trainingstep =  653\n",
      "trainingstep =  654\n",
      "trainingstep =  655\n",
      "trainingstep =  656\n",
      "trainingstep =  657\n",
      "trainingstep =  658\n",
      "trainingstep =  659\n",
      "trainingstep =  660\n",
      "trainingstep =  661\n",
      "trainingstep =  662\n",
      "trainingstep =  663\n",
      "trainingstep =  664\n",
      "trainingstep =  665\n",
      "trainingstep =  666\n",
      "trainingstep =  667\n",
      "trainingstep =  668\n",
      "trainingstep =  669\n",
      "trainingstep =  670\n",
      "trainingstep =  671\n",
      "trainingstep =  672\n",
      "trainingstep =  673\n",
      "trainingstep =  674\n",
      "trainingstep =  675\n",
      "trainingstep =  676\n",
      "trainingstep =  677\n",
      "trainingstep =  678\n",
      "trainingstep =  679\n",
      "trainingstep =  680\n",
      "trainingstep =  681\n",
      "trainingstep =  682\n",
      "trainingstep =  683\n",
      "trainingstep =  684\n",
      "trainingstep =  685\n",
      "trainingstep =  686\n",
      "trainingstep =  687\n",
      "trainingstep =  688\n",
      "trainingstep =  689\n",
      "trainingstep =  690\n",
      "trainingstep =  691\n",
      "trainingstep =  692\n",
      "trainingstep =  693\n",
      "trainingstep =  694\n",
      "trainingstep =  695\n",
      "trainingstep =  696\n",
      "trainingstep =  697\n",
      "trainingstep =  698\n",
      "trainingstep =  699\n",
      "trainingstep =  700\n",
      "Step: 700, Train accuracy: 100.0000%, Cross entropy: 0.018724, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  701\n",
      "trainingstep =  702\n",
      "trainingstep =  703\n",
      "trainingstep =  704\n",
      "trainingstep =  705\n",
      "trainingstep =  706\n",
      "trainingstep =  707\n",
      "trainingstep =  708\n",
      "trainingstep =  709\n",
      "trainingstep =  710\n",
      "trainingstep =  711\n",
      "trainingstep =  712\n",
      "trainingstep =  713\n",
      "trainingstep =  714\n",
      "trainingstep =  715\n",
      "trainingstep =  716\n",
      "trainingstep =  717\n",
      "trainingstep =  718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  719\n",
      "trainingstep =  720\n",
      "trainingstep =  721\n",
      "trainingstep =  722\n",
      "trainingstep =  723\n",
      "trainingstep =  724\n",
      "trainingstep =  725\n",
      "trainingstep =  726\n",
      "trainingstep =  727\n",
      "trainingstep =  728\n",
      "trainingstep =  729\n",
      "trainingstep =  730\n",
      "trainingstep =  731\n",
      "trainingstep =  732\n",
      "trainingstep =  733\n",
      "trainingstep =  734\n",
      "trainingstep =  735\n",
      "trainingstep =  736\n",
      "trainingstep =  737\n",
      "trainingstep =  738\n",
      "trainingstep =  739\n",
      "trainingstep =  740\n",
      "trainingstep =  741\n",
      "trainingstep =  742\n",
      "trainingstep =  743\n",
      "trainingstep =  744\n",
      "trainingstep =  745\n",
      "trainingstep =  746\n",
      "trainingstep =  747\n",
      "trainingstep =  748\n",
      "trainingstep =  749\n",
      "trainingstep =  750\n",
      "trainingstep =  751\n",
      "trainingstep =  752\n",
      "trainingstep =  753\n",
      "trainingstep =  754\n",
      "trainingstep =  755\n",
      "trainingstep =  756\n",
      "trainingstep =  757\n",
      "trainingstep =  758\n",
      "trainingstep =  759\n",
      "trainingstep =  760\n",
      "trainingstep =  761\n",
      "trainingstep =  762\n",
      "trainingstep =  763\n",
      "trainingstep =  764\n",
      "trainingstep =  765\n",
      "trainingstep =  766\n",
      "trainingstep =  767\n",
      "trainingstep =  768\n",
      "trainingstep =  769\n",
      "trainingstep =  770\n",
      "trainingstep =  771\n",
      "trainingstep =  772\n",
      "trainingstep =  773\n",
      "trainingstep =  774\n",
      "trainingstep =  775\n",
      "trainingstep =  776\n",
      "trainingstep =  777\n",
      "trainingstep =  778\n",
      "trainingstep =  779\n",
      "trainingstep =  780\n",
      "trainingstep =  781\n",
      "trainingstep =  782\n",
      "trainingstep =  783\n",
      "trainingstep =  784\n",
      "trainingstep =  785\n",
      "trainingstep =  786\n",
      "trainingstep =  787\n",
      "trainingstep =  788\n",
      "trainingstep =  789\n",
      "trainingstep =  790\n",
      "trainingstep =  791\n",
      "trainingstep =  792\n",
      "trainingstep =  793\n",
      "trainingstep =  794\n",
      "trainingstep =  795\n",
      "trainingstep =  796\n",
      "trainingstep =  797\n",
      "trainingstep =  798\n",
      "trainingstep =  799\n",
      "trainingstep =  800\n",
      "Step: 800, Train accuracy: 100.0000%, Cross entropy: 0.013174, Validation accuracy: 99.0% (N=100)\n",
      "trainingstep =  801\n",
      "trainingstep =  802\n",
      "trainingstep =  803\n",
      "trainingstep =  804\n",
      "trainingstep =  805\n",
      "trainingstep =  806\n",
      "trainingstep =  807\n",
      "trainingstep =  808\n",
      "trainingstep =  809\n",
      "trainingstep =  810\n",
      "trainingstep =  811\n",
      "trainingstep =  812\n",
      "trainingstep =  813\n",
      "trainingstep =  814\n",
      "trainingstep =  815\n",
      "trainingstep =  816\n",
      "trainingstep =  817\n",
      "trainingstep =  818\n",
      "trainingstep =  819\n",
      "trainingstep =  820\n",
      "trainingstep =  821\n",
      "trainingstep =  822\n",
      "trainingstep =  823\n",
      "trainingstep =  824\n",
      "trainingstep =  825\n",
      "trainingstep =  826\n",
      "trainingstep =  827\n",
      "trainingstep =  828\n",
      "trainingstep =  829\n",
      "trainingstep =  830\n",
      "trainingstep =  831\n",
      "trainingstep =  832\n",
      "trainingstep =  833\n",
      "trainingstep =  834\n",
      "trainingstep =  835\n",
      "trainingstep =  836\n",
      "trainingstep =  837\n",
      "trainingstep =  838\n",
      "trainingstep =  839\n",
      "trainingstep =  840\n",
      "trainingstep =  841\n",
      "trainingstep =  842\n",
      "trainingstep =  843\n",
      "trainingstep =  844\n",
      "trainingstep =  845\n",
      "trainingstep =  846\n",
      "trainingstep =  847\n",
      "trainingstep =  848\n",
      "trainingstep =  849\n",
      "trainingstep =  850\n",
      "trainingstep =  851\n",
      "trainingstep =  852\n",
      "trainingstep =  853\n",
      "trainingstep =  854\n",
      "trainingstep =  855\n",
      "trainingstep =  856\n",
      "trainingstep =  857\n",
      "trainingstep =  858\n",
      "trainingstep =  859\n",
      "trainingstep =  860\n",
      "trainingstep =  861\n",
      "trainingstep =  862\n",
      "trainingstep =  863\n",
      "trainingstep =  864\n",
      "trainingstep =  865\n",
      "trainingstep =  866\n",
      "trainingstep =  867\n",
      "trainingstep =  868\n",
      "trainingstep =  869\n",
      "trainingstep =  870\n",
      "trainingstep =  871\n",
      "trainingstep =  872\n",
      "trainingstep =  873\n",
      "trainingstep =  874\n",
      "trainingstep =  875\n",
      "trainingstep =  876\n",
      "trainingstep =  877\n",
      "trainingstep =  878\n",
      "trainingstep =  879\n",
      "trainingstep =  880\n",
      "trainingstep =  881\n",
      "trainingstep =  882\n",
      "trainingstep =  883\n",
      "trainingstep =  884\n",
      "trainingstep =  885\n",
      "trainingstep =  886\n",
      "trainingstep =  887\n",
      "trainingstep =  888\n",
      "trainingstep =  889\n",
      "trainingstep =  890\n",
      "trainingstep =  891\n",
      "trainingstep =  892\n",
      "trainingstep =  893\n",
      "trainingstep =  894\n",
      "trainingstep =  895\n",
      "trainingstep =  896\n",
      "trainingstep =  897\n",
      "trainingstep =  898\n",
      "trainingstep =  899\n",
      "trainingstep =  900\n",
      "Step: 900, Train accuracy: 100.0000%, Cross entropy: 0.010597, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  901\n",
      "trainingstep =  902\n",
      "trainingstep =  903\n",
      "trainingstep =  904\n",
      "trainingstep =  905\n",
      "trainingstep =  906\n",
      "trainingstep =  907\n",
      "trainingstep =  908\n",
      "trainingstep =  909\n",
      "trainingstep =  910\n",
      "trainingstep =  911\n",
      "trainingstep =  912\n",
      "trainingstep =  913\n",
      "trainingstep =  914\n",
      "trainingstep =  915\n",
      "trainingstep =  916\n",
      "trainingstep =  917\n",
      "trainingstep =  918\n",
      "trainingstep =  919\n",
      "trainingstep =  920\n",
      "trainingstep =  921\n",
      "trainingstep =  922\n",
      "trainingstep =  923\n",
      "trainingstep =  924\n",
      "trainingstep =  925\n",
      "trainingstep =  926\n",
      "trainingstep =  927\n",
      "trainingstep =  928\n",
      "trainingstep =  929\n",
      "trainingstep =  930\n",
      "trainingstep =  931\n",
      "trainingstep =  932\n",
      "trainingstep =  933\n",
      "trainingstep =  934\n",
      "trainingstep =  935\n",
      "trainingstep =  936\n",
      "trainingstep =  937\n",
      "trainingstep =  938\n",
      "trainingstep =  939\n",
      "trainingstep =  940\n",
      "trainingstep =  941\n",
      "trainingstep =  942\n",
      "trainingstep =  943\n",
      "trainingstep =  944\n",
      "trainingstep =  945\n",
      "trainingstep =  946\n",
      "trainingstep =  947\n",
      "trainingstep =  948\n",
      "trainingstep =  949\n",
      "trainingstep =  950\n",
      "trainingstep =  951\n",
      "trainingstep =  952\n",
      "trainingstep =  953\n",
      "trainingstep =  954\n",
      "trainingstep =  955\n",
      "trainingstep =  956\n",
      "trainingstep =  957\n",
      "trainingstep =  958\n",
      "trainingstep =  959\n",
      "trainingstep =  960\n",
      "trainingstep =  961\n",
      "trainingstep =  962\n",
      "trainingstep =  963\n",
      "trainingstep =  964\n",
      "trainingstep =  965\n",
      "trainingstep =  966\n",
      "trainingstep =  967\n",
      "trainingstep =  968\n",
      "trainingstep =  969\n",
      "trainingstep =  970\n",
      "trainingstep =  971\n",
      "trainingstep =  972\n",
      "trainingstep =  973\n",
      "trainingstep =  974\n",
      "trainingstep =  975\n",
      "trainingstep =  976\n",
      "trainingstep =  977\n",
      "trainingstep =  978\n",
      "trainingstep =  979\n",
      "trainingstep =  980\n",
      "trainingstep =  981\n",
      "trainingstep =  982\n",
      "trainingstep =  983\n",
      "trainingstep =  984\n",
      "trainingstep =  985\n",
      "trainingstep =  986\n",
      "trainingstep =  987\n",
      "trainingstep =  988\n",
      "trainingstep =  989\n",
      "trainingstep =  990\n",
      "trainingstep =  991\n",
      "trainingstep =  992\n",
      "trainingstep =  993\n",
      "trainingstep =  994\n",
      "trainingstep =  995\n",
      "trainingstep =  996\n",
      "trainingstep =  997\n",
      "trainingstep =  998\n",
      "trainingstep =  999\n",
      "trainingstep =  1000\n",
      "Step: 1000, Train accuracy: 100.0000%, Cross entropy: 0.015091, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1001\n",
      "trainingstep =  1002\n",
      "trainingstep =  1003\n",
      "trainingstep =  1004\n",
      "trainingstep =  1005\n",
      "trainingstep =  1006\n",
      "trainingstep =  1007\n",
      "trainingstep =  1008\n",
      "trainingstep =  1009\n",
      "trainingstep =  1010\n",
      "trainingstep =  1011\n",
      "trainingstep =  1012\n",
      "trainingstep =  1013\n",
      "trainingstep =  1014\n",
      "trainingstep =  1015\n",
      "trainingstep =  1016\n",
      "trainingstep =  1017\n",
      "trainingstep =  1018\n",
      "trainingstep =  1019\n",
      "trainingstep =  1020\n",
      "trainingstep =  1021\n",
      "trainingstep =  1022\n",
      "trainingstep =  1023\n",
      "trainingstep =  1024\n",
      "trainingstep =  1025\n",
      "trainingstep =  1026\n",
      "trainingstep =  1027\n",
      "trainingstep =  1028\n",
      "trainingstep =  1029\n",
      "trainingstep =  1030\n",
      "trainingstep =  1031\n",
      "trainingstep =  1032\n",
      "trainingstep =  1033\n",
      "trainingstep =  1034\n",
      "trainingstep =  1035\n",
      "trainingstep =  1036\n",
      "trainingstep =  1037\n",
      "trainingstep =  1038\n",
      "trainingstep =  1039\n",
      "trainingstep =  1040\n",
      "trainingstep =  1041\n",
      "trainingstep =  1042\n",
      "trainingstep =  1043\n",
      "trainingstep =  1044\n",
      "trainingstep =  1045\n",
      "trainingstep =  1046\n",
      "trainingstep =  1047\n",
      "trainingstep =  1048\n",
      "trainingstep =  1049\n",
      "trainingstep =  1050\n",
      "trainingstep =  1051\n",
      "trainingstep =  1052\n",
      "trainingstep =  1053\n",
      "trainingstep =  1054\n",
      "trainingstep =  1055\n",
      "trainingstep =  1056\n",
      "trainingstep =  1057\n",
      "trainingstep =  1058\n",
      "trainingstep =  1059\n",
      "trainingstep =  1060\n",
      "trainingstep =  1061\n",
      "trainingstep =  1062\n",
      "trainingstep =  1063\n",
      "trainingstep =  1064\n",
      "trainingstep =  1065\n",
      "trainingstep =  1066\n",
      "trainingstep =  1067\n",
      "trainingstep =  1068\n",
      "trainingstep =  1069\n",
      "trainingstep =  1070\n",
      "trainingstep =  1071\n",
      "trainingstep =  1072\n",
      "trainingstep =  1073\n",
      "trainingstep =  1074\n",
      "trainingstep =  1075\n",
      "trainingstep =  1076\n",
      "trainingstep =  1077\n",
      "trainingstep =  1078\n",
      "trainingstep =  1079\n",
      "trainingstep =  1080\n",
      "trainingstep =  1081\n",
      "trainingstep =  1082\n",
      "trainingstep =  1083\n",
      "trainingstep =  1084\n",
      "trainingstep =  1085\n",
      "trainingstep =  1086\n",
      "trainingstep =  1087\n",
      "trainingstep =  1088\n",
      "trainingstep =  1089\n",
      "trainingstep =  1090\n",
      "trainingstep =  1091\n",
      "trainingstep =  1092\n",
      "trainingstep =  1093\n",
      "trainingstep =  1094\n",
      "trainingstep =  1095\n",
      "trainingstep =  1096\n",
      "trainingstep =  1097\n",
      "trainingstep =  1098\n",
      "trainingstep =  1099\n",
      "trainingstep =  1100\n",
      "Step: 1100, Train accuracy: 100.0000%, Cross entropy: 0.008452, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1101\n",
      "trainingstep =  1102\n",
      "trainingstep =  1103\n",
      "trainingstep =  1104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  1105\n",
      "trainingstep =  1106\n",
      "trainingstep =  1107\n",
      "trainingstep =  1108\n",
      "trainingstep =  1109\n",
      "trainingstep =  1110\n",
      "trainingstep =  1111\n",
      "trainingstep =  1112\n",
      "trainingstep =  1113\n",
      "trainingstep =  1114\n",
      "trainingstep =  1115\n",
      "trainingstep =  1116\n",
      "trainingstep =  1117\n",
      "trainingstep =  1118\n",
      "trainingstep =  1119\n",
      "trainingstep =  1120\n",
      "trainingstep =  1121\n",
      "trainingstep =  1122\n",
      "trainingstep =  1123\n",
      "trainingstep =  1124\n",
      "trainingstep =  1125\n",
      "trainingstep =  1126\n",
      "trainingstep =  1127\n",
      "trainingstep =  1128\n",
      "trainingstep =  1129\n",
      "trainingstep =  1130\n",
      "trainingstep =  1131\n",
      "trainingstep =  1132\n",
      "trainingstep =  1133\n",
      "trainingstep =  1134\n",
      "trainingstep =  1135\n",
      "trainingstep =  1136\n",
      "trainingstep =  1137\n",
      "trainingstep =  1138\n",
      "trainingstep =  1139\n",
      "trainingstep =  1140\n",
      "trainingstep =  1141\n",
      "trainingstep =  1142\n",
      "trainingstep =  1143\n",
      "trainingstep =  1144\n",
      "trainingstep =  1145\n",
      "trainingstep =  1146\n",
      "trainingstep =  1147\n",
      "trainingstep =  1148\n",
      "trainingstep =  1149\n",
      "trainingstep =  1150\n",
      "trainingstep =  1151\n",
      "trainingstep =  1152\n",
      "trainingstep =  1153\n",
      "trainingstep =  1154\n",
      "trainingstep =  1155\n",
      "trainingstep =  1156\n",
      "trainingstep =  1157\n",
      "trainingstep =  1158\n",
      "trainingstep =  1159\n",
      "trainingstep =  1160\n",
      "trainingstep =  1161\n",
      "trainingstep =  1162\n",
      "trainingstep =  1163\n",
      "trainingstep =  1164\n",
      "trainingstep =  1165\n",
      "trainingstep =  1166\n",
      "trainingstep =  1167\n",
      "trainingstep =  1168\n",
      "trainingstep =  1169\n",
      "trainingstep =  1170\n",
      "trainingstep =  1171\n",
      "trainingstep =  1172\n",
      "trainingstep =  1173\n",
      "trainingstep =  1174\n",
      "trainingstep =  1175\n",
      "trainingstep =  1176\n",
      "trainingstep =  1177\n",
      "trainingstep =  1178\n",
      "trainingstep =  1179\n",
      "trainingstep =  1180\n",
      "trainingstep =  1181\n",
      "trainingstep =  1182\n",
      "trainingstep =  1183\n",
      "trainingstep =  1184\n",
      "trainingstep =  1185\n",
      "trainingstep =  1186\n",
      "trainingstep =  1187\n",
      "trainingstep =  1188\n",
      "trainingstep =  1189\n",
      "trainingstep =  1190\n",
      "trainingstep =  1191\n",
      "trainingstep =  1192\n",
      "trainingstep =  1193\n",
      "trainingstep =  1194\n",
      "trainingstep =  1195\n",
      "trainingstep =  1196\n",
      "trainingstep =  1197\n",
      "trainingstep =  1198\n",
      "trainingstep =  1199\n",
      "trainingstep =  1200\n",
      "Step: 1200, Train accuracy: 99.0000%, Cross entropy: 0.014543, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1201\n",
      "trainingstep =  1202\n",
      "trainingstep =  1203\n",
      "trainingstep =  1204\n",
      "trainingstep =  1205\n",
      "trainingstep =  1206\n",
      "trainingstep =  1207\n",
      "trainingstep =  1208\n",
      "trainingstep =  1209\n",
      "trainingstep =  1210\n",
      "trainingstep =  1211\n",
      "trainingstep =  1212\n",
      "trainingstep =  1213\n",
      "trainingstep =  1214\n",
      "trainingstep =  1215\n",
      "trainingstep =  1216\n",
      "trainingstep =  1217\n",
      "trainingstep =  1218\n",
      "trainingstep =  1219\n",
      "trainingstep =  1220\n",
      "trainingstep =  1221\n",
      "trainingstep =  1222\n",
      "trainingstep =  1223\n",
      "trainingstep =  1224\n",
      "trainingstep =  1225\n",
      "trainingstep =  1226\n",
      "trainingstep =  1227\n",
      "trainingstep =  1228\n",
      "trainingstep =  1229\n",
      "trainingstep =  1230\n",
      "trainingstep =  1231\n",
      "trainingstep =  1232\n",
      "trainingstep =  1233\n",
      "trainingstep =  1234\n",
      "trainingstep =  1235\n",
      "trainingstep =  1236\n",
      "trainingstep =  1237\n",
      "trainingstep =  1238\n",
      "trainingstep =  1239\n",
      "trainingstep =  1240\n",
      "trainingstep =  1241\n",
      "trainingstep =  1242\n",
      "trainingstep =  1243\n",
      "trainingstep =  1244\n",
      "trainingstep =  1245\n",
      "trainingstep =  1246\n",
      "trainingstep =  1247\n",
      "trainingstep =  1248\n",
      "trainingstep =  1249\n",
      "trainingstep =  1250\n",
      "trainingstep =  1251\n",
      "trainingstep =  1252\n",
      "trainingstep =  1253\n",
      "trainingstep =  1254\n",
      "trainingstep =  1255\n",
      "trainingstep =  1256\n",
      "trainingstep =  1257\n",
      "trainingstep =  1258\n",
      "trainingstep =  1259\n",
      "trainingstep =  1260\n",
      "trainingstep =  1261\n",
      "trainingstep =  1262\n",
      "trainingstep =  1263\n",
      "trainingstep =  1264\n",
      "trainingstep =  1265\n",
      "trainingstep =  1266\n",
      "trainingstep =  1267\n",
      "trainingstep =  1268\n",
      "trainingstep =  1269\n",
      "trainingstep =  1270\n",
      "trainingstep =  1271\n",
      "trainingstep =  1272\n",
      "trainingstep =  1273\n",
      "trainingstep =  1274\n",
      "trainingstep =  1275\n",
      "trainingstep =  1276\n",
      "trainingstep =  1277\n",
      "trainingstep =  1278\n",
      "trainingstep =  1279\n",
      "trainingstep =  1280\n",
      "trainingstep =  1281\n",
      "trainingstep =  1282\n",
      "trainingstep =  1283\n",
      "trainingstep =  1284\n",
      "trainingstep =  1285\n",
      "trainingstep =  1286\n",
      "trainingstep =  1287\n",
      "trainingstep =  1288\n",
      "trainingstep =  1289\n",
      "trainingstep =  1290\n",
      "trainingstep =  1291\n",
      "trainingstep =  1292\n",
      "trainingstep =  1293\n",
      "trainingstep =  1294\n",
      "trainingstep =  1295\n",
      "trainingstep =  1296\n",
      "trainingstep =  1297\n",
      "trainingstep =  1298\n",
      "trainingstep =  1299\n",
      "trainingstep =  1300\n",
      "Step: 1300, Train accuracy: 100.0000%, Cross entropy: 0.005667, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1301\n",
      "trainingstep =  1302\n",
      "trainingstep =  1303\n",
      "trainingstep =  1304\n",
      "trainingstep =  1305\n",
      "trainingstep =  1306\n",
      "trainingstep =  1307\n",
      "trainingstep =  1308\n",
      "trainingstep =  1309\n",
      "trainingstep =  1310\n",
      "trainingstep =  1311\n",
      "trainingstep =  1312\n",
      "trainingstep =  1313\n",
      "trainingstep =  1314\n",
      "trainingstep =  1315\n",
      "trainingstep =  1316\n",
      "trainingstep =  1317\n",
      "trainingstep =  1318\n",
      "trainingstep =  1319\n",
      "trainingstep =  1320\n",
      "trainingstep =  1321\n",
      "trainingstep =  1322\n",
      "trainingstep =  1323\n",
      "trainingstep =  1324\n",
      "trainingstep =  1325\n",
      "trainingstep =  1326\n",
      "trainingstep =  1327\n",
      "trainingstep =  1328\n",
      "trainingstep =  1329\n",
      "trainingstep =  1330\n",
      "trainingstep =  1331\n",
      "trainingstep =  1332\n",
      "trainingstep =  1333\n",
      "trainingstep =  1334\n",
      "trainingstep =  1335\n",
      "trainingstep =  1336\n",
      "trainingstep =  1337\n",
      "trainingstep =  1338\n",
      "trainingstep =  1339\n",
      "trainingstep =  1340\n",
      "trainingstep =  1341\n",
      "trainingstep =  1342\n",
      "trainingstep =  1343\n",
      "trainingstep =  1344\n",
      "trainingstep =  1345\n",
      "trainingstep =  1346\n",
      "trainingstep =  1347\n",
      "trainingstep =  1348\n",
      "trainingstep =  1349\n",
      "trainingstep =  1350\n",
      "trainingstep =  1351\n",
      "trainingstep =  1352\n",
      "trainingstep =  1353\n",
      "trainingstep =  1354\n",
      "trainingstep =  1355\n",
      "trainingstep =  1356\n",
      "trainingstep =  1357\n",
      "trainingstep =  1358\n",
      "trainingstep =  1359\n",
      "trainingstep =  1360\n",
      "trainingstep =  1361\n",
      "trainingstep =  1362\n",
      "trainingstep =  1363\n",
      "trainingstep =  1364\n",
      "trainingstep =  1365\n",
      "trainingstep =  1366\n",
      "trainingstep =  1367\n",
      "trainingstep =  1368\n",
      "trainingstep =  1369\n",
      "trainingstep =  1370\n",
      "trainingstep =  1371\n",
      "trainingstep =  1372\n",
      "trainingstep =  1373\n",
      "trainingstep =  1374\n",
      "trainingstep =  1375\n",
      "trainingstep =  1376\n",
      "trainingstep =  1377\n",
      "trainingstep =  1378\n",
      "trainingstep =  1379\n",
      "trainingstep =  1380\n",
      "trainingstep =  1381\n",
      "trainingstep =  1382\n",
      "trainingstep =  1383\n",
      "trainingstep =  1384\n",
      "trainingstep =  1385\n",
      "trainingstep =  1386\n",
      "trainingstep =  1387\n",
      "trainingstep =  1388\n",
      "trainingstep =  1389\n",
      "trainingstep =  1390\n",
      "trainingstep =  1391\n",
      "trainingstep =  1392\n",
      "trainingstep =  1393\n",
      "trainingstep =  1394\n",
      "trainingstep =  1395\n",
      "trainingstep =  1396\n",
      "trainingstep =  1397\n",
      "trainingstep =  1398\n",
      "trainingstep =  1399\n",
      "trainingstep =  1400\n",
      "Step: 1400, Train accuracy: 100.0000%, Cross entropy: 0.019657, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1401\n",
      "trainingstep =  1402\n",
      "trainingstep =  1403\n",
      "trainingstep =  1404\n",
      "trainingstep =  1405\n",
      "trainingstep =  1406\n",
      "trainingstep =  1407\n",
      "trainingstep =  1408\n",
      "trainingstep =  1409\n",
      "trainingstep =  1410\n",
      "trainingstep =  1411\n",
      "trainingstep =  1412\n",
      "trainingstep =  1413\n",
      "trainingstep =  1414\n",
      "trainingstep =  1415\n",
      "trainingstep =  1416\n",
      "trainingstep =  1417\n",
      "trainingstep =  1418\n",
      "trainingstep =  1419\n",
      "trainingstep =  1420\n",
      "trainingstep =  1421\n",
      "trainingstep =  1422\n",
      "trainingstep =  1423\n",
      "trainingstep =  1424\n",
      "trainingstep =  1425\n",
      "trainingstep =  1426\n",
      "trainingstep =  1427\n",
      "trainingstep =  1428\n",
      "trainingstep =  1429\n",
      "trainingstep =  1430\n",
      "trainingstep =  1431\n",
      "trainingstep =  1432\n",
      "trainingstep =  1433\n",
      "trainingstep =  1434\n",
      "trainingstep =  1435\n",
      "trainingstep =  1436\n",
      "trainingstep =  1437\n",
      "trainingstep =  1438\n",
      "trainingstep =  1439\n",
      "trainingstep =  1440\n",
      "trainingstep =  1441\n",
      "trainingstep =  1442\n",
      "trainingstep =  1443\n",
      "trainingstep =  1444\n",
      "trainingstep =  1445\n",
      "trainingstep =  1446\n",
      "trainingstep =  1447\n",
      "trainingstep =  1448\n",
      "trainingstep =  1449\n",
      "trainingstep =  1450\n",
      "trainingstep =  1451\n",
      "trainingstep =  1452\n",
      "trainingstep =  1453\n",
      "trainingstep =  1454\n",
      "trainingstep =  1455\n",
      "trainingstep =  1456\n",
      "trainingstep =  1457\n",
      "trainingstep =  1458\n",
      "trainingstep =  1459\n",
      "trainingstep =  1460\n",
      "trainingstep =  1461\n",
      "trainingstep =  1462\n",
      "trainingstep =  1463\n",
      "trainingstep =  1464\n",
      "trainingstep =  1465\n",
      "trainingstep =  1466\n",
      "trainingstep =  1467\n",
      "trainingstep =  1468\n",
      "trainingstep =  1469\n",
      "trainingstep =  1470\n",
      "trainingstep =  1471\n",
      "trainingstep =  1472\n",
      "trainingstep =  1473\n",
      "trainingstep =  1474\n",
      "trainingstep =  1475\n",
      "trainingstep =  1476\n",
      "trainingstep =  1477\n",
      "trainingstep =  1478\n",
      "trainingstep =  1479\n",
      "trainingstep =  1480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  1481\n",
      "trainingstep =  1482\n",
      "trainingstep =  1483\n",
      "trainingstep =  1484\n",
      "trainingstep =  1485\n",
      "trainingstep =  1486\n",
      "trainingstep =  1487\n",
      "trainingstep =  1488\n",
      "trainingstep =  1489\n",
      "trainingstep =  1490\n",
      "trainingstep =  1491\n",
      "trainingstep =  1492\n",
      "trainingstep =  1493\n",
      "trainingstep =  1494\n",
      "trainingstep =  1495\n",
      "trainingstep =  1496\n",
      "trainingstep =  1497\n",
      "trainingstep =  1498\n",
      "trainingstep =  1499\n",
      "trainingstep =  1500\n",
      "Step: 1500, Train accuracy: 100.0000%, Cross entropy: 0.010978, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1501\n",
      "trainingstep =  1502\n",
      "trainingstep =  1503\n",
      "trainingstep =  1504\n",
      "trainingstep =  1505\n",
      "trainingstep =  1506\n",
      "trainingstep =  1507\n",
      "trainingstep =  1508\n",
      "trainingstep =  1509\n",
      "trainingstep =  1510\n",
      "trainingstep =  1511\n",
      "trainingstep =  1512\n",
      "trainingstep =  1513\n",
      "trainingstep =  1514\n",
      "trainingstep =  1515\n",
      "trainingstep =  1516\n",
      "trainingstep =  1517\n",
      "trainingstep =  1518\n",
      "trainingstep =  1519\n",
      "trainingstep =  1520\n",
      "trainingstep =  1521\n",
      "trainingstep =  1522\n",
      "trainingstep =  1523\n",
      "trainingstep =  1524\n",
      "trainingstep =  1525\n",
      "trainingstep =  1526\n",
      "trainingstep =  1527\n",
      "trainingstep =  1528\n",
      "trainingstep =  1529\n",
      "trainingstep =  1530\n",
      "trainingstep =  1531\n",
      "trainingstep =  1532\n",
      "trainingstep =  1533\n",
      "trainingstep =  1534\n",
      "trainingstep =  1535\n",
      "trainingstep =  1536\n",
      "trainingstep =  1537\n",
      "trainingstep =  1538\n",
      "trainingstep =  1539\n",
      "trainingstep =  1540\n",
      "trainingstep =  1541\n",
      "trainingstep =  1542\n",
      "trainingstep =  1543\n",
      "trainingstep =  1544\n",
      "trainingstep =  1545\n",
      "trainingstep =  1546\n",
      "trainingstep =  1547\n",
      "trainingstep =  1548\n",
      "trainingstep =  1549\n",
      "trainingstep =  1550\n",
      "trainingstep =  1551\n",
      "trainingstep =  1552\n",
      "trainingstep =  1553\n",
      "trainingstep =  1554\n",
      "trainingstep =  1555\n",
      "trainingstep =  1556\n",
      "trainingstep =  1557\n",
      "trainingstep =  1558\n",
      "trainingstep =  1559\n",
      "trainingstep =  1560\n",
      "trainingstep =  1561\n",
      "trainingstep =  1562\n",
      "trainingstep =  1563\n",
      "trainingstep =  1564\n",
      "trainingstep =  1565\n",
      "trainingstep =  1566\n",
      "trainingstep =  1567\n",
      "trainingstep =  1568\n",
      "trainingstep =  1569\n",
      "trainingstep =  1570\n",
      "trainingstep =  1571\n",
      "trainingstep =  1572\n",
      "trainingstep =  1573\n",
      "trainingstep =  1574\n",
      "trainingstep =  1575\n",
      "trainingstep =  1576\n",
      "trainingstep =  1577\n",
      "trainingstep =  1578\n",
      "trainingstep =  1579\n",
      "trainingstep =  1580\n",
      "trainingstep =  1581\n",
      "trainingstep =  1582\n",
      "trainingstep =  1583\n",
      "trainingstep =  1584\n",
      "trainingstep =  1585\n",
      "trainingstep =  1586\n",
      "trainingstep =  1587\n",
      "trainingstep =  1588\n",
      "trainingstep =  1589\n",
      "trainingstep =  1590\n",
      "trainingstep =  1591\n",
      "trainingstep =  1592\n",
      "trainingstep =  1593\n",
      "trainingstep =  1594\n",
      "trainingstep =  1595\n",
      "trainingstep =  1596\n",
      "trainingstep =  1597\n",
      "trainingstep =  1598\n",
      "trainingstep =  1599\n",
      "trainingstep =  1600\n",
      "Step: 1600, Train accuracy: 99.0000%, Cross entropy: 0.018637, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1601\n",
      "trainingstep =  1602\n",
      "trainingstep =  1603\n",
      "trainingstep =  1604\n",
      "trainingstep =  1605\n",
      "trainingstep =  1606\n",
      "trainingstep =  1607\n",
      "trainingstep =  1608\n",
      "trainingstep =  1609\n",
      "trainingstep =  1610\n",
      "trainingstep =  1611\n",
      "trainingstep =  1612\n",
      "trainingstep =  1613\n",
      "trainingstep =  1614\n",
      "trainingstep =  1615\n",
      "trainingstep =  1616\n",
      "trainingstep =  1617\n",
      "trainingstep =  1618\n",
      "trainingstep =  1619\n",
      "trainingstep =  1620\n",
      "trainingstep =  1621\n",
      "trainingstep =  1622\n",
      "trainingstep =  1623\n",
      "trainingstep =  1624\n",
      "trainingstep =  1625\n",
      "trainingstep =  1626\n",
      "trainingstep =  1627\n",
      "trainingstep =  1628\n",
      "trainingstep =  1629\n",
      "trainingstep =  1630\n",
      "trainingstep =  1631\n",
      "trainingstep =  1632\n",
      "trainingstep =  1633\n",
      "trainingstep =  1634\n",
      "trainingstep =  1635\n",
      "trainingstep =  1636\n",
      "trainingstep =  1637\n",
      "trainingstep =  1638\n",
      "trainingstep =  1639\n",
      "trainingstep =  1640\n",
      "trainingstep =  1641\n",
      "trainingstep =  1642\n",
      "trainingstep =  1643\n",
      "trainingstep =  1644\n",
      "trainingstep =  1645\n",
      "trainingstep =  1646\n",
      "trainingstep =  1647\n",
      "trainingstep =  1648\n",
      "trainingstep =  1649\n",
      "trainingstep =  1650\n",
      "trainingstep =  1651\n",
      "trainingstep =  1652\n",
      "trainingstep =  1653\n",
      "trainingstep =  1654\n",
      "trainingstep =  1655\n",
      "trainingstep =  1656\n",
      "trainingstep =  1657\n",
      "trainingstep =  1658\n",
      "trainingstep =  1659\n",
      "trainingstep =  1660\n",
      "trainingstep =  1661\n",
      "trainingstep =  1662\n",
      "trainingstep =  1663\n",
      "trainingstep =  1664\n",
      "trainingstep =  1665\n",
      "trainingstep =  1666\n",
      "trainingstep =  1667\n",
      "trainingstep =  1668\n",
      "trainingstep =  1669\n",
      "trainingstep =  1670\n",
      "trainingstep =  1671\n",
      "trainingstep =  1672\n",
      "trainingstep =  1673\n",
      "trainingstep =  1674\n",
      "trainingstep =  1675\n",
      "trainingstep =  1676\n",
      "trainingstep =  1677\n",
      "trainingstep =  1678\n",
      "trainingstep =  1679\n",
      "trainingstep =  1680\n",
      "trainingstep =  1681\n",
      "trainingstep =  1682\n",
      "trainingstep =  1683\n",
      "trainingstep =  1684\n",
      "trainingstep =  1685\n",
      "trainingstep =  1686\n",
      "trainingstep =  1687\n",
      "trainingstep =  1688\n",
      "trainingstep =  1689\n",
      "trainingstep =  1690\n",
      "trainingstep =  1691\n",
      "trainingstep =  1692\n",
      "trainingstep =  1693\n",
      "trainingstep =  1694\n",
      "trainingstep =  1695\n",
      "trainingstep =  1696\n",
      "trainingstep =  1697\n",
      "trainingstep =  1698\n",
      "trainingstep =  1699\n",
      "trainingstep =  1700\n",
      "Step: 1700, Train accuracy: 100.0000%, Cross entropy: 0.007439, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1701\n",
      "trainingstep =  1702\n",
      "trainingstep =  1703\n",
      "trainingstep =  1704\n",
      "trainingstep =  1705\n",
      "trainingstep =  1706\n",
      "trainingstep =  1707\n",
      "trainingstep =  1708\n",
      "trainingstep =  1709\n",
      "trainingstep =  1710\n",
      "trainingstep =  1711\n",
      "trainingstep =  1712\n",
      "trainingstep =  1713\n",
      "trainingstep =  1714\n",
      "trainingstep =  1715\n",
      "trainingstep =  1716\n",
      "trainingstep =  1717\n",
      "trainingstep =  1718\n",
      "trainingstep =  1719\n",
      "trainingstep =  1720\n",
      "trainingstep =  1721\n",
      "trainingstep =  1722\n",
      "trainingstep =  1723\n",
      "trainingstep =  1724\n",
      "trainingstep =  1725\n",
      "trainingstep =  1726\n",
      "trainingstep =  1727\n",
      "trainingstep =  1728\n",
      "trainingstep =  1729\n",
      "trainingstep =  1730\n",
      "trainingstep =  1731\n",
      "trainingstep =  1732\n",
      "trainingstep =  1733\n",
      "trainingstep =  1734\n",
      "trainingstep =  1735\n",
      "trainingstep =  1736\n",
      "trainingstep =  1737\n",
      "trainingstep =  1738\n",
      "trainingstep =  1739\n",
      "trainingstep =  1740\n",
      "trainingstep =  1741\n",
      "trainingstep =  1742\n",
      "trainingstep =  1743\n",
      "trainingstep =  1744\n",
      "trainingstep =  1745\n",
      "trainingstep =  1746\n",
      "trainingstep =  1747\n",
      "trainingstep =  1748\n",
      "trainingstep =  1749\n",
      "trainingstep =  1750\n",
      "trainingstep =  1751\n",
      "trainingstep =  1752\n",
      "trainingstep =  1753\n",
      "trainingstep =  1754\n",
      "trainingstep =  1755\n",
      "trainingstep =  1756\n",
      "trainingstep =  1757\n",
      "trainingstep =  1758\n",
      "trainingstep =  1759\n",
      "trainingstep =  1760\n",
      "trainingstep =  1761\n",
      "trainingstep =  1762\n",
      "trainingstep =  1763\n",
      "trainingstep =  1764\n",
      "trainingstep =  1765\n",
      "trainingstep =  1766\n",
      "trainingstep =  1767\n",
      "trainingstep =  1768\n",
      "trainingstep =  1769\n",
      "trainingstep =  1770\n",
      "trainingstep =  1771\n",
      "trainingstep =  1772\n",
      "trainingstep =  1773\n",
      "trainingstep =  1774\n",
      "trainingstep =  1775\n",
      "trainingstep =  1776\n",
      "trainingstep =  1777\n",
      "trainingstep =  1778\n",
      "trainingstep =  1779\n",
      "trainingstep =  1780\n",
      "trainingstep =  1781\n",
      "trainingstep =  1782\n",
      "trainingstep =  1783\n",
      "trainingstep =  1784\n",
      "trainingstep =  1785\n",
      "trainingstep =  1786\n",
      "trainingstep =  1787\n",
      "trainingstep =  1788\n",
      "trainingstep =  1789\n",
      "trainingstep =  1790\n",
      "trainingstep =  1791\n",
      "trainingstep =  1792\n",
      "trainingstep =  1793\n",
      "trainingstep =  1794\n",
      "trainingstep =  1795\n",
      "trainingstep =  1796\n",
      "trainingstep =  1797\n",
      "trainingstep =  1798\n",
      "trainingstep =  1799\n",
      "trainingstep =  1800\n",
      "Step: 1800, Train accuracy: 100.0000%, Cross entropy: 0.008425, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1801\n",
      "trainingstep =  1802\n",
      "trainingstep =  1803\n",
      "trainingstep =  1804\n",
      "trainingstep =  1805\n",
      "trainingstep =  1806\n",
      "trainingstep =  1807\n",
      "trainingstep =  1808\n",
      "trainingstep =  1809\n",
      "trainingstep =  1810\n",
      "trainingstep =  1811\n",
      "trainingstep =  1812\n",
      "trainingstep =  1813\n",
      "trainingstep =  1814\n",
      "trainingstep =  1815\n",
      "trainingstep =  1816\n",
      "trainingstep =  1817\n",
      "trainingstep =  1818\n",
      "trainingstep =  1819\n",
      "trainingstep =  1820\n",
      "trainingstep =  1821\n",
      "trainingstep =  1822\n",
      "trainingstep =  1823\n",
      "trainingstep =  1824\n",
      "trainingstep =  1825\n",
      "trainingstep =  1826\n",
      "trainingstep =  1827\n",
      "trainingstep =  1828\n",
      "trainingstep =  1829\n",
      "trainingstep =  1830\n",
      "trainingstep =  1831\n",
      "trainingstep =  1832\n",
      "trainingstep =  1833\n",
      "trainingstep =  1834\n",
      "trainingstep =  1835\n",
      "trainingstep =  1836\n",
      "trainingstep =  1837\n",
      "trainingstep =  1838\n",
      "trainingstep =  1839\n",
      "trainingstep =  1840\n",
      "trainingstep =  1841\n",
      "trainingstep =  1842\n",
      "trainingstep =  1843\n",
      "trainingstep =  1844\n",
      "trainingstep =  1845\n",
      "trainingstep =  1846\n",
      "trainingstep =  1847\n",
      "trainingstep =  1848\n",
      "trainingstep =  1849\n",
      "trainingstep =  1850\n",
      "trainingstep =  1851\n",
      "trainingstep =  1852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  1853\n",
      "trainingstep =  1854\n",
      "trainingstep =  1855\n",
      "trainingstep =  1856\n",
      "trainingstep =  1857\n",
      "trainingstep =  1858\n",
      "trainingstep =  1859\n",
      "trainingstep =  1860\n",
      "trainingstep =  1861\n",
      "trainingstep =  1862\n",
      "trainingstep =  1863\n",
      "trainingstep =  1864\n",
      "trainingstep =  1865\n",
      "trainingstep =  1866\n",
      "trainingstep =  1867\n",
      "trainingstep =  1868\n",
      "trainingstep =  1869\n",
      "trainingstep =  1870\n",
      "trainingstep =  1871\n",
      "trainingstep =  1872\n",
      "trainingstep =  1873\n",
      "trainingstep =  1874\n",
      "trainingstep =  1875\n",
      "trainingstep =  1876\n",
      "trainingstep =  1877\n",
      "trainingstep =  1878\n",
      "trainingstep =  1879\n",
      "trainingstep =  1880\n",
      "trainingstep =  1881\n",
      "trainingstep =  1882\n",
      "trainingstep =  1883\n",
      "trainingstep =  1884\n",
      "trainingstep =  1885\n",
      "trainingstep =  1886\n",
      "trainingstep =  1887\n",
      "trainingstep =  1888\n",
      "trainingstep =  1889\n",
      "trainingstep =  1890\n",
      "trainingstep =  1891\n",
      "trainingstep =  1892\n",
      "trainingstep =  1893\n",
      "trainingstep =  1894\n",
      "trainingstep =  1895\n",
      "trainingstep =  1896\n",
      "trainingstep =  1897\n",
      "trainingstep =  1898\n",
      "trainingstep =  1899\n",
      "trainingstep =  1900\n",
      "Step: 1900, Train accuracy: 100.0000%, Cross entropy: 0.003755, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  1901\n",
      "trainingstep =  1902\n",
      "trainingstep =  1903\n",
      "trainingstep =  1904\n",
      "trainingstep =  1905\n",
      "trainingstep =  1906\n",
      "trainingstep =  1907\n",
      "trainingstep =  1908\n",
      "trainingstep =  1909\n",
      "trainingstep =  1910\n",
      "trainingstep =  1911\n",
      "trainingstep =  1912\n",
      "trainingstep =  1913\n",
      "trainingstep =  1914\n",
      "trainingstep =  1915\n",
      "trainingstep =  1916\n",
      "trainingstep =  1917\n",
      "trainingstep =  1918\n",
      "trainingstep =  1919\n",
      "trainingstep =  1920\n",
      "trainingstep =  1921\n",
      "trainingstep =  1922\n",
      "trainingstep =  1923\n",
      "trainingstep =  1924\n",
      "trainingstep =  1925\n",
      "trainingstep =  1926\n",
      "trainingstep =  1927\n",
      "trainingstep =  1928\n",
      "trainingstep =  1929\n",
      "trainingstep =  1930\n",
      "trainingstep =  1931\n",
      "trainingstep =  1932\n",
      "trainingstep =  1933\n",
      "trainingstep =  1934\n",
      "trainingstep =  1935\n",
      "trainingstep =  1936\n",
      "trainingstep =  1937\n",
      "trainingstep =  1938\n",
      "trainingstep =  1939\n",
      "trainingstep =  1940\n",
      "trainingstep =  1941\n",
      "trainingstep =  1942\n",
      "trainingstep =  1943\n",
      "trainingstep =  1944\n",
      "trainingstep =  1945\n",
      "trainingstep =  1946\n",
      "trainingstep =  1947\n",
      "trainingstep =  1948\n",
      "trainingstep =  1949\n",
      "trainingstep =  1950\n",
      "trainingstep =  1951\n",
      "trainingstep =  1952\n",
      "trainingstep =  1953\n",
      "trainingstep =  1954\n",
      "trainingstep =  1955\n",
      "trainingstep =  1956\n",
      "trainingstep =  1957\n",
      "trainingstep =  1958\n",
      "trainingstep =  1959\n",
      "trainingstep =  1960\n",
      "trainingstep =  1961\n",
      "trainingstep =  1962\n",
      "trainingstep =  1963\n",
      "trainingstep =  1964\n",
      "trainingstep =  1965\n",
      "trainingstep =  1966\n",
      "trainingstep =  1967\n",
      "trainingstep =  1968\n",
      "trainingstep =  1969\n",
      "trainingstep =  1970\n",
      "trainingstep =  1971\n",
      "trainingstep =  1972\n",
      "trainingstep =  1973\n",
      "trainingstep =  1974\n",
      "trainingstep =  1975\n",
      "trainingstep =  1976\n",
      "trainingstep =  1977\n",
      "trainingstep =  1978\n",
      "trainingstep =  1979\n",
      "trainingstep =  1980\n",
      "trainingstep =  1981\n",
      "trainingstep =  1982\n",
      "trainingstep =  1983\n",
      "trainingstep =  1984\n",
      "trainingstep =  1985\n",
      "trainingstep =  1986\n",
      "trainingstep =  1987\n",
      "trainingstep =  1988\n",
      "trainingstep =  1989\n",
      "trainingstep =  1990\n",
      "trainingstep =  1991\n",
      "trainingstep =  1992\n",
      "trainingstep =  1993\n",
      "trainingstep =  1994\n",
      "trainingstep =  1995\n",
      "trainingstep =  1996\n",
      "trainingstep =  1997\n",
      "trainingstep =  1998\n",
      "trainingstep =  1999\n",
      "trainingstep =  2000\n",
      "Step: 2000, Train accuracy: 100.0000%, Cross entropy: 0.010295, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2001\n",
      "trainingstep =  2002\n",
      "trainingstep =  2003\n",
      "trainingstep =  2004\n",
      "trainingstep =  2005\n",
      "trainingstep =  2006\n",
      "trainingstep =  2007\n",
      "trainingstep =  2008\n",
      "trainingstep =  2009\n",
      "trainingstep =  2010\n",
      "trainingstep =  2011\n",
      "trainingstep =  2012\n",
      "trainingstep =  2013\n",
      "trainingstep =  2014\n",
      "trainingstep =  2015\n",
      "trainingstep =  2016\n",
      "trainingstep =  2017\n",
      "trainingstep =  2018\n",
      "trainingstep =  2019\n",
      "trainingstep =  2020\n",
      "trainingstep =  2021\n",
      "trainingstep =  2022\n",
      "trainingstep =  2023\n",
      "trainingstep =  2024\n",
      "trainingstep =  2025\n",
      "trainingstep =  2026\n",
      "trainingstep =  2027\n",
      "trainingstep =  2028\n",
      "trainingstep =  2029\n",
      "trainingstep =  2030\n",
      "trainingstep =  2031\n",
      "trainingstep =  2032\n",
      "trainingstep =  2033\n",
      "trainingstep =  2034\n",
      "trainingstep =  2035\n",
      "trainingstep =  2036\n",
      "trainingstep =  2037\n",
      "trainingstep =  2038\n",
      "trainingstep =  2039\n",
      "trainingstep =  2040\n",
      "trainingstep =  2041\n",
      "trainingstep =  2042\n",
      "trainingstep =  2043\n",
      "trainingstep =  2044\n",
      "trainingstep =  2045\n",
      "trainingstep =  2046\n",
      "trainingstep =  2047\n",
      "trainingstep =  2048\n",
      "trainingstep =  2049\n",
      "trainingstep =  2050\n",
      "trainingstep =  2051\n",
      "trainingstep =  2052\n",
      "trainingstep =  2053\n",
      "trainingstep =  2054\n",
      "trainingstep =  2055\n",
      "trainingstep =  2056\n",
      "trainingstep =  2057\n",
      "trainingstep =  2058\n",
      "trainingstep =  2059\n",
      "trainingstep =  2060\n",
      "trainingstep =  2061\n",
      "trainingstep =  2062\n",
      "trainingstep =  2063\n",
      "trainingstep =  2064\n",
      "trainingstep =  2065\n",
      "trainingstep =  2066\n",
      "trainingstep =  2067\n",
      "trainingstep =  2068\n",
      "trainingstep =  2069\n",
      "trainingstep =  2070\n",
      "trainingstep =  2071\n",
      "trainingstep =  2072\n",
      "trainingstep =  2073\n",
      "trainingstep =  2074\n",
      "trainingstep =  2075\n",
      "trainingstep =  2076\n",
      "trainingstep =  2077\n",
      "trainingstep =  2078\n",
      "trainingstep =  2079\n",
      "trainingstep =  2080\n",
      "trainingstep =  2081\n",
      "trainingstep =  2082\n",
      "trainingstep =  2083\n",
      "trainingstep =  2084\n",
      "trainingstep =  2085\n",
      "trainingstep =  2086\n",
      "trainingstep =  2087\n",
      "trainingstep =  2088\n",
      "trainingstep =  2089\n",
      "trainingstep =  2090\n",
      "trainingstep =  2091\n",
      "trainingstep =  2092\n",
      "trainingstep =  2093\n",
      "trainingstep =  2094\n",
      "trainingstep =  2095\n",
      "trainingstep =  2096\n",
      "trainingstep =  2097\n",
      "trainingstep =  2098\n",
      "trainingstep =  2099\n",
      "trainingstep =  2100\n",
      "Step: 2100, Train accuracy: 100.0000%, Cross entropy: 0.010022, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2101\n",
      "trainingstep =  2102\n",
      "trainingstep =  2103\n",
      "trainingstep =  2104\n",
      "trainingstep =  2105\n",
      "trainingstep =  2106\n",
      "trainingstep =  2107\n",
      "trainingstep =  2108\n",
      "trainingstep =  2109\n",
      "trainingstep =  2110\n",
      "trainingstep =  2111\n",
      "trainingstep =  2112\n",
      "trainingstep =  2113\n",
      "trainingstep =  2114\n",
      "trainingstep =  2115\n",
      "trainingstep =  2116\n",
      "trainingstep =  2117\n",
      "trainingstep =  2118\n",
      "trainingstep =  2119\n",
      "trainingstep =  2120\n",
      "trainingstep =  2121\n",
      "trainingstep =  2122\n",
      "trainingstep =  2123\n",
      "trainingstep =  2124\n",
      "trainingstep =  2125\n",
      "trainingstep =  2126\n",
      "trainingstep =  2127\n",
      "trainingstep =  2128\n",
      "trainingstep =  2129\n",
      "trainingstep =  2130\n",
      "trainingstep =  2131\n",
      "trainingstep =  2132\n",
      "trainingstep =  2133\n",
      "trainingstep =  2134\n",
      "trainingstep =  2135\n",
      "trainingstep =  2136\n",
      "trainingstep =  2137\n",
      "trainingstep =  2138\n",
      "trainingstep =  2139\n",
      "trainingstep =  2140\n",
      "trainingstep =  2141\n",
      "trainingstep =  2142\n",
      "trainingstep =  2143\n",
      "trainingstep =  2144\n",
      "trainingstep =  2145\n",
      "trainingstep =  2146\n",
      "trainingstep =  2147\n",
      "trainingstep =  2148\n",
      "trainingstep =  2149\n",
      "trainingstep =  2150\n",
      "trainingstep =  2151\n",
      "trainingstep =  2152\n",
      "trainingstep =  2153\n",
      "trainingstep =  2154\n",
      "trainingstep =  2155\n",
      "trainingstep =  2156\n",
      "trainingstep =  2157\n",
      "trainingstep =  2158\n",
      "trainingstep =  2159\n",
      "trainingstep =  2160\n",
      "trainingstep =  2161\n",
      "trainingstep =  2162\n",
      "trainingstep =  2163\n",
      "trainingstep =  2164\n",
      "trainingstep =  2165\n",
      "trainingstep =  2166\n",
      "trainingstep =  2167\n",
      "trainingstep =  2168\n",
      "trainingstep =  2169\n",
      "trainingstep =  2170\n",
      "trainingstep =  2171\n",
      "trainingstep =  2172\n",
      "trainingstep =  2173\n",
      "trainingstep =  2174\n",
      "trainingstep =  2175\n",
      "trainingstep =  2176\n",
      "trainingstep =  2177\n",
      "trainingstep =  2178\n",
      "trainingstep =  2179\n",
      "trainingstep =  2180\n",
      "trainingstep =  2181\n",
      "trainingstep =  2182\n",
      "trainingstep =  2183\n",
      "trainingstep =  2184\n",
      "trainingstep =  2185\n",
      "trainingstep =  2186\n",
      "trainingstep =  2187\n",
      "trainingstep =  2188\n",
      "trainingstep =  2189\n",
      "trainingstep =  2190\n",
      "trainingstep =  2191\n",
      "trainingstep =  2192\n",
      "trainingstep =  2193\n",
      "trainingstep =  2194\n",
      "trainingstep =  2195\n",
      "trainingstep =  2196\n",
      "trainingstep =  2197\n",
      "trainingstep =  2198\n",
      "trainingstep =  2199\n",
      "trainingstep =  2200\n",
      "Step: 2200, Train accuracy: 100.0000%, Cross entropy: 0.009067, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2201\n",
      "trainingstep =  2202\n",
      "trainingstep =  2203\n",
      "trainingstep =  2204\n",
      "trainingstep =  2205\n",
      "trainingstep =  2206\n",
      "trainingstep =  2207\n",
      "trainingstep =  2208\n",
      "trainingstep =  2209\n",
      "trainingstep =  2210\n",
      "trainingstep =  2211\n",
      "trainingstep =  2212\n",
      "trainingstep =  2213\n",
      "trainingstep =  2214\n",
      "trainingstep =  2215\n",
      "trainingstep =  2216\n",
      "trainingstep =  2217\n",
      "trainingstep =  2218\n",
      "trainingstep =  2219\n",
      "trainingstep =  2220\n",
      "trainingstep =  2221\n",
      "trainingstep =  2222\n",
      "trainingstep =  2223\n",
      "trainingstep =  2224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  2225\n",
      "trainingstep =  2226\n",
      "trainingstep =  2227\n",
      "trainingstep =  2228\n",
      "trainingstep =  2229\n",
      "trainingstep =  2230\n",
      "trainingstep =  2231\n",
      "trainingstep =  2232\n",
      "trainingstep =  2233\n",
      "trainingstep =  2234\n",
      "trainingstep =  2235\n",
      "trainingstep =  2236\n",
      "trainingstep =  2237\n",
      "trainingstep =  2238\n",
      "trainingstep =  2239\n",
      "trainingstep =  2240\n",
      "trainingstep =  2241\n",
      "trainingstep =  2242\n",
      "trainingstep =  2243\n",
      "trainingstep =  2244\n",
      "trainingstep =  2245\n",
      "trainingstep =  2246\n",
      "trainingstep =  2247\n",
      "trainingstep =  2248\n",
      "trainingstep =  2249\n",
      "trainingstep =  2250\n",
      "trainingstep =  2251\n",
      "trainingstep =  2252\n",
      "trainingstep =  2253\n",
      "trainingstep =  2254\n",
      "trainingstep =  2255\n",
      "trainingstep =  2256\n",
      "trainingstep =  2257\n",
      "trainingstep =  2258\n",
      "trainingstep =  2259\n",
      "trainingstep =  2260\n",
      "trainingstep =  2261\n",
      "trainingstep =  2262\n",
      "trainingstep =  2263\n",
      "trainingstep =  2264\n",
      "trainingstep =  2265\n",
      "trainingstep =  2266\n",
      "trainingstep =  2267\n",
      "trainingstep =  2268\n",
      "trainingstep =  2269\n",
      "trainingstep =  2270\n",
      "trainingstep =  2271\n",
      "trainingstep =  2272\n",
      "trainingstep =  2273\n",
      "trainingstep =  2274\n",
      "trainingstep =  2275\n",
      "trainingstep =  2276\n",
      "trainingstep =  2277\n",
      "trainingstep =  2278\n",
      "trainingstep =  2279\n",
      "trainingstep =  2280\n",
      "trainingstep =  2281\n",
      "trainingstep =  2282\n",
      "trainingstep =  2283\n",
      "trainingstep =  2284\n",
      "trainingstep =  2285\n",
      "trainingstep =  2286\n",
      "trainingstep =  2287\n",
      "trainingstep =  2288\n",
      "trainingstep =  2289\n",
      "trainingstep =  2290\n",
      "trainingstep =  2291\n",
      "trainingstep =  2292\n",
      "trainingstep =  2293\n",
      "trainingstep =  2294\n",
      "trainingstep =  2295\n",
      "trainingstep =  2296\n",
      "trainingstep =  2297\n",
      "trainingstep =  2298\n",
      "trainingstep =  2299\n",
      "trainingstep =  2300\n",
      "Step: 2300, Train accuracy: 100.0000%, Cross entropy: 0.004493, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2301\n",
      "trainingstep =  2302\n",
      "trainingstep =  2303\n",
      "trainingstep =  2304\n",
      "trainingstep =  2305\n",
      "trainingstep =  2306\n",
      "trainingstep =  2307\n",
      "trainingstep =  2308\n",
      "trainingstep =  2309\n",
      "trainingstep =  2310\n",
      "trainingstep =  2311\n",
      "trainingstep =  2312\n",
      "trainingstep =  2313\n",
      "trainingstep =  2314\n",
      "trainingstep =  2315\n",
      "trainingstep =  2316\n",
      "trainingstep =  2317\n",
      "trainingstep =  2318\n",
      "trainingstep =  2319\n",
      "trainingstep =  2320\n",
      "trainingstep =  2321\n",
      "trainingstep =  2322\n",
      "trainingstep =  2323\n",
      "trainingstep =  2324\n",
      "trainingstep =  2325\n",
      "trainingstep =  2326\n",
      "trainingstep =  2327\n",
      "trainingstep =  2328\n",
      "trainingstep =  2329\n",
      "trainingstep =  2330\n",
      "trainingstep =  2331\n",
      "trainingstep =  2332\n",
      "trainingstep =  2333\n",
      "trainingstep =  2334\n",
      "trainingstep =  2335\n",
      "trainingstep =  2336\n",
      "trainingstep =  2337\n",
      "trainingstep =  2338\n",
      "trainingstep =  2339\n",
      "trainingstep =  2340\n",
      "trainingstep =  2341\n",
      "trainingstep =  2342\n",
      "trainingstep =  2343\n",
      "trainingstep =  2344\n",
      "trainingstep =  2345\n",
      "trainingstep =  2346\n",
      "trainingstep =  2347\n",
      "trainingstep =  2348\n",
      "trainingstep =  2349\n",
      "trainingstep =  2350\n",
      "trainingstep =  2351\n",
      "trainingstep =  2352\n",
      "trainingstep =  2353\n",
      "trainingstep =  2354\n",
      "trainingstep =  2355\n",
      "trainingstep =  2356\n",
      "trainingstep =  2357\n",
      "trainingstep =  2358\n",
      "trainingstep =  2359\n",
      "trainingstep =  2360\n",
      "trainingstep =  2361\n",
      "trainingstep =  2362\n",
      "trainingstep =  2363\n",
      "trainingstep =  2364\n",
      "trainingstep =  2365\n",
      "trainingstep =  2366\n",
      "trainingstep =  2367\n",
      "trainingstep =  2368\n",
      "trainingstep =  2369\n",
      "trainingstep =  2370\n",
      "trainingstep =  2371\n",
      "trainingstep =  2372\n",
      "trainingstep =  2373\n",
      "trainingstep =  2374\n",
      "trainingstep =  2375\n",
      "trainingstep =  2376\n",
      "trainingstep =  2377\n",
      "trainingstep =  2378\n",
      "trainingstep =  2379\n",
      "trainingstep =  2380\n",
      "trainingstep =  2381\n",
      "trainingstep =  2382\n",
      "trainingstep =  2383\n",
      "trainingstep =  2384\n",
      "trainingstep =  2385\n",
      "trainingstep =  2386\n",
      "trainingstep =  2387\n",
      "trainingstep =  2388\n",
      "trainingstep =  2389\n",
      "trainingstep =  2390\n",
      "trainingstep =  2391\n",
      "trainingstep =  2392\n",
      "trainingstep =  2393\n",
      "trainingstep =  2394\n",
      "trainingstep =  2395\n",
      "trainingstep =  2396\n",
      "trainingstep =  2397\n",
      "trainingstep =  2398\n",
      "trainingstep =  2399\n",
      "trainingstep =  2400\n",
      "Step: 2400, Train accuracy: 100.0000%, Cross entropy: 0.005816, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2401\n",
      "trainingstep =  2402\n",
      "trainingstep =  2403\n",
      "trainingstep =  2404\n",
      "trainingstep =  2405\n",
      "trainingstep =  2406\n",
      "trainingstep =  2407\n",
      "trainingstep =  2408\n",
      "trainingstep =  2409\n",
      "trainingstep =  2410\n",
      "trainingstep =  2411\n",
      "trainingstep =  2412\n",
      "trainingstep =  2413\n",
      "trainingstep =  2414\n",
      "trainingstep =  2415\n",
      "trainingstep =  2416\n",
      "trainingstep =  2417\n",
      "trainingstep =  2418\n",
      "trainingstep =  2419\n",
      "trainingstep =  2420\n",
      "trainingstep =  2421\n",
      "trainingstep =  2422\n",
      "trainingstep =  2423\n",
      "trainingstep =  2424\n",
      "trainingstep =  2425\n",
      "trainingstep =  2426\n",
      "trainingstep =  2427\n",
      "trainingstep =  2428\n",
      "trainingstep =  2429\n",
      "trainingstep =  2430\n",
      "trainingstep =  2431\n",
      "trainingstep =  2432\n",
      "trainingstep =  2433\n",
      "trainingstep =  2434\n",
      "trainingstep =  2435\n",
      "trainingstep =  2436\n",
      "trainingstep =  2437\n",
      "trainingstep =  2438\n",
      "trainingstep =  2439\n",
      "trainingstep =  2440\n",
      "trainingstep =  2441\n",
      "trainingstep =  2442\n",
      "trainingstep =  2443\n",
      "trainingstep =  2444\n",
      "trainingstep =  2445\n",
      "trainingstep =  2446\n",
      "trainingstep =  2447\n",
      "trainingstep =  2448\n",
      "trainingstep =  2449\n",
      "trainingstep =  2450\n",
      "trainingstep =  2451\n",
      "trainingstep =  2452\n",
      "trainingstep =  2453\n",
      "trainingstep =  2454\n",
      "trainingstep =  2455\n",
      "trainingstep =  2456\n",
      "trainingstep =  2457\n",
      "trainingstep =  2458\n",
      "trainingstep =  2459\n",
      "trainingstep =  2460\n",
      "trainingstep =  2461\n",
      "trainingstep =  2462\n",
      "trainingstep =  2463\n",
      "trainingstep =  2464\n",
      "trainingstep =  2465\n",
      "trainingstep =  2466\n",
      "trainingstep =  2467\n",
      "trainingstep =  2468\n",
      "trainingstep =  2469\n",
      "trainingstep =  2470\n",
      "trainingstep =  2471\n",
      "trainingstep =  2472\n",
      "trainingstep =  2473\n",
      "trainingstep =  2474\n",
      "trainingstep =  2475\n",
      "trainingstep =  2476\n",
      "trainingstep =  2477\n",
      "trainingstep =  2478\n",
      "trainingstep =  2479\n",
      "trainingstep =  2480\n",
      "trainingstep =  2481\n",
      "trainingstep =  2482\n",
      "trainingstep =  2483\n",
      "trainingstep =  2484\n",
      "trainingstep =  2485\n",
      "trainingstep =  2486\n",
      "trainingstep =  2487\n",
      "trainingstep =  2488\n",
      "trainingstep =  2489\n",
      "trainingstep =  2490\n",
      "trainingstep =  2491\n",
      "trainingstep =  2492\n",
      "trainingstep =  2493\n",
      "trainingstep =  2494\n",
      "trainingstep =  2495\n",
      "trainingstep =  2496\n",
      "trainingstep =  2497\n",
      "trainingstep =  2498\n",
      "trainingstep =  2499\n",
      "trainingstep =  2500\n",
      "Step: 2500, Train accuracy: 100.0000%, Cross entropy: 0.005655, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2501\n",
      "trainingstep =  2502\n",
      "trainingstep =  2503\n",
      "trainingstep =  2504\n",
      "trainingstep =  2505\n",
      "trainingstep =  2506\n",
      "trainingstep =  2507\n",
      "trainingstep =  2508\n",
      "trainingstep =  2509\n",
      "trainingstep =  2510\n",
      "trainingstep =  2511\n",
      "trainingstep =  2512\n",
      "trainingstep =  2513\n",
      "trainingstep =  2514\n",
      "trainingstep =  2515\n",
      "trainingstep =  2516\n",
      "trainingstep =  2517\n",
      "trainingstep =  2518\n",
      "trainingstep =  2519\n",
      "trainingstep =  2520\n",
      "trainingstep =  2521\n",
      "trainingstep =  2522\n",
      "trainingstep =  2523\n",
      "trainingstep =  2524\n",
      "trainingstep =  2525\n",
      "trainingstep =  2526\n",
      "trainingstep =  2527\n",
      "trainingstep =  2528\n",
      "trainingstep =  2529\n",
      "trainingstep =  2530\n",
      "trainingstep =  2531\n",
      "trainingstep =  2532\n",
      "trainingstep =  2533\n",
      "trainingstep =  2534\n",
      "trainingstep =  2535\n",
      "trainingstep =  2536\n",
      "trainingstep =  2537\n",
      "trainingstep =  2538\n",
      "trainingstep =  2539\n",
      "trainingstep =  2540\n",
      "trainingstep =  2541\n",
      "trainingstep =  2542\n",
      "trainingstep =  2543\n",
      "trainingstep =  2544\n",
      "trainingstep =  2545\n",
      "trainingstep =  2546\n",
      "trainingstep =  2547\n",
      "trainingstep =  2548\n",
      "trainingstep =  2549\n",
      "trainingstep =  2550\n",
      "trainingstep =  2551\n",
      "trainingstep =  2552\n",
      "trainingstep =  2553\n",
      "trainingstep =  2554\n",
      "trainingstep =  2555\n",
      "trainingstep =  2556\n",
      "trainingstep =  2557\n",
      "trainingstep =  2558\n",
      "trainingstep =  2559\n",
      "trainingstep =  2560\n",
      "trainingstep =  2561\n",
      "trainingstep =  2562\n",
      "trainingstep =  2563\n",
      "trainingstep =  2564\n",
      "trainingstep =  2565\n",
      "trainingstep =  2566\n",
      "trainingstep =  2567\n",
      "trainingstep =  2568\n",
      "trainingstep =  2569\n",
      "trainingstep =  2570\n",
      "trainingstep =  2571\n",
      "trainingstep =  2572\n",
      "trainingstep =  2573\n",
      "trainingstep =  2574\n",
      "trainingstep =  2575\n",
      "trainingstep =  2576\n",
      "trainingstep =  2577\n",
      "trainingstep =  2578\n",
      "trainingstep =  2579\n",
      "trainingstep =  2580\n",
      "trainingstep =  2581\n",
      "trainingstep =  2582\n",
      "trainingstep =  2583\n",
      "trainingstep =  2584\n",
      "trainingstep =  2585\n",
      "trainingstep =  2586\n",
      "trainingstep =  2587\n",
      "trainingstep =  2588\n",
      "trainingstep =  2589\n",
      "trainingstep =  2590\n",
      "trainingstep =  2591\n",
      "trainingstep =  2592\n",
      "trainingstep =  2593\n",
      "trainingstep =  2594\n",
      "trainingstep =  2595\n",
      "trainingstep =  2596\n",
      "trainingstep =  2597\n",
      "trainingstep =  2598\n",
      "trainingstep =  2599\n",
      "trainingstep =  2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2600, Train accuracy: 100.0000%, Cross entropy: 0.003161, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2601\n",
      "trainingstep =  2602\n",
      "trainingstep =  2603\n",
      "trainingstep =  2604\n",
      "trainingstep =  2605\n",
      "trainingstep =  2606\n",
      "trainingstep =  2607\n",
      "trainingstep =  2608\n",
      "trainingstep =  2609\n",
      "trainingstep =  2610\n",
      "trainingstep =  2611\n",
      "trainingstep =  2612\n",
      "trainingstep =  2613\n",
      "trainingstep =  2614\n",
      "trainingstep =  2615\n",
      "trainingstep =  2616\n",
      "trainingstep =  2617\n",
      "trainingstep =  2618\n",
      "trainingstep =  2619\n",
      "trainingstep =  2620\n",
      "trainingstep =  2621\n",
      "trainingstep =  2622\n",
      "trainingstep =  2623\n",
      "trainingstep =  2624\n",
      "trainingstep =  2625\n",
      "trainingstep =  2626\n",
      "trainingstep =  2627\n",
      "trainingstep =  2628\n",
      "trainingstep =  2629\n",
      "trainingstep =  2630\n",
      "trainingstep =  2631\n",
      "trainingstep =  2632\n",
      "trainingstep =  2633\n",
      "trainingstep =  2634\n",
      "trainingstep =  2635\n",
      "trainingstep =  2636\n",
      "trainingstep =  2637\n",
      "trainingstep =  2638\n",
      "trainingstep =  2639\n",
      "trainingstep =  2640\n",
      "trainingstep =  2641\n",
      "trainingstep =  2642\n",
      "trainingstep =  2643\n",
      "trainingstep =  2644\n",
      "trainingstep =  2645\n",
      "trainingstep =  2646\n",
      "trainingstep =  2647\n",
      "trainingstep =  2648\n",
      "trainingstep =  2649\n",
      "trainingstep =  2650\n",
      "trainingstep =  2651\n",
      "trainingstep =  2652\n",
      "trainingstep =  2653\n",
      "trainingstep =  2654\n",
      "trainingstep =  2655\n",
      "trainingstep =  2656\n",
      "trainingstep =  2657\n",
      "trainingstep =  2658\n",
      "trainingstep =  2659\n",
      "trainingstep =  2660\n",
      "trainingstep =  2661\n",
      "trainingstep =  2662\n",
      "trainingstep =  2663\n",
      "trainingstep =  2664\n",
      "trainingstep =  2665\n",
      "trainingstep =  2666\n",
      "trainingstep =  2667\n",
      "trainingstep =  2668\n",
      "trainingstep =  2669\n",
      "trainingstep =  2670\n",
      "trainingstep =  2671\n",
      "trainingstep =  2672\n",
      "trainingstep =  2673\n",
      "trainingstep =  2674\n",
      "trainingstep =  2675\n",
      "trainingstep =  2676\n",
      "trainingstep =  2677\n",
      "trainingstep =  2678\n",
      "trainingstep =  2679\n",
      "trainingstep =  2680\n",
      "trainingstep =  2681\n",
      "trainingstep =  2682\n",
      "trainingstep =  2683\n",
      "trainingstep =  2684\n",
      "trainingstep =  2685\n",
      "trainingstep =  2686\n",
      "trainingstep =  2687\n",
      "trainingstep =  2688\n",
      "trainingstep =  2689\n",
      "trainingstep =  2690\n",
      "trainingstep =  2691\n",
      "trainingstep =  2692\n",
      "trainingstep =  2693\n",
      "trainingstep =  2694\n",
      "trainingstep =  2695\n",
      "trainingstep =  2696\n",
      "trainingstep =  2697\n",
      "trainingstep =  2698\n",
      "trainingstep =  2699\n",
      "trainingstep =  2700\n",
      "Step: 2700, Train accuracy: 100.0000%, Cross entropy: 0.006363, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2701\n",
      "trainingstep =  2702\n",
      "trainingstep =  2703\n",
      "trainingstep =  2704\n",
      "trainingstep =  2705\n",
      "trainingstep =  2706\n",
      "trainingstep =  2707\n",
      "trainingstep =  2708\n",
      "trainingstep =  2709\n",
      "trainingstep =  2710\n",
      "trainingstep =  2711\n",
      "trainingstep =  2712\n",
      "trainingstep =  2713\n",
      "trainingstep =  2714\n",
      "trainingstep =  2715\n",
      "trainingstep =  2716\n",
      "trainingstep =  2717\n",
      "trainingstep =  2718\n",
      "trainingstep =  2719\n",
      "trainingstep =  2720\n",
      "trainingstep =  2721\n",
      "trainingstep =  2722\n",
      "trainingstep =  2723\n",
      "trainingstep =  2724\n",
      "trainingstep =  2725\n",
      "trainingstep =  2726\n",
      "trainingstep =  2727\n",
      "trainingstep =  2728\n",
      "trainingstep =  2729\n",
      "trainingstep =  2730\n",
      "trainingstep =  2731\n",
      "trainingstep =  2732\n",
      "trainingstep =  2733\n",
      "trainingstep =  2734\n",
      "trainingstep =  2735\n",
      "trainingstep =  2736\n",
      "trainingstep =  2737\n",
      "trainingstep =  2738\n",
      "trainingstep =  2739\n",
      "trainingstep =  2740\n",
      "trainingstep =  2741\n",
      "trainingstep =  2742\n",
      "trainingstep =  2743\n",
      "trainingstep =  2744\n",
      "trainingstep =  2745\n",
      "trainingstep =  2746\n",
      "trainingstep =  2747\n",
      "trainingstep =  2748\n",
      "trainingstep =  2749\n",
      "trainingstep =  2750\n",
      "trainingstep =  2751\n",
      "trainingstep =  2752\n",
      "trainingstep =  2753\n",
      "trainingstep =  2754\n",
      "trainingstep =  2755\n",
      "trainingstep =  2756\n",
      "trainingstep =  2757\n",
      "trainingstep =  2758\n",
      "trainingstep =  2759\n",
      "trainingstep =  2760\n",
      "trainingstep =  2761\n",
      "trainingstep =  2762\n",
      "trainingstep =  2763\n",
      "trainingstep =  2764\n",
      "trainingstep =  2765\n",
      "trainingstep =  2766\n",
      "trainingstep =  2767\n",
      "trainingstep =  2768\n",
      "trainingstep =  2769\n",
      "trainingstep =  2770\n",
      "trainingstep =  2771\n",
      "trainingstep =  2772\n",
      "trainingstep =  2773\n",
      "trainingstep =  2774\n",
      "trainingstep =  2775\n",
      "trainingstep =  2776\n",
      "trainingstep =  2777\n",
      "trainingstep =  2778\n",
      "trainingstep =  2779\n",
      "trainingstep =  2780\n",
      "trainingstep =  2781\n",
      "trainingstep =  2782\n",
      "trainingstep =  2783\n",
      "trainingstep =  2784\n",
      "trainingstep =  2785\n",
      "trainingstep =  2786\n",
      "trainingstep =  2787\n",
      "trainingstep =  2788\n",
      "trainingstep =  2789\n",
      "trainingstep =  2790\n",
      "trainingstep =  2791\n",
      "trainingstep =  2792\n",
      "trainingstep =  2793\n",
      "trainingstep =  2794\n",
      "trainingstep =  2795\n",
      "trainingstep =  2796\n",
      "trainingstep =  2797\n",
      "trainingstep =  2798\n",
      "trainingstep =  2799\n",
      "trainingstep =  2800\n",
      "Step: 2800, Train accuracy: 100.0000%, Cross entropy: 0.007088, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2801\n",
      "trainingstep =  2802\n",
      "trainingstep =  2803\n",
      "trainingstep =  2804\n",
      "trainingstep =  2805\n",
      "trainingstep =  2806\n",
      "trainingstep =  2807\n",
      "trainingstep =  2808\n",
      "trainingstep =  2809\n",
      "trainingstep =  2810\n",
      "trainingstep =  2811\n",
      "trainingstep =  2812\n",
      "trainingstep =  2813\n",
      "trainingstep =  2814\n",
      "trainingstep =  2815\n",
      "trainingstep =  2816\n",
      "trainingstep =  2817\n",
      "trainingstep =  2818\n",
      "trainingstep =  2819\n",
      "trainingstep =  2820\n",
      "trainingstep =  2821\n",
      "trainingstep =  2822\n",
      "trainingstep =  2823\n",
      "trainingstep =  2824\n",
      "trainingstep =  2825\n",
      "trainingstep =  2826\n",
      "trainingstep =  2827\n",
      "trainingstep =  2828\n",
      "trainingstep =  2829\n",
      "trainingstep =  2830\n",
      "trainingstep =  2831\n",
      "trainingstep =  2832\n",
      "trainingstep =  2833\n",
      "trainingstep =  2834\n",
      "trainingstep =  2835\n",
      "trainingstep =  2836\n",
      "trainingstep =  2837\n",
      "trainingstep =  2838\n",
      "trainingstep =  2839\n",
      "trainingstep =  2840\n",
      "trainingstep =  2841\n",
      "trainingstep =  2842\n",
      "trainingstep =  2843\n",
      "trainingstep =  2844\n",
      "trainingstep =  2845\n",
      "trainingstep =  2846\n",
      "trainingstep =  2847\n",
      "trainingstep =  2848\n",
      "trainingstep =  2849\n",
      "trainingstep =  2850\n",
      "trainingstep =  2851\n",
      "trainingstep =  2852\n",
      "trainingstep =  2853\n",
      "trainingstep =  2854\n",
      "trainingstep =  2855\n",
      "trainingstep =  2856\n",
      "trainingstep =  2857\n",
      "trainingstep =  2858\n",
      "trainingstep =  2859\n",
      "trainingstep =  2860\n",
      "trainingstep =  2861\n",
      "trainingstep =  2862\n",
      "trainingstep =  2863\n",
      "trainingstep =  2864\n",
      "trainingstep =  2865\n",
      "trainingstep =  2866\n",
      "trainingstep =  2867\n",
      "trainingstep =  2868\n",
      "trainingstep =  2869\n",
      "trainingstep =  2870\n",
      "trainingstep =  2871\n",
      "trainingstep =  2872\n",
      "trainingstep =  2873\n",
      "trainingstep =  2874\n",
      "trainingstep =  2875\n",
      "trainingstep =  2876\n",
      "trainingstep =  2877\n",
      "trainingstep =  2878\n",
      "trainingstep =  2879\n",
      "trainingstep =  2880\n",
      "trainingstep =  2881\n",
      "trainingstep =  2882\n",
      "trainingstep =  2883\n",
      "trainingstep =  2884\n",
      "trainingstep =  2885\n",
      "trainingstep =  2886\n",
      "trainingstep =  2887\n",
      "trainingstep =  2888\n",
      "trainingstep =  2889\n",
      "trainingstep =  2890\n",
      "trainingstep =  2891\n",
      "trainingstep =  2892\n",
      "trainingstep =  2893\n",
      "trainingstep =  2894\n",
      "trainingstep =  2895\n",
      "trainingstep =  2896\n",
      "trainingstep =  2897\n",
      "trainingstep =  2898\n",
      "trainingstep =  2899\n",
      "trainingstep =  2900\n",
      "Step: 2900, Train accuracy: 100.0000%, Cross entropy: 0.005426, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  2901\n",
      "trainingstep =  2902\n",
      "trainingstep =  2903\n",
      "trainingstep =  2904\n",
      "trainingstep =  2905\n",
      "trainingstep =  2906\n",
      "trainingstep =  2907\n",
      "trainingstep =  2908\n",
      "trainingstep =  2909\n",
      "trainingstep =  2910\n",
      "trainingstep =  2911\n",
      "trainingstep =  2912\n",
      "trainingstep =  2913\n",
      "trainingstep =  2914\n",
      "trainingstep =  2915\n",
      "trainingstep =  2916\n",
      "trainingstep =  2917\n",
      "trainingstep =  2918\n",
      "trainingstep =  2919\n",
      "trainingstep =  2920\n",
      "trainingstep =  2921\n",
      "trainingstep =  2922\n",
      "trainingstep =  2923\n",
      "trainingstep =  2924\n",
      "trainingstep =  2925\n",
      "trainingstep =  2926\n",
      "trainingstep =  2927\n",
      "trainingstep =  2928\n",
      "trainingstep =  2929\n",
      "trainingstep =  2930\n",
      "trainingstep =  2931\n",
      "trainingstep =  2932\n",
      "trainingstep =  2933\n",
      "trainingstep =  2934\n",
      "trainingstep =  2935\n",
      "trainingstep =  2936\n",
      "trainingstep =  2937\n",
      "trainingstep =  2938\n",
      "trainingstep =  2939\n",
      "trainingstep =  2940\n",
      "trainingstep =  2941\n",
      "trainingstep =  2942\n",
      "trainingstep =  2943\n",
      "trainingstep =  2944\n",
      "trainingstep =  2945\n",
      "trainingstep =  2946\n",
      "trainingstep =  2947\n",
      "trainingstep =  2948\n",
      "trainingstep =  2949\n",
      "trainingstep =  2950\n",
      "trainingstep =  2951\n",
      "trainingstep =  2952\n",
      "trainingstep =  2953\n",
      "trainingstep =  2954\n",
      "trainingstep =  2955\n",
      "trainingstep =  2956\n",
      "trainingstep =  2957\n",
      "trainingstep =  2958\n",
      "trainingstep =  2959\n",
      "trainingstep =  2960\n",
      "trainingstep =  2961\n",
      "trainingstep =  2962\n",
      "trainingstep =  2963\n",
      "trainingstep =  2964\n",
      "trainingstep =  2965\n",
      "trainingstep =  2966\n",
      "trainingstep =  2967\n",
      "trainingstep =  2968\n",
      "trainingstep =  2969\n",
      "trainingstep =  2970\n",
      "trainingstep =  2971\n",
      "trainingstep =  2972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  2973\n",
      "trainingstep =  2974\n",
      "trainingstep =  2975\n",
      "trainingstep =  2976\n",
      "trainingstep =  2977\n",
      "trainingstep =  2978\n",
      "trainingstep =  2979\n",
      "trainingstep =  2980\n",
      "trainingstep =  2981\n",
      "trainingstep =  2982\n",
      "trainingstep =  2983\n",
      "trainingstep =  2984\n",
      "trainingstep =  2985\n",
      "trainingstep =  2986\n",
      "trainingstep =  2987\n",
      "trainingstep =  2988\n",
      "trainingstep =  2989\n",
      "trainingstep =  2990\n",
      "trainingstep =  2991\n",
      "trainingstep =  2992\n",
      "trainingstep =  2993\n",
      "trainingstep =  2994\n",
      "trainingstep =  2995\n",
      "trainingstep =  2996\n",
      "trainingstep =  2997\n",
      "trainingstep =  2998\n",
      "trainingstep =  2999\n",
      "trainingstep =  3000\n",
      "Step: 3000, Train accuracy: 100.0000%, Cross entropy: 0.008252, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3001\n",
      "trainingstep =  3002\n",
      "trainingstep =  3003\n",
      "trainingstep =  3004\n",
      "trainingstep =  3005\n",
      "trainingstep =  3006\n",
      "trainingstep =  3007\n",
      "trainingstep =  3008\n",
      "trainingstep =  3009\n",
      "trainingstep =  3010\n",
      "trainingstep =  3011\n",
      "trainingstep =  3012\n",
      "trainingstep =  3013\n",
      "trainingstep =  3014\n",
      "trainingstep =  3015\n",
      "trainingstep =  3016\n",
      "trainingstep =  3017\n",
      "trainingstep =  3018\n",
      "trainingstep =  3019\n",
      "trainingstep =  3020\n",
      "trainingstep =  3021\n",
      "trainingstep =  3022\n",
      "trainingstep =  3023\n",
      "trainingstep =  3024\n",
      "trainingstep =  3025\n",
      "trainingstep =  3026\n",
      "trainingstep =  3027\n",
      "trainingstep =  3028\n",
      "trainingstep =  3029\n",
      "trainingstep =  3030\n",
      "trainingstep =  3031\n",
      "trainingstep =  3032\n",
      "trainingstep =  3033\n",
      "trainingstep =  3034\n",
      "trainingstep =  3035\n",
      "trainingstep =  3036\n",
      "trainingstep =  3037\n",
      "trainingstep =  3038\n",
      "trainingstep =  3039\n",
      "trainingstep =  3040\n",
      "trainingstep =  3041\n",
      "trainingstep =  3042\n",
      "trainingstep =  3043\n",
      "trainingstep =  3044\n",
      "trainingstep =  3045\n",
      "trainingstep =  3046\n",
      "trainingstep =  3047\n",
      "trainingstep =  3048\n",
      "trainingstep =  3049\n",
      "trainingstep =  3050\n",
      "trainingstep =  3051\n",
      "trainingstep =  3052\n",
      "trainingstep =  3053\n",
      "trainingstep =  3054\n",
      "trainingstep =  3055\n",
      "trainingstep =  3056\n",
      "trainingstep =  3057\n",
      "trainingstep =  3058\n",
      "trainingstep =  3059\n",
      "trainingstep =  3060\n",
      "trainingstep =  3061\n",
      "trainingstep =  3062\n",
      "trainingstep =  3063\n",
      "trainingstep =  3064\n",
      "trainingstep =  3065\n",
      "trainingstep =  3066\n",
      "trainingstep =  3067\n",
      "trainingstep =  3068\n",
      "trainingstep =  3069\n",
      "trainingstep =  3070\n",
      "trainingstep =  3071\n",
      "trainingstep =  3072\n",
      "trainingstep =  3073\n",
      "trainingstep =  3074\n",
      "trainingstep =  3075\n",
      "trainingstep =  3076\n",
      "trainingstep =  3077\n",
      "trainingstep =  3078\n",
      "trainingstep =  3079\n",
      "trainingstep =  3080\n",
      "trainingstep =  3081\n",
      "trainingstep =  3082\n",
      "trainingstep =  3083\n",
      "trainingstep =  3084\n",
      "trainingstep =  3085\n",
      "trainingstep =  3086\n",
      "trainingstep =  3087\n",
      "trainingstep =  3088\n",
      "trainingstep =  3089\n",
      "trainingstep =  3090\n",
      "trainingstep =  3091\n",
      "trainingstep =  3092\n",
      "trainingstep =  3093\n",
      "trainingstep =  3094\n",
      "trainingstep =  3095\n",
      "trainingstep =  3096\n",
      "trainingstep =  3097\n",
      "trainingstep =  3098\n",
      "trainingstep =  3099\n",
      "trainingstep =  3100\n",
      "Step: 3100, Train accuracy: 100.0000%, Cross entropy: 0.002708, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3101\n",
      "trainingstep =  3102\n",
      "trainingstep =  3103\n",
      "trainingstep =  3104\n",
      "trainingstep =  3105\n",
      "trainingstep =  3106\n",
      "trainingstep =  3107\n",
      "trainingstep =  3108\n",
      "trainingstep =  3109\n",
      "trainingstep =  3110\n",
      "trainingstep =  3111\n",
      "trainingstep =  3112\n",
      "trainingstep =  3113\n",
      "trainingstep =  3114\n",
      "trainingstep =  3115\n",
      "trainingstep =  3116\n",
      "trainingstep =  3117\n",
      "trainingstep =  3118\n",
      "trainingstep =  3119\n",
      "trainingstep =  3120\n",
      "trainingstep =  3121\n",
      "trainingstep =  3122\n",
      "trainingstep =  3123\n",
      "trainingstep =  3124\n",
      "trainingstep =  3125\n",
      "trainingstep =  3126\n",
      "trainingstep =  3127\n",
      "trainingstep =  3128\n",
      "trainingstep =  3129\n",
      "trainingstep =  3130\n",
      "trainingstep =  3131\n",
      "trainingstep =  3132\n",
      "trainingstep =  3133\n",
      "trainingstep =  3134\n",
      "trainingstep =  3135\n",
      "trainingstep =  3136\n",
      "trainingstep =  3137\n",
      "trainingstep =  3138\n",
      "trainingstep =  3139\n",
      "trainingstep =  3140\n",
      "trainingstep =  3141\n",
      "trainingstep =  3142\n",
      "trainingstep =  3143\n",
      "trainingstep =  3144\n",
      "trainingstep =  3145\n",
      "trainingstep =  3146\n",
      "trainingstep =  3147\n",
      "trainingstep =  3148\n",
      "trainingstep =  3149\n",
      "trainingstep =  3150\n",
      "trainingstep =  3151\n",
      "trainingstep =  3152\n",
      "trainingstep =  3153\n",
      "trainingstep =  3154\n",
      "trainingstep =  3155\n",
      "trainingstep =  3156\n",
      "trainingstep =  3157\n",
      "trainingstep =  3158\n",
      "trainingstep =  3159\n",
      "trainingstep =  3160\n",
      "trainingstep =  3161\n",
      "trainingstep =  3162\n",
      "trainingstep =  3163\n",
      "trainingstep =  3164\n",
      "trainingstep =  3165\n",
      "trainingstep =  3166\n",
      "trainingstep =  3167\n",
      "trainingstep =  3168\n",
      "trainingstep =  3169\n",
      "trainingstep =  3170\n",
      "trainingstep =  3171\n",
      "trainingstep =  3172\n",
      "trainingstep =  3173\n",
      "trainingstep =  3174\n",
      "trainingstep =  3175\n",
      "trainingstep =  3176\n",
      "trainingstep =  3177\n",
      "trainingstep =  3178\n",
      "trainingstep =  3179\n",
      "trainingstep =  3180\n",
      "trainingstep =  3181\n",
      "trainingstep =  3182\n",
      "trainingstep =  3183\n",
      "trainingstep =  3184\n",
      "trainingstep =  3185\n",
      "trainingstep =  3186\n",
      "trainingstep =  3187\n",
      "trainingstep =  3188\n",
      "trainingstep =  3189\n",
      "trainingstep =  3190\n",
      "trainingstep =  3191\n",
      "trainingstep =  3192\n",
      "trainingstep =  3193\n",
      "trainingstep =  3194\n",
      "trainingstep =  3195\n",
      "trainingstep =  3196\n",
      "trainingstep =  3197\n",
      "trainingstep =  3198\n",
      "trainingstep =  3199\n",
      "trainingstep =  3200\n",
      "Step: 3200, Train accuracy: 100.0000%, Cross entropy: 0.003703, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3201\n",
      "trainingstep =  3202\n",
      "trainingstep =  3203\n",
      "trainingstep =  3204\n",
      "trainingstep =  3205\n",
      "trainingstep =  3206\n",
      "trainingstep =  3207\n",
      "trainingstep =  3208\n",
      "trainingstep =  3209\n",
      "trainingstep =  3210\n",
      "trainingstep =  3211\n",
      "trainingstep =  3212\n",
      "trainingstep =  3213\n",
      "trainingstep =  3214\n",
      "trainingstep =  3215\n",
      "trainingstep =  3216\n",
      "trainingstep =  3217\n",
      "trainingstep =  3218\n",
      "trainingstep =  3219\n",
      "trainingstep =  3220\n",
      "trainingstep =  3221\n",
      "trainingstep =  3222\n",
      "trainingstep =  3223\n",
      "trainingstep =  3224\n",
      "trainingstep =  3225\n",
      "trainingstep =  3226\n",
      "trainingstep =  3227\n",
      "trainingstep =  3228\n",
      "trainingstep =  3229\n",
      "trainingstep =  3230\n",
      "trainingstep =  3231\n",
      "trainingstep =  3232\n",
      "trainingstep =  3233\n",
      "trainingstep =  3234\n",
      "trainingstep =  3235\n",
      "trainingstep =  3236\n",
      "trainingstep =  3237\n",
      "trainingstep =  3238\n",
      "trainingstep =  3239\n",
      "trainingstep =  3240\n",
      "trainingstep =  3241\n",
      "trainingstep =  3242\n",
      "trainingstep =  3243\n",
      "trainingstep =  3244\n",
      "trainingstep =  3245\n",
      "trainingstep =  3246\n",
      "trainingstep =  3247\n",
      "trainingstep =  3248\n",
      "trainingstep =  3249\n",
      "trainingstep =  3250\n",
      "trainingstep =  3251\n",
      "trainingstep =  3252\n",
      "trainingstep =  3253\n",
      "trainingstep =  3254\n",
      "trainingstep =  3255\n",
      "trainingstep =  3256\n",
      "trainingstep =  3257\n",
      "trainingstep =  3258\n",
      "trainingstep =  3259\n",
      "trainingstep =  3260\n",
      "trainingstep =  3261\n",
      "trainingstep =  3262\n",
      "trainingstep =  3263\n",
      "trainingstep =  3264\n",
      "trainingstep =  3265\n",
      "trainingstep =  3266\n",
      "trainingstep =  3267\n",
      "trainingstep =  3268\n",
      "trainingstep =  3269\n",
      "trainingstep =  3270\n",
      "trainingstep =  3271\n",
      "trainingstep =  3272\n",
      "trainingstep =  3273\n",
      "trainingstep =  3274\n",
      "trainingstep =  3275\n",
      "trainingstep =  3276\n",
      "trainingstep =  3277\n",
      "trainingstep =  3278\n",
      "trainingstep =  3279\n",
      "trainingstep =  3280\n",
      "trainingstep =  3281\n",
      "trainingstep =  3282\n",
      "trainingstep =  3283\n",
      "trainingstep =  3284\n",
      "trainingstep =  3285\n",
      "trainingstep =  3286\n",
      "trainingstep =  3287\n",
      "trainingstep =  3288\n",
      "trainingstep =  3289\n",
      "trainingstep =  3290\n",
      "trainingstep =  3291\n",
      "trainingstep =  3292\n",
      "trainingstep =  3293\n",
      "trainingstep =  3294\n",
      "trainingstep =  3295\n",
      "trainingstep =  3296\n",
      "trainingstep =  3297\n",
      "trainingstep =  3298\n",
      "trainingstep =  3299\n",
      "trainingstep =  3300\n",
      "Step: 3300, Train accuracy: 100.0000%, Cross entropy: 0.002748, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3301\n",
      "trainingstep =  3302\n",
      "trainingstep =  3303\n",
      "trainingstep =  3304\n",
      "trainingstep =  3305\n",
      "trainingstep =  3306\n",
      "trainingstep =  3307\n",
      "trainingstep =  3308\n",
      "trainingstep =  3309\n",
      "trainingstep =  3310\n",
      "trainingstep =  3311\n",
      "trainingstep =  3312\n",
      "trainingstep =  3313\n",
      "trainingstep =  3314\n",
      "trainingstep =  3315\n",
      "trainingstep =  3316\n",
      "trainingstep =  3317\n",
      "trainingstep =  3318\n",
      "trainingstep =  3319\n",
      "trainingstep =  3320\n",
      "trainingstep =  3321\n",
      "trainingstep =  3322\n",
      "trainingstep =  3323\n",
      "trainingstep =  3324\n",
      "trainingstep =  3325\n",
      "trainingstep =  3326\n",
      "trainingstep =  3327\n",
      "trainingstep =  3328\n",
      "trainingstep =  3329\n",
      "trainingstep =  3330\n",
      "trainingstep =  3331\n",
      "trainingstep =  3332\n",
      "trainingstep =  3333\n",
      "trainingstep =  3334\n",
      "trainingstep =  3335\n",
      "trainingstep =  3336\n",
      "trainingstep =  3337\n",
      "trainingstep =  3338\n",
      "trainingstep =  3339\n",
      "trainingstep =  3340\n",
      "trainingstep =  3341\n",
      "trainingstep =  3342\n",
      "trainingstep =  3343\n",
      "trainingstep =  3344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  3345\n",
      "trainingstep =  3346\n",
      "trainingstep =  3347\n",
      "trainingstep =  3348\n",
      "trainingstep =  3349\n",
      "trainingstep =  3350\n",
      "trainingstep =  3351\n",
      "trainingstep =  3352\n",
      "trainingstep =  3353\n",
      "trainingstep =  3354\n",
      "trainingstep =  3355\n",
      "trainingstep =  3356\n",
      "trainingstep =  3357\n",
      "trainingstep =  3358\n",
      "trainingstep =  3359\n",
      "trainingstep =  3360\n",
      "trainingstep =  3361\n",
      "trainingstep =  3362\n",
      "trainingstep =  3363\n",
      "trainingstep =  3364\n",
      "trainingstep =  3365\n",
      "trainingstep =  3366\n",
      "trainingstep =  3367\n",
      "trainingstep =  3368\n",
      "trainingstep =  3369\n",
      "trainingstep =  3370\n",
      "trainingstep =  3371\n",
      "trainingstep =  3372\n",
      "trainingstep =  3373\n",
      "trainingstep =  3374\n",
      "trainingstep =  3375\n",
      "trainingstep =  3376\n",
      "trainingstep =  3377\n",
      "trainingstep =  3378\n",
      "trainingstep =  3379\n",
      "trainingstep =  3380\n",
      "trainingstep =  3381\n",
      "trainingstep =  3382\n",
      "trainingstep =  3383\n",
      "trainingstep =  3384\n",
      "trainingstep =  3385\n",
      "trainingstep =  3386\n",
      "trainingstep =  3387\n",
      "trainingstep =  3388\n",
      "trainingstep =  3389\n",
      "trainingstep =  3390\n",
      "trainingstep =  3391\n",
      "trainingstep =  3392\n",
      "trainingstep =  3393\n",
      "trainingstep =  3394\n",
      "trainingstep =  3395\n",
      "trainingstep =  3396\n",
      "trainingstep =  3397\n",
      "trainingstep =  3398\n",
      "trainingstep =  3399\n",
      "trainingstep =  3400\n",
      "Step: 3400, Train accuracy: 100.0000%, Cross entropy: 0.005210, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3401\n",
      "trainingstep =  3402\n",
      "trainingstep =  3403\n",
      "trainingstep =  3404\n",
      "trainingstep =  3405\n",
      "trainingstep =  3406\n",
      "trainingstep =  3407\n",
      "trainingstep =  3408\n",
      "trainingstep =  3409\n",
      "trainingstep =  3410\n",
      "trainingstep =  3411\n",
      "trainingstep =  3412\n",
      "trainingstep =  3413\n",
      "trainingstep =  3414\n",
      "trainingstep =  3415\n",
      "trainingstep =  3416\n",
      "trainingstep =  3417\n",
      "trainingstep =  3418\n",
      "trainingstep =  3419\n",
      "trainingstep =  3420\n",
      "trainingstep =  3421\n",
      "trainingstep =  3422\n",
      "trainingstep =  3423\n",
      "trainingstep =  3424\n",
      "trainingstep =  3425\n",
      "trainingstep =  3426\n",
      "trainingstep =  3427\n",
      "trainingstep =  3428\n",
      "trainingstep =  3429\n",
      "trainingstep =  3430\n",
      "trainingstep =  3431\n",
      "trainingstep =  3432\n",
      "trainingstep =  3433\n",
      "trainingstep =  3434\n",
      "trainingstep =  3435\n",
      "trainingstep =  3436\n",
      "trainingstep =  3437\n",
      "trainingstep =  3438\n",
      "trainingstep =  3439\n",
      "trainingstep =  3440\n",
      "trainingstep =  3441\n",
      "trainingstep =  3442\n",
      "trainingstep =  3443\n",
      "trainingstep =  3444\n",
      "trainingstep =  3445\n",
      "trainingstep =  3446\n",
      "trainingstep =  3447\n",
      "trainingstep =  3448\n",
      "trainingstep =  3449\n",
      "trainingstep =  3450\n",
      "trainingstep =  3451\n",
      "trainingstep =  3452\n",
      "trainingstep =  3453\n",
      "trainingstep =  3454\n",
      "trainingstep =  3455\n",
      "trainingstep =  3456\n",
      "trainingstep =  3457\n",
      "trainingstep =  3458\n",
      "trainingstep =  3459\n",
      "trainingstep =  3460\n",
      "trainingstep =  3461\n",
      "trainingstep =  3462\n",
      "trainingstep =  3463\n",
      "trainingstep =  3464\n",
      "trainingstep =  3465\n",
      "trainingstep =  3466\n",
      "trainingstep =  3467\n",
      "trainingstep =  3468\n",
      "trainingstep =  3469\n",
      "trainingstep =  3470\n",
      "trainingstep =  3471\n",
      "trainingstep =  3472\n",
      "trainingstep =  3473\n",
      "trainingstep =  3474\n",
      "trainingstep =  3475\n",
      "trainingstep =  3476\n",
      "trainingstep =  3477\n",
      "trainingstep =  3478\n",
      "trainingstep =  3479\n",
      "trainingstep =  3480\n",
      "trainingstep =  3481\n",
      "trainingstep =  3482\n",
      "trainingstep =  3483\n",
      "trainingstep =  3484\n",
      "trainingstep =  3485\n",
      "trainingstep =  3486\n",
      "trainingstep =  3487\n",
      "trainingstep =  3488\n",
      "trainingstep =  3489\n",
      "trainingstep =  3490\n",
      "trainingstep =  3491\n",
      "trainingstep =  3492\n",
      "trainingstep =  3493\n",
      "trainingstep =  3494\n",
      "trainingstep =  3495\n",
      "trainingstep =  3496\n",
      "trainingstep =  3497\n",
      "trainingstep =  3498\n",
      "trainingstep =  3499\n",
      "trainingstep =  3500\n",
      "Step: 3500, Train accuracy: 100.0000%, Cross entropy: 0.003656, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3501\n",
      "trainingstep =  3502\n",
      "trainingstep =  3503\n",
      "trainingstep =  3504\n",
      "trainingstep =  3505\n",
      "trainingstep =  3506\n",
      "trainingstep =  3507\n",
      "trainingstep =  3508\n",
      "trainingstep =  3509\n",
      "trainingstep =  3510\n",
      "trainingstep =  3511\n",
      "trainingstep =  3512\n",
      "trainingstep =  3513\n",
      "trainingstep =  3514\n",
      "trainingstep =  3515\n",
      "trainingstep =  3516\n",
      "trainingstep =  3517\n",
      "trainingstep =  3518\n",
      "trainingstep =  3519\n",
      "trainingstep =  3520\n",
      "trainingstep =  3521\n",
      "trainingstep =  3522\n",
      "trainingstep =  3523\n",
      "trainingstep =  3524\n",
      "trainingstep =  3525\n",
      "trainingstep =  3526\n",
      "trainingstep =  3527\n",
      "trainingstep =  3528\n",
      "trainingstep =  3529\n",
      "trainingstep =  3530\n",
      "trainingstep =  3531\n",
      "trainingstep =  3532\n",
      "trainingstep =  3533\n",
      "trainingstep =  3534\n",
      "trainingstep =  3535\n",
      "trainingstep =  3536\n",
      "trainingstep =  3537\n",
      "trainingstep =  3538\n",
      "trainingstep =  3539\n",
      "trainingstep =  3540\n",
      "trainingstep =  3541\n",
      "trainingstep =  3542\n",
      "trainingstep =  3543\n",
      "trainingstep =  3544\n",
      "trainingstep =  3545\n",
      "trainingstep =  3546\n",
      "trainingstep =  3547\n",
      "trainingstep =  3548\n",
      "trainingstep =  3549\n",
      "trainingstep =  3550\n",
      "trainingstep =  3551\n",
      "trainingstep =  3552\n",
      "trainingstep =  3553\n",
      "trainingstep =  3554\n",
      "trainingstep =  3555\n",
      "trainingstep =  3556\n",
      "trainingstep =  3557\n",
      "trainingstep =  3558\n",
      "trainingstep =  3559\n",
      "trainingstep =  3560\n",
      "trainingstep =  3561\n",
      "trainingstep =  3562\n",
      "trainingstep =  3563\n",
      "trainingstep =  3564\n",
      "trainingstep =  3565\n",
      "trainingstep =  3566\n",
      "trainingstep =  3567\n",
      "trainingstep =  3568\n",
      "trainingstep =  3569\n",
      "trainingstep =  3570\n",
      "trainingstep =  3571\n",
      "trainingstep =  3572\n",
      "trainingstep =  3573\n",
      "trainingstep =  3574\n",
      "trainingstep =  3575\n",
      "trainingstep =  3576\n",
      "trainingstep =  3577\n",
      "trainingstep =  3578\n",
      "trainingstep =  3579\n",
      "trainingstep =  3580\n",
      "trainingstep =  3581\n",
      "trainingstep =  3582\n",
      "trainingstep =  3583\n",
      "trainingstep =  3584\n",
      "trainingstep =  3585\n",
      "trainingstep =  3586\n",
      "trainingstep =  3587\n",
      "trainingstep =  3588\n",
      "trainingstep =  3589\n",
      "trainingstep =  3590\n",
      "trainingstep =  3591\n",
      "trainingstep =  3592\n",
      "trainingstep =  3593\n",
      "trainingstep =  3594\n",
      "trainingstep =  3595\n",
      "trainingstep =  3596\n",
      "trainingstep =  3597\n",
      "trainingstep =  3598\n",
      "trainingstep =  3599\n",
      "trainingstep =  3600\n",
      "Step: 3600, Train accuracy: 100.0000%, Cross entropy: 0.008550, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3601\n",
      "trainingstep =  3602\n",
      "trainingstep =  3603\n",
      "trainingstep =  3604\n",
      "trainingstep =  3605\n",
      "trainingstep =  3606\n",
      "trainingstep =  3607\n",
      "trainingstep =  3608\n",
      "trainingstep =  3609\n",
      "trainingstep =  3610\n",
      "trainingstep =  3611\n",
      "trainingstep =  3612\n",
      "trainingstep =  3613\n",
      "trainingstep =  3614\n",
      "trainingstep =  3615\n",
      "trainingstep =  3616\n",
      "trainingstep =  3617\n",
      "trainingstep =  3618\n",
      "trainingstep =  3619\n",
      "trainingstep =  3620\n",
      "trainingstep =  3621\n",
      "trainingstep =  3622\n",
      "trainingstep =  3623\n",
      "trainingstep =  3624\n",
      "trainingstep =  3625\n",
      "trainingstep =  3626\n",
      "trainingstep =  3627\n",
      "trainingstep =  3628\n",
      "trainingstep =  3629\n",
      "trainingstep =  3630\n",
      "trainingstep =  3631\n",
      "trainingstep =  3632\n",
      "trainingstep =  3633\n",
      "trainingstep =  3634\n",
      "trainingstep =  3635\n",
      "trainingstep =  3636\n",
      "trainingstep =  3637\n",
      "trainingstep =  3638\n",
      "trainingstep =  3639\n",
      "trainingstep =  3640\n",
      "trainingstep =  3641\n",
      "trainingstep =  3642\n",
      "trainingstep =  3643\n",
      "trainingstep =  3644\n",
      "trainingstep =  3645\n",
      "trainingstep =  3646\n",
      "trainingstep =  3647\n",
      "trainingstep =  3648\n",
      "trainingstep =  3649\n",
      "trainingstep =  3650\n",
      "trainingstep =  3651\n",
      "trainingstep =  3652\n",
      "trainingstep =  3653\n",
      "trainingstep =  3654\n",
      "trainingstep =  3655\n",
      "trainingstep =  3656\n",
      "trainingstep =  3657\n",
      "trainingstep =  3658\n",
      "trainingstep =  3659\n",
      "trainingstep =  3660\n",
      "trainingstep =  3661\n",
      "trainingstep =  3662\n",
      "trainingstep =  3663\n",
      "trainingstep =  3664\n",
      "trainingstep =  3665\n",
      "trainingstep =  3666\n",
      "trainingstep =  3667\n",
      "trainingstep =  3668\n",
      "trainingstep =  3669\n",
      "trainingstep =  3670\n",
      "trainingstep =  3671\n",
      "trainingstep =  3672\n",
      "trainingstep =  3673\n",
      "trainingstep =  3674\n",
      "trainingstep =  3675\n",
      "trainingstep =  3676\n",
      "trainingstep =  3677\n",
      "trainingstep =  3678\n",
      "trainingstep =  3679\n",
      "trainingstep =  3680\n",
      "trainingstep =  3681\n",
      "trainingstep =  3682\n",
      "trainingstep =  3683\n",
      "trainingstep =  3684\n",
      "trainingstep =  3685\n",
      "trainingstep =  3686\n",
      "trainingstep =  3687\n",
      "trainingstep =  3688\n",
      "trainingstep =  3689\n",
      "trainingstep =  3690\n",
      "trainingstep =  3691\n",
      "trainingstep =  3692\n",
      "trainingstep =  3693\n",
      "trainingstep =  3694\n",
      "trainingstep =  3695\n",
      "trainingstep =  3696\n",
      "trainingstep =  3697\n",
      "trainingstep =  3698\n",
      "trainingstep =  3699\n",
      "trainingstep =  3700\n",
      "Step: 3700, Train accuracy: 100.0000%, Cross entropy: 0.001551, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3701\n",
      "trainingstep =  3702\n",
      "trainingstep =  3703\n",
      "trainingstep =  3704\n",
      "trainingstep =  3705\n",
      "trainingstep =  3706\n",
      "trainingstep =  3707\n",
      "trainingstep =  3708\n",
      "trainingstep =  3709\n",
      "trainingstep =  3710\n",
      "trainingstep =  3711\n",
      "trainingstep =  3712\n",
      "trainingstep =  3713\n",
      "trainingstep =  3714\n",
      "trainingstep =  3715\n",
      "trainingstep =  3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  3717\n",
      "trainingstep =  3718\n",
      "trainingstep =  3719\n",
      "trainingstep =  3720\n",
      "trainingstep =  3721\n",
      "trainingstep =  3722\n",
      "trainingstep =  3723\n",
      "trainingstep =  3724\n",
      "trainingstep =  3725\n",
      "trainingstep =  3726\n",
      "trainingstep =  3727\n",
      "trainingstep =  3728\n",
      "trainingstep =  3729\n",
      "trainingstep =  3730\n",
      "trainingstep =  3731\n",
      "trainingstep =  3732\n",
      "trainingstep =  3733\n",
      "trainingstep =  3734\n",
      "trainingstep =  3735\n",
      "trainingstep =  3736\n",
      "trainingstep =  3737\n",
      "trainingstep =  3738\n",
      "trainingstep =  3739\n",
      "trainingstep =  3740\n",
      "trainingstep =  3741\n",
      "trainingstep =  3742\n",
      "trainingstep =  3743\n",
      "trainingstep =  3744\n",
      "trainingstep =  3745\n",
      "trainingstep =  3746\n",
      "trainingstep =  3747\n",
      "trainingstep =  3748\n",
      "trainingstep =  3749\n",
      "trainingstep =  3750\n",
      "trainingstep =  3751\n",
      "trainingstep =  3752\n",
      "trainingstep =  3753\n",
      "trainingstep =  3754\n",
      "trainingstep =  3755\n",
      "trainingstep =  3756\n",
      "trainingstep =  3757\n",
      "trainingstep =  3758\n",
      "trainingstep =  3759\n",
      "trainingstep =  3760\n",
      "trainingstep =  3761\n",
      "trainingstep =  3762\n",
      "trainingstep =  3763\n",
      "trainingstep =  3764\n",
      "trainingstep =  3765\n",
      "trainingstep =  3766\n",
      "trainingstep =  3767\n",
      "trainingstep =  3768\n",
      "trainingstep =  3769\n",
      "trainingstep =  3770\n",
      "trainingstep =  3771\n",
      "trainingstep =  3772\n",
      "trainingstep =  3773\n",
      "trainingstep =  3774\n",
      "trainingstep =  3775\n",
      "trainingstep =  3776\n",
      "trainingstep =  3777\n",
      "trainingstep =  3778\n",
      "trainingstep =  3779\n",
      "trainingstep =  3780\n",
      "trainingstep =  3781\n",
      "trainingstep =  3782\n",
      "trainingstep =  3783\n",
      "trainingstep =  3784\n",
      "trainingstep =  3785\n",
      "trainingstep =  3786\n",
      "trainingstep =  3787\n",
      "trainingstep =  3788\n",
      "trainingstep =  3789\n",
      "trainingstep =  3790\n",
      "trainingstep =  3791\n",
      "trainingstep =  3792\n",
      "trainingstep =  3793\n",
      "trainingstep =  3794\n",
      "trainingstep =  3795\n",
      "trainingstep =  3796\n",
      "trainingstep =  3797\n",
      "trainingstep =  3798\n",
      "trainingstep =  3799\n",
      "trainingstep =  3800\n",
      "Step: 3800, Train accuracy: 100.0000%, Cross entropy: 0.006079, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3801\n",
      "trainingstep =  3802\n",
      "trainingstep =  3803\n",
      "trainingstep =  3804\n",
      "trainingstep =  3805\n",
      "trainingstep =  3806\n",
      "trainingstep =  3807\n",
      "trainingstep =  3808\n",
      "trainingstep =  3809\n",
      "trainingstep =  3810\n",
      "trainingstep =  3811\n",
      "trainingstep =  3812\n",
      "trainingstep =  3813\n",
      "trainingstep =  3814\n",
      "trainingstep =  3815\n",
      "trainingstep =  3816\n",
      "trainingstep =  3817\n",
      "trainingstep =  3818\n",
      "trainingstep =  3819\n",
      "trainingstep =  3820\n",
      "trainingstep =  3821\n",
      "trainingstep =  3822\n",
      "trainingstep =  3823\n",
      "trainingstep =  3824\n",
      "trainingstep =  3825\n",
      "trainingstep =  3826\n",
      "trainingstep =  3827\n",
      "trainingstep =  3828\n",
      "trainingstep =  3829\n",
      "trainingstep =  3830\n",
      "trainingstep =  3831\n",
      "trainingstep =  3832\n",
      "trainingstep =  3833\n",
      "trainingstep =  3834\n",
      "trainingstep =  3835\n",
      "trainingstep =  3836\n",
      "trainingstep =  3837\n",
      "trainingstep =  3838\n",
      "trainingstep =  3839\n",
      "trainingstep =  3840\n",
      "trainingstep =  3841\n",
      "trainingstep =  3842\n",
      "trainingstep =  3843\n",
      "trainingstep =  3844\n",
      "trainingstep =  3845\n",
      "trainingstep =  3846\n",
      "trainingstep =  3847\n",
      "trainingstep =  3848\n",
      "trainingstep =  3849\n",
      "trainingstep =  3850\n",
      "trainingstep =  3851\n",
      "trainingstep =  3852\n",
      "trainingstep =  3853\n",
      "trainingstep =  3854\n",
      "trainingstep =  3855\n",
      "trainingstep =  3856\n",
      "trainingstep =  3857\n",
      "trainingstep =  3858\n",
      "trainingstep =  3859\n",
      "trainingstep =  3860\n",
      "trainingstep =  3861\n",
      "trainingstep =  3862\n",
      "trainingstep =  3863\n",
      "trainingstep =  3864\n",
      "trainingstep =  3865\n",
      "trainingstep =  3866\n",
      "trainingstep =  3867\n",
      "trainingstep =  3868\n",
      "trainingstep =  3869\n",
      "trainingstep =  3870\n",
      "trainingstep =  3871\n",
      "trainingstep =  3872\n",
      "trainingstep =  3873\n",
      "trainingstep =  3874\n",
      "trainingstep =  3875\n",
      "trainingstep =  3876\n",
      "trainingstep =  3877\n",
      "trainingstep =  3878\n",
      "trainingstep =  3879\n",
      "trainingstep =  3880\n",
      "trainingstep =  3881\n",
      "trainingstep =  3882\n",
      "trainingstep =  3883\n",
      "trainingstep =  3884\n",
      "trainingstep =  3885\n",
      "trainingstep =  3886\n",
      "trainingstep =  3887\n",
      "trainingstep =  3888\n",
      "trainingstep =  3889\n",
      "trainingstep =  3890\n",
      "trainingstep =  3891\n",
      "trainingstep =  3892\n",
      "trainingstep =  3893\n",
      "trainingstep =  3894\n",
      "trainingstep =  3895\n",
      "trainingstep =  3896\n",
      "trainingstep =  3897\n",
      "trainingstep =  3898\n",
      "trainingstep =  3899\n",
      "trainingstep =  3900\n",
      "Step: 3900, Train accuracy: 100.0000%, Cross entropy: 0.002611, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  3901\n",
      "trainingstep =  3902\n",
      "trainingstep =  3903\n",
      "trainingstep =  3904\n",
      "trainingstep =  3905\n",
      "trainingstep =  3906\n",
      "trainingstep =  3907\n",
      "trainingstep =  3908\n",
      "trainingstep =  3909\n",
      "trainingstep =  3910\n",
      "trainingstep =  3911\n",
      "trainingstep =  3912\n",
      "trainingstep =  3913\n",
      "trainingstep =  3914\n",
      "trainingstep =  3915\n",
      "trainingstep =  3916\n",
      "trainingstep =  3917\n",
      "trainingstep =  3918\n",
      "trainingstep =  3919\n",
      "trainingstep =  3920\n",
      "trainingstep =  3921\n",
      "trainingstep =  3922\n",
      "trainingstep =  3923\n",
      "trainingstep =  3924\n",
      "trainingstep =  3925\n",
      "trainingstep =  3926\n",
      "trainingstep =  3927\n",
      "trainingstep =  3928\n",
      "trainingstep =  3929\n",
      "trainingstep =  3930\n",
      "trainingstep =  3931\n",
      "trainingstep =  3932\n",
      "trainingstep =  3933\n",
      "trainingstep =  3934\n",
      "trainingstep =  3935\n",
      "trainingstep =  3936\n",
      "trainingstep =  3937\n",
      "trainingstep =  3938\n",
      "trainingstep =  3939\n",
      "trainingstep =  3940\n",
      "trainingstep =  3941\n",
      "trainingstep =  3942\n",
      "trainingstep =  3943\n",
      "trainingstep =  3944\n",
      "trainingstep =  3945\n",
      "trainingstep =  3946\n",
      "trainingstep =  3947\n",
      "trainingstep =  3948\n",
      "trainingstep =  3949\n",
      "trainingstep =  3950\n",
      "trainingstep =  3951\n",
      "trainingstep =  3952\n",
      "trainingstep =  3953\n",
      "trainingstep =  3954\n",
      "trainingstep =  3955\n",
      "trainingstep =  3956\n",
      "trainingstep =  3957\n",
      "trainingstep =  3958\n",
      "trainingstep =  3959\n",
      "trainingstep =  3960\n",
      "trainingstep =  3961\n",
      "trainingstep =  3962\n",
      "trainingstep =  3963\n",
      "trainingstep =  3964\n",
      "trainingstep =  3965\n",
      "trainingstep =  3966\n",
      "trainingstep =  3967\n",
      "trainingstep =  3968\n",
      "trainingstep =  3969\n",
      "trainingstep =  3970\n",
      "trainingstep =  3971\n",
      "trainingstep =  3972\n",
      "trainingstep =  3973\n",
      "trainingstep =  3974\n",
      "trainingstep =  3975\n",
      "trainingstep =  3976\n",
      "trainingstep =  3977\n",
      "trainingstep =  3978\n",
      "trainingstep =  3979\n",
      "trainingstep =  3980\n",
      "trainingstep =  3981\n",
      "trainingstep =  3982\n",
      "trainingstep =  3983\n",
      "trainingstep =  3984\n",
      "trainingstep =  3985\n",
      "trainingstep =  3986\n",
      "trainingstep =  3987\n",
      "trainingstep =  3988\n",
      "trainingstep =  3989\n",
      "trainingstep =  3990\n",
      "trainingstep =  3991\n",
      "trainingstep =  3992\n",
      "trainingstep =  3993\n",
      "trainingstep =  3994\n",
      "trainingstep =  3995\n",
      "trainingstep =  3996\n",
      "trainingstep =  3997\n",
      "trainingstep =  3998\n",
      "trainingstep =  3999\n",
      "trainingstep =  4000\n",
      "Step: 4000, Train accuracy: 100.0000%, Cross entropy: 0.002476, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4001\n",
      "trainingstep =  4002\n",
      "trainingstep =  4003\n",
      "trainingstep =  4004\n",
      "trainingstep =  4005\n",
      "trainingstep =  4006\n",
      "trainingstep =  4007\n",
      "trainingstep =  4008\n",
      "trainingstep =  4009\n",
      "trainingstep =  4010\n",
      "trainingstep =  4011\n",
      "trainingstep =  4012\n",
      "trainingstep =  4013\n",
      "trainingstep =  4014\n",
      "trainingstep =  4015\n",
      "trainingstep =  4016\n",
      "trainingstep =  4017\n",
      "trainingstep =  4018\n",
      "trainingstep =  4019\n",
      "trainingstep =  4020\n",
      "trainingstep =  4021\n",
      "trainingstep =  4022\n",
      "trainingstep =  4023\n",
      "trainingstep =  4024\n",
      "trainingstep =  4025\n",
      "trainingstep =  4026\n",
      "trainingstep =  4027\n",
      "trainingstep =  4028\n",
      "trainingstep =  4029\n",
      "trainingstep =  4030\n",
      "trainingstep =  4031\n",
      "trainingstep =  4032\n",
      "trainingstep =  4033\n",
      "trainingstep =  4034\n",
      "trainingstep =  4035\n",
      "trainingstep =  4036\n",
      "trainingstep =  4037\n",
      "trainingstep =  4038\n",
      "trainingstep =  4039\n",
      "trainingstep =  4040\n",
      "trainingstep =  4041\n",
      "trainingstep =  4042\n",
      "trainingstep =  4043\n",
      "trainingstep =  4044\n",
      "trainingstep =  4045\n",
      "trainingstep =  4046\n",
      "trainingstep =  4047\n",
      "trainingstep =  4048\n",
      "trainingstep =  4049\n",
      "trainingstep =  4050\n",
      "trainingstep =  4051\n",
      "trainingstep =  4052\n",
      "trainingstep =  4053\n",
      "trainingstep =  4054\n",
      "trainingstep =  4055\n",
      "trainingstep =  4056\n",
      "trainingstep =  4057\n",
      "trainingstep =  4058\n",
      "trainingstep =  4059\n",
      "trainingstep =  4060\n",
      "trainingstep =  4061\n",
      "trainingstep =  4062\n",
      "trainingstep =  4063\n",
      "trainingstep =  4064\n",
      "trainingstep =  4065\n",
      "trainingstep =  4066\n",
      "trainingstep =  4067\n",
      "trainingstep =  4068\n",
      "trainingstep =  4069\n",
      "trainingstep =  4070\n",
      "trainingstep =  4071\n",
      "trainingstep =  4072\n",
      "trainingstep =  4073\n",
      "trainingstep =  4074\n",
      "trainingstep =  4075\n",
      "trainingstep =  4076\n",
      "trainingstep =  4077\n",
      "trainingstep =  4078\n",
      "trainingstep =  4079\n",
      "trainingstep =  4080\n",
      "trainingstep =  4081\n",
      "trainingstep =  4082\n",
      "trainingstep =  4083\n",
      "trainingstep =  4084\n",
      "trainingstep =  4085\n",
      "trainingstep =  4086\n",
      "trainingstep =  4087\n",
      "trainingstep =  4088\n",
      "trainingstep =  4089\n",
      "trainingstep =  4090\n",
      "trainingstep =  4091\n",
      "trainingstep =  4092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  4093\n",
      "trainingstep =  4094\n",
      "trainingstep =  4095\n",
      "trainingstep =  4096\n",
      "trainingstep =  4097\n",
      "trainingstep =  4098\n",
      "trainingstep =  4099\n",
      "trainingstep =  4100\n",
      "Step: 4100, Train accuracy: 100.0000%, Cross entropy: 0.002723, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4101\n",
      "trainingstep =  4102\n",
      "trainingstep =  4103\n",
      "trainingstep =  4104\n",
      "trainingstep =  4105\n",
      "trainingstep =  4106\n",
      "trainingstep =  4107\n",
      "trainingstep =  4108\n",
      "trainingstep =  4109\n",
      "trainingstep =  4110\n",
      "trainingstep =  4111\n",
      "trainingstep =  4112\n",
      "trainingstep =  4113\n",
      "trainingstep =  4114\n",
      "trainingstep =  4115\n",
      "trainingstep =  4116\n",
      "trainingstep =  4117\n",
      "trainingstep =  4118\n",
      "trainingstep =  4119\n",
      "trainingstep =  4120\n",
      "trainingstep =  4121\n",
      "trainingstep =  4122\n",
      "trainingstep =  4123\n",
      "trainingstep =  4124\n",
      "trainingstep =  4125\n",
      "trainingstep =  4126\n",
      "trainingstep =  4127\n",
      "trainingstep =  4128\n",
      "trainingstep =  4129\n",
      "trainingstep =  4130\n",
      "trainingstep =  4131\n",
      "trainingstep =  4132\n",
      "trainingstep =  4133\n",
      "trainingstep =  4134\n",
      "trainingstep =  4135\n",
      "trainingstep =  4136\n",
      "trainingstep =  4137\n",
      "trainingstep =  4138\n",
      "trainingstep =  4139\n",
      "trainingstep =  4140\n",
      "trainingstep =  4141\n",
      "trainingstep =  4142\n",
      "trainingstep =  4143\n",
      "trainingstep =  4144\n",
      "trainingstep =  4145\n",
      "trainingstep =  4146\n",
      "trainingstep =  4147\n",
      "trainingstep =  4148\n",
      "trainingstep =  4149\n",
      "trainingstep =  4150\n",
      "trainingstep =  4151\n",
      "trainingstep =  4152\n",
      "trainingstep =  4153\n",
      "trainingstep =  4154\n",
      "trainingstep =  4155\n",
      "trainingstep =  4156\n",
      "trainingstep =  4157\n",
      "trainingstep =  4158\n",
      "trainingstep =  4159\n",
      "trainingstep =  4160\n",
      "trainingstep =  4161\n",
      "trainingstep =  4162\n",
      "trainingstep =  4163\n",
      "trainingstep =  4164\n",
      "trainingstep =  4165\n",
      "trainingstep =  4166\n",
      "trainingstep =  4167\n",
      "trainingstep =  4168\n",
      "trainingstep =  4169\n",
      "trainingstep =  4170\n",
      "trainingstep =  4171\n",
      "trainingstep =  4172\n",
      "trainingstep =  4173\n",
      "trainingstep =  4174\n",
      "trainingstep =  4175\n",
      "trainingstep =  4176\n",
      "trainingstep =  4177\n",
      "trainingstep =  4178\n",
      "trainingstep =  4179\n",
      "trainingstep =  4180\n",
      "trainingstep =  4181\n",
      "trainingstep =  4182\n",
      "trainingstep =  4183\n",
      "trainingstep =  4184\n",
      "trainingstep =  4185\n",
      "trainingstep =  4186\n",
      "trainingstep =  4187\n",
      "trainingstep =  4188\n",
      "trainingstep =  4189\n",
      "trainingstep =  4190\n",
      "trainingstep =  4191\n",
      "trainingstep =  4192\n",
      "trainingstep =  4193\n",
      "trainingstep =  4194\n",
      "trainingstep =  4195\n",
      "trainingstep =  4196\n",
      "trainingstep =  4197\n",
      "trainingstep =  4198\n",
      "trainingstep =  4199\n",
      "trainingstep =  4200\n",
      "Step: 4200, Train accuracy: 100.0000%, Cross entropy: 0.002992, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4201\n",
      "trainingstep =  4202\n",
      "trainingstep =  4203\n",
      "trainingstep =  4204\n",
      "trainingstep =  4205\n",
      "trainingstep =  4206\n",
      "trainingstep =  4207\n",
      "trainingstep =  4208\n",
      "trainingstep =  4209\n",
      "trainingstep =  4210\n",
      "trainingstep =  4211\n",
      "trainingstep =  4212\n",
      "trainingstep =  4213\n",
      "trainingstep =  4214\n",
      "trainingstep =  4215\n",
      "trainingstep =  4216\n",
      "trainingstep =  4217\n",
      "trainingstep =  4218\n",
      "trainingstep =  4219\n",
      "trainingstep =  4220\n",
      "trainingstep =  4221\n",
      "trainingstep =  4222\n",
      "trainingstep =  4223\n",
      "trainingstep =  4224\n",
      "trainingstep =  4225\n",
      "trainingstep =  4226\n",
      "trainingstep =  4227\n",
      "trainingstep =  4228\n",
      "trainingstep =  4229\n",
      "trainingstep =  4230\n",
      "trainingstep =  4231\n",
      "trainingstep =  4232\n",
      "trainingstep =  4233\n",
      "trainingstep =  4234\n",
      "trainingstep =  4235\n",
      "trainingstep =  4236\n",
      "trainingstep =  4237\n",
      "trainingstep =  4238\n",
      "trainingstep =  4239\n",
      "trainingstep =  4240\n",
      "trainingstep =  4241\n",
      "trainingstep =  4242\n",
      "trainingstep =  4243\n",
      "trainingstep =  4244\n",
      "trainingstep =  4245\n",
      "trainingstep =  4246\n",
      "trainingstep =  4247\n",
      "trainingstep =  4248\n",
      "trainingstep =  4249\n",
      "trainingstep =  4250\n",
      "trainingstep =  4251\n",
      "trainingstep =  4252\n",
      "trainingstep =  4253\n",
      "trainingstep =  4254\n",
      "trainingstep =  4255\n",
      "trainingstep =  4256\n",
      "trainingstep =  4257\n",
      "trainingstep =  4258\n",
      "trainingstep =  4259\n",
      "trainingstep =  4260\n",
      "trainingstep =  4261\n",
      "trainingstep =  4262\n",
      "trainingstep =  4263\n",
      "trainingstep =  4264\n",
      "trainingstep =  4265\n",
      "trainingstep =  4266\n",
      "trainingstep =  4267\n",
      "trainingstep =  4268\n",
      "trainingstep =  4269\n",
      "trainingstep =  4270\n",
      "trainingstep =  4271\n",
      "trainingstep =  4272\n",
      "trainingstep =  4273\n",
      "trainingstep =  4274\n",
      "trainingstep =  4275\n",
      "trainingstep =  4276\n",
      "trainingstep =  4277\n",
      "trainingstep =  4278\n",
      "trainingstep =  4279\n",
      "trainingstep =  4280\n",
      "trainingstep =  4281\n",
      "trainingstep =  4282\n",
      "trainingstep =  4283\n",
      "trainingstep =  4284\n",
      "trainingstep =  4285\n",
      "trainingstep =  4286\n",
      "trainingstep =  4287\n",
      "trainingstep =  4288\n",
      "trainingstep =  4289\n",
      "trainingstep =  4290\n",
      "trainingstep =  4291\n",
      "trainingstep =  4292\n",
      "trainingstep =  4293\n",
      "trainingstep =  4294\n",
      "trainingstep =  4295\n",
      "trainingstep =  4296\n",
      "trainingstep =  4297\n",
      "trainingstep =  4298\n",
      "trainingstep =  4299\n",
      "trainingstep =  4300\n",
      "Step: 4300, Train accuracy: 100.0000%, Cross entropy: 0.003515, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4301\n",
      "trainingstep =  4302\n",
      "trainingstep =  4303\n",
      "trainingstep =  4304\n",
      "trainingstep =  4305\n",
      "trainingstep =  4306\n",
      "trainingstep =  4307\n",
      "trainingstep =  4308\n",
      "trainingstep =  4309\n",
      "trainingstep =  4310\n",
      "trainingstep =  4311\n",
      "trainingstep =  4312\n",
      "trainingstep =  4313\n",
      "trainingstep =  4314\n",
      "trainingstep =  4315\n",
      "trainingstep =  4316\n",
      "trainingstep =  4317\n",
      "trainingstep =  4318\n",
      "trainingstep =  4319\n",
      "trainingstep =  4320\n",
      "trainingstep =  4321\n",
      "trainingstep =  4322\n",
      "trainingstep =  4323\n",
      "trainingstep =  4324\n",
      "trainingstep =  4325\n",
      "trainingstep =  4326\n",
      "trainingstep =  4327\n",
      "trainingstep =  4328\n",
      "trainingstep =  4329\n",
      "trainingstep =  4330\n",
      "trainingstep =  4331\n",
      "trainingstep =  4332\n",
      "trainingstep =  4333\n",
      "trainingstep =  4334\n",
      "trainingstep =  4335\n",
      "trainingstep =  4336\n",
      "trainingstep =  4337\n",
      "trainingstep =  4338\n",
      "trainingstep =  4339\n",
      "trainingstep =  4340\n",
      "trainingstep =  4341\n",
      "trainingstep =  4342\n",
      "trainingstep =  4343\n",
      "trainingstep =  4344\n",
      "trainingstep =  4345\n",
      "trainingstep =  4346\n",
      "trainingstep =  4347\n",
      "trainingstep =  4348\n",
      "trainingstep =  4349\n",
      "trainingstep =  4350\n",
      "trainingstep =  4351\n",
      "trainingstep =  4352\n",
      "trainingstep =  4353\n",
      "trainingstep =  4354\n",
      "trainingstep =  4355\n",
      "trainingstep =  4356\n",
      "trainingstep =  4357\n",
      "trainingstep =  4358\n",
      "trainingstep =  4359\n",
      "trainingstep =  4360\n",
      "trainingstep =  4361\n",
      "trainingstep =  4362\n",
      "trainingstep =  4363\n",
      "trainingstep =  4364\n",
      "trainingstep =  4365\n",
      "trainingstep =  4366\n",
      "trainingstep =  4367\n",
      "trainingstep =  4368\n",
      "trainingstep =  4369\n",
      "trainingstep =  4370\n",
      "trainingstep =  4371\n",
      "trainingstep =  4372\n",
      "trainingstep =  4373\n",
      "trainingstep =  4374\n",
      "trainingstep =  4375\n",
      "trainingstep =  4376\n",
      "trainingstep =  4377\n",
      "trainingstep =  4378\n",
      "trainingstep =  4379\n",
      "trainingstep =  4380\n",
      "trainingstep =  4381\n",
      "trainingstep =  4382\n",
      "trainingstep =  4383\n",
      "trainingstep =  4384\n",
      "trainingstep =  4385\n",
      "trainingstep =  4386\n",
      "trainingstep =  4387\n",
      "trainingstep =  4388\n",
      "trainingstep =  4389\n",
      "trainingstep =  4390\n",
      "trainingstep =  4391\n",
      "trainingstep =  4392\n",
      "trainingstep =  4393\n",
      "trainingstep =  4394\n",
      "trainingstep =  4395\n",
      "trainingstep =  4396\n",
      "trainingstep =  4397\n",
      "trainingstep =  4398\n",
      "trainingstep =  4399\n",
      "trainingstep =  4400\n",
      "Step: 4400, Train accuracy: 100.0000%, Cross entropy: 0.006169, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4401\n",
      "trainingstep =  4402\n",
      "trainingstep =  4403\n",
      "trainingstep =  4404\n",
      "trainingstep =  4405\n",
      "trainingstep =  4406\n",
      "trainingstep =  4407\n",
      "trainingstep =  4408\n",
      "trainingstep =  4409\n",
      "trainingstep =  4410\n",
      "trainingstep =  4411\n",
      "trainingstep =  4412\n",
      "trainingstep =  4413\n",
      "trainingstep =  4414\n",
      "trainingstep =  4415\n",
      "trainingstep =  4416\n",
      "trainingstep =  4417\n",
      "trainingstep =  4418\n",
      "trainingstep =  4419\n",
      "trainingstep =  4420\n",
      "trainingstep =  4421\n",
      "trainingstep =  4422\n",
      "trainingstep =  4423\n",
      "trainingstep =  4424\n",
      "trainingstep =  4425\n",
      "trainingstep =  4426\n",
      "trainingstep =  4427\n",
      "trainingstep =  4428\n",
      "trainingstep =  4429\n",
      "trainingstep =  4430\n",
      "trainingstep =  4431\n",
      "trainingstep =  4432\n",
      "trainingstep =  4433\n",
      "trainingstep =  4434\n",
      "trainingstep =  4435\n",
      "trainingstep =  4436\n",
      "trainingstep =  4437\n",
      "trainingstep =  4438\n",
      "trainingstep =  4439\n",
      "trainingstep =  4440\n",
      "trainingstep =  4441\n",
      "trainingstep =  4442\n",
      "trainingstep =  4443\n",
      "trainingstep =  4444\n",
      "trainingstep =  4445\n",
      "trainingstep =  4446\n",
      "trainingstep =  4447\n",
      "trainingstep =  4448\n",
      "trainingstep =  4449\n",
      "trainingstep =  4450\n",
      "trainingstep =  4451\n",
      "trainingstep =  4452\n",
      "trainingstep =  4453\n",
      "trainingstep =  4454\n",
      "trainingstep =  4455\n",
      "trainingstep =  4456\n",
      "trainingstep =  4457\n",
      "trainingstep =  4458\n",
      "trainingstep =  4459\n",
      "trainingstep =  4460\n",
      "trainingstep =  4461\n",
      "trainingstep =  4462\n",
      "trainingstep =  4463\n",
      "trainingstep =  4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  4465\n",
      "trainingstep =  4466\n",
      "trainingstep =  4467\n",
      "trainingstep =  4468\n",
      "trainingstep =  4469\n",
      "trainingstep =  4470\n",
      "trainingstep =  4471\n",
      "trainingstep =  4472\n",
      "trainingstep =  4473\n",
      "trainingstep =  4474\n",
      "trainingstep =  4475\n",
      "trainingstep =  4476\n",
      "trainingstep =  4477\n",
      "trainingstep =  4478\n",
      "trainingstep =  4479\n",
      "trainingstep =  4480\n",
      "trainingstep =  4481\n",
      "trainingstep =  4482\n",
      "trainingstep =  4483\n",
      "trainingstep =  4484\n",
      "trainingstep =  4485\n",
      "trainingstep =  4486\n",
      "trainingstep =  4487\n",
      "trainingstep =  4488\n",
      "trainingstep =  4489\n",
      "trainingstep =  4490\n",
      "trainingstep =  4491\n",
      "trainingstep =  4492\n",
      "trainingstep =  4493\n",
      "trainingstep =  4494\n",
      "trainingstep =  4495\n",
      "trainingstep =  4496\n",
      "trainingstep =  4497\n",
      "trainingstep =  4498\n",
      "trainingstep =  4499\n",
      "trainingstep =  4500\n",
      "Step: 4500, Train accuracy: 100.0000%, Cross entropy: 0.000959, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4501\n",
      "trainingstep =  4502\n",
      "trainingstep =  4503\n",
      "trainingstep =  4504\n",
      "trainingstep =  4505\n",
      "trainingstep =  4506\n",
      "trainingstep =  4507\n",
      "trainingstep =  4508\n",
      "trainingstep =  4509\n",
      "trainingstep =  4510\n",
      "trainingstep =  4511\n",
      "trainingstep =  4512\n",
      "trainingstep =  4513\n",
      "trainingstep =  4514\n",
      "trainingstep =  4515\n",
      "trainingstep =  4516\n",
      "trainingstep =  4517\n",
      "trainingstep =  4518\n",
      "trainingstep =  4519\n",
      "trainingstep =  4520\n",
      "trainingstep =  4521\n",
      "trainingstep =  4522\n",
      "trainingstep =  4523\n",
      "trainingstep =  4524\n",
      "trainingstep =  4525\n",
      "trainingstep =  4526\n",
      "trainingstep =  4527\n",
      "trainingstep =  4528\n",
      "trainingstep =  4529\n",
      "trainingstep =  4530\n",
      "trainingstep =  4531\n",
      "trainingstep =  4532\n",
      "trainingstep =  4533\n",
      "trainingstep =  4534\n",
      "trainingstep =  4535\n",
      "trainingstep =  4536\n",
      "trainingstep =  4537\n",
      "trainingstep =  4538\n",
      "trainingstep =  4539\n",
      "trainingstep =  4540\n",
      "trainingstep =  4541\n",
      "trainingstep =  4542\n",
      "trainingstep =  4543\n",
      "trainingstep =  4544\n",
      "trainingstep =  4545\n",
      "trainingstep =  4546\n",
      "trainingstep =  4547\n",
      "trainingstep =  4548\n",
      "trainingstep =  4549\n",
      "trainingstep =  4550\n",
      "trainingstep =  4551\n",
      "trainingstep =  4552\n",
      "trainingstep =  4553\n",
      "trainingstep =  4554\n",
      "trainingstep =  4555\n",
      "trainingstep =  4556\n",
      "trainingstep =  4557\n",
      "trainingstep =  4558\n",
      "trainingstep =  4559\n",
      "trainingstep =  4560\n",
      "trainingstep =  4561\n",
      "trainingstep =  4562\n",
      "trainingstep =  4563\n",
      "trainingstep =  4564\n",
      "trainingstep =  4565\n",
      "trainingstep =  4566\n",
      "trainingstep =  4567\n",
      "trainingstep =  4568\n",
      "trainingstep =  4569\n",
      "trainingstep =  4570\n",
      "trainingstep =  4571\n",
      "trainingstep =  4572\n",
      "trainingstep =  4573\n",
      "trainingstep =  4574\n",
      "trainingstep =  4575\n",
      "trainingstep =  4576\n",
      "trainingstep =  4577\n",
      "trainingstep =  4578\n",
      "trainingstep =  4579\n",
      "trainingstep =  4580\n",
      "trainingstep =  4581\n",
      "trainingstep =  4582\n",
      "trainingstep =  4583\n",
      "trainingstep =  4584\n",
      "trainingstep =  4585\n",
      "trainingstep =  4586\n",
      "trainingstep =  4587\n",
      "trainingstep =  4588\n",
      "trainingstep =  4589\n",
      "trainingstep =  4590\n",
      "trainingstep =  4591\n",
      "trainingstep =  4592\n",
      "trainingstep =  4593\n",
      "trainingstep =  4594\n",
      "trainingstep =  4595\n",
      "trainingstep =  4596\n",
      "trainingstep =  4597\n",
      "trainingstep =  4598\n",
      "trainingstep =  4599\n",
      "trainingstep =  4600\n",
      "Step: 4600, Train accuracy: 100.0000%, Cross entropy: 0.003237, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4601\n",
      "trainingstep =  4602\n",
      "trainingstep =  4603\n",
      "trainingstep =  4604\n",
      "trainingstep =  4605\n",
      "trainingstep =  4606\n",
      "trainingstep =  4607\n",
      "trainingstep =  4608\n",
      "trainingstep =  4609\n",
      "trainingstep =  4610\n",
      "trainingstep =  4611\n",
      "trainingstep =  4612\n",
      "trainingstep =  4613\n",
      "trainingstep =  4614\n",
      "trainingstep =  4615\n",
      "trainingstep =  4616\n",
      "trainingstep =  4617\n",
      "trainingstep =  4618\n",
      "trainingstep =  4619\n",
      "trainingstep =  4620\n",
      "trainingstep =  4621\n",
      "trainingstep =  4622\n",
      "trainingstep =  4623\n",
      "trainingstep =  4624\n",
      "trainingstep =  4625\n",
      "trainingstep =  4626\n",
      "trainingstep =  4627\n",
      "trainingstep =  4628\n",
      "trainingstep =  4629\n",
      "trainingstep =  4630\n",
      "trainingstep =  4631\n",
      "trainingstep =  4632\n",
      "trainingstep =  4633\n",
      "trainingstep =  4634\n",
      "trainingstep =  4635\n",
      "trainingstep =  4636\n",
      "trainingstep =  4637\n",
      "trainingstep =  4638\n",
      "trainingstep =  4639\n",
      "trainingstep =  4640\n",
      "trainingstep =  4641\n",
      "trainingstep =  4642\n",
      "trainingstep =  4643\n",
      "trainingstep =  4644\n",
      "trainingstep =  4645\n",
      "trainingstep =  4646\n",
      "trainingstep =  4647\n",
      "trainingstep =  4648\n",
      "trainingstep =  4649\n",
      "trainingstep =  4650\n",
      "trainingstep =  4651\n",
      "trainingstep =  4652\n",
      "trainingstep =  4653\n",
      "trainingstep =  4654\n",
      "trainingstep =  4655\n",
      "trainingstep =  4656\n",
      "trainingstep =  4657\n",
      "trainingstep =  4658\n",
      "trainingstep =  4659\n",
      "trainingstep =  4660\n",
      "trainingstep =  4661\n",
      "trainingstep =  4662\n",
      "trainingstep =  4663\n",
      "trainingstep =  4664\n",
      "trainingstep =  4665\n",
      "trainingstep =  4666\n",
      "trainingstep =  4667\n",
      "trainingstep =  4668\n",
      "trainingstep =  4669\n",
      "trainingstep =  4670\n",
      "trainingstep =  4671\n",
      "trainingstep =  4672\n",
      "trainingstep =  4673\n",
      "trainingstep =  4674\n",
      "trainingstep =  4675\n",
      "trainingstep =  4676\n",
      "trainingstep =  4677\n",
      "trainingstep =  4678\n",
      "trainingstep =  4679\n",
      "trainingstep =  4680\n",
      "trainingstep =  4681\n",
      "trainingstep =  4682\n",
      "trainingstep =  4683\n",
      "trainingstep =  4684\n",
      "trainingstep =  4685\n",
      "trainingstep =  4686\n",
      "trainingstep =  4687\n",
      "trainingstep =  4688\n",
      "trainingstep =  4689\n",
      "trainingstep =  4690\n",
      "trainingstep =  4691\n",
      "trainingstep =  4692\n",
      "trainingstep =  4693\n",
      "trainingstep =  4694\n",
      "trainingstep =  4695\n",
      "trainingstep =  4696\n",
      "trainingstep =  4697\n",
      "trainingstep =  4698\n",
      "trainingstep =  4699\n",
      "trainingstep =  4700\n",
      "Step: 4700, Train accuracy: 100.0000%, Cross entropy: 0.006713, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4701\n",
      "trainingstep =  4702\n",
      "trainingstep =  4703\n",
      "trainingstep =  4704\n",
      "trainingstep =  4705\n",
      "trainingstep =  4706\n",
      "trainingstep =  4707\n",
      "trainingstep =  4708\n",
      "trainingstep =  4709\n",
      "trainingstep =  4710\n",
      "trainingstep =  4711\n",
      "trainingstep =  4712\n",
      "trainingstep =  4713\n",
      "trainingstep =  4714\n",
      "trainingstep =  4715\n",
      "trainingstep =  4716\n",
      "trainingstep =  4717\n",
      "trainingstep =  4718\n",
      "trainingstep =  4719\n",
      "trainingstep =  4720\n",
      "trainingstep =  4721\n",
      "trainingstep =  4722\n",
      "trainingstep =  4723\n",
      "trainingstep =  4724\n",
      "trainingstep =  4725\n",
      "trainingstep =  4726\n",
      "trainingstep =  4727\n",
      "trainingstep =  4728\n",
      "trainingstep =  4729\n",
      "trainingstep =  4730\n",
      "trainingstep =  4731\n",
      "trainingstep =  4732\n",
      "trainingstep =  4733\n",
      "trainingstep =  4734\n",
      "trainingstep =  4735\n",
      "trainingstep =  4736\n",
      "trainingstep =  4737\n",
      "trainingstep =  4738\n",
      "trainingstep =  4739\n",
      "trainingstep =  4740\n",
      "trainingstep =  4741\n",
      "trainingstep =  4742\n",
      "trainingstep =  4743\n",
      "trainingstep =  4744\n",
      "trainingstep =  4745\n",
      "trainingstep =  4746\n",
      "trainingstep =  4747\n",
      "trainingstep =  4748\n",
      "trainingstep =  4749\n",
      "trainingstep =  4750\n",
      "trainingstep =  4751\n",
      "trainingstep =  4752\n",
      "trainingstep =  4753\n",
      "trainingstep =  4754\n",
      "trainingstep =  4755\n",
      "trainingstep =  4756\n",
      "trainingstep =  4757\n",
      "trainingstep =  4758\n",
      "trainingstep =  4759\n",
      "trainingstep =  4760\n",
      "trainingstep =  4761\n",
      "trainingstep =  4762\n",
      "trainingstep =  4763\n",
      "trainingstep =  4764\n",
      "trainingstep =  4765\n",
      "trainingstep =  4766\n",
      "trainingstep =  4767\n",
      "trainingstep =  4768\n",
      "trainingstep =  4769\n",
      "trainingstep =  4770\n",
      "trainingstep =  4771\n",
      "trainingstep =  4772\n",
      "trainingstep =  4773\n",
      "trainingstep =  4774\n",
      "trainingstep =  4775\n",
      "trainingstep =  4776\n",
      "trainingstep =  4777\n",
      "trainingstep =  4778\n",
      "trainingstep =  4779\n",
      "trainingstep =  4780\n",
      "trainingstep =  4781\n",
      "trainingstep =  4782\n",
      "trainingstep =  4783\n",
      "trainingstep =  4784\n",
      "trainingstep =  4785\n",
      "trainingstep =  4786\n",
      "trainingstep =  4787\n",
      "trainingstep =  4788\n",
      "trainingstep =  4789\n",
      "trainingstep =  4790\n",
      "trainingstep =  4791\n",
      "trainingstep =  4792\n",
      "trainingstep =  4793\n",
      "trainingstep =  4794\n",
      "trainingstep =  4795\n",
      "trainingstep =  4796\n",
      "trainingstep =  4797\n",
      "trainingstep =  4798\n",
      "trainingstep =  4799\n",
      "trainingstep =  4800\n",
      "Step: 4800, Train accuracy: 100.0000%, Cross entropy: 0.002314, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4801\n",
      "trainingstep =  4802\n",
      "trainingstep =  4803\n",
      "trainingstep =  4804\n",
      "trainingstep =  4805\n",
      "trainingstep =  4806\n",
      "trainingstep =  4807\n",
      "trainingstep =  4808\n",
      "trainingstep =  4809\n",
      "trainingstep =  4810\n",
      "trainingstep =  4811\n",
      "trainingstep =  4812\n",
      "trainingstep =  4813\n",
      "trainingstep =  4814\n",
      "trainingstep =  4815\n",
      "trainingstep =  4816\n",
      "trainingstep =  4817\n",
      "trainingstep =  4818\n",
      "trainingstep =  4819\n",
      "trainingstep =  4820\n",
      "trainingstep =  4821\n",
      "trainingstep =  4822\n",
      "trainingstep =  4823\n",
      "trainingstep =  4824\n",
      "trainingstep =  4825\n",
      "trainingstep =  4826\n",
      "trainingstep =  4827\n",
      "trainingstep =  4828\n",
      "trainingstep =  4829\n",
      "trainingstep =  4830\n",
      "trainingstep =  4831\n",
      "trainingstep =  4832\n",
      "trainingstep =  4833\n",
      "trainingstep =  4834\n",
      "trainingstep =  4835\n",
      "trainingstep =  4836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingstep =  4837\n",
      "trainingstep =  4838\n",
      "trainingstep =  4839\n",
      "trainingstep =  4840\n",
      "trainingstep =  4841\n",
      "trainingstep =  4842\n",
      "trainingstep =  4843\n",
      "trainingstep =  4844\n",
      "trainingstep =  4845\n",
      "trainingstep =  4846\n",
      "trainingstep =  4847\n",
      "trainingstep =  4848\n",
      "trainingstep =  4849\n",
      "trainingstep =  4850\n",
      "trainingstep =  4851\n",
      "trainingstep =  4852\n",
      "trainingstep =  4853\n",
      "trainingstep =  4854\n",
      "trainingstep =  4855\n",
      "trainingstep =  4856\n",
      "trainingstep =  4857\n",
      "trainingstep =  4858\n",
      "trainingstep =  4859\n",
      "trainingstep =  4860\n",
      "trainingstep =  4861\n",
      "trainingstep =  4862\n",
      "trainingstep =  4863\n",
      "trainingstep =  4864\n",
      "trainingstep =  4865\n",
      "trainingstep =  4866\n",
      "trainingstep =  4867\n",
      "trainingstep =  4868\n",
      "trainingstep =  4869\n",
      "trainingstep =  4870\n",
      "trainingstep =  4871\n",
      "trainingstep =  4872\n",
      "trainingstep =  4873\n",
      "trainingstep =  4874\n",
      "trainingstep =  4875\n",
      "trainingstep =  4876\n",
      "trainingstep =  4877\n",
      "trainingstep =  4878\n",
      "trainingstep =  4879\n",
      "trainingstep =  4880\n",
      "trainingstep =  4881\n",
      "trainingstep =  4882\n",
      "trainingstep =  4883\n",
      "trainingstep =  4884\n",
      "trainingstep =  4885\n",
      "trainingstep =  4886\n",
      "trainingstep =  4887\n",
      "trainingstep =  4888\n",
      "trainingstep =  4889\n",
      "trainingstep =  4890\n",
      "trainingstep =  4891\n",
      "trainingstep =  4892\n",
      "trainingstep =  4893\n",
      "trainingstep =  4894\n",
      "trainingstep =  4895\n",
      "trainingstep =  4896\n",
      "trainingstep =  4897\n",
      "trainingstep =  4898\n",
      "trainingstep =  4899\n",
      "trainingstep =  4900\n",
      "Step: 4900, Train accuracy: 100.0000%, Cross entropy: 0.003363, Validation accuracy: 100.0% (N=100)\n",
      "trainingstep =  4901\n",
      "trainingstep =  4902\n",
      "trainingstep =  4903\n",
      "trainingstep =  4904\n",
      "trainingstep =  4905\n",
      "trainingstep =  4906\n",
      "trainingstep =  4907\n",
      "trainingstep =  4908\n",
      "trainingstep =  4909\n",
      "trainingstep =  4910\n",
      "trainingstep =  4911\n",
      "trainingstep =  4912\n",
      "trainingstep =  4913\n",
      "trainingstep =  4914\n",
      "trainingstep =  4915\n",
      "trainingstep =  4916\n",
      "trainingstep =  4917\n",
      "trainingstep =  4918\n",
      "trainingstep =  4919\n",
      "trainingstep =  4920\n",
      "trainingstep =  4921\n",
      "trainingstep =  4922\n",
      "trainingstep =  4923\n",
      "trainingstep =  4924\n",
      "trainingstep =  4925\n",
      "trainingstep =  4926\n",
      "trainingstep =  4927\n",
      "trainingstep =  4928\n",
      "trainingstep =  4929\n",
      "trainingstep =  4930\n",
      "trainingstep =  4931\n",
      "trainingstep =  4932\n",
      "trainingstep =  4933\n",
      "trainingstep =  4934\n",
      "trainingstep =  4935\n",
      "trainingstep =  4936\n",
      "trainingstep =  4937\n",
      "trainingstep =  4938\n",
      "trainingstep =  4939\n",
      "trainingstep =  4940\n",
      "trainingstep =  4941\n",
      "trainingstep =  4942\n",
      "trainingstep =  4943\n",
      "trainingstep =  4944\n",
      "trainingstep =  4945\n",
      "trainingstep =  4946\n",
      "trainingstep =  4947\n",
      "trainingstep =  4948\n",
      "trainingstep =  4949\n",
      "trainingstep =  4950\n",
      "trainingstep =  4951\n",
      "trainingstep =  4952\n",
      "trainingstep =  4953\n",
      "trainingstep =  4954\n",
      "trainingstep =  4955\n",
      "trainingstep =  4956\n",
      "trainingstep =  4957\n",
      "trainingstep =  4958\n",
      "trainingstep =  4959\n",
      "trainingstep =  4960\n",
      "trainingstep =  4961\n",
      "trainingstep =  4962\n",
      "trainingstep =  4963\n",
      "trainingstep =  4964\n",
      "trainingstep =  4965\n",
      "trainingstep =  4966\n",
      "trainingstep =  4967\n",
      "trainingstep =  4968\n",
      "trainingstep =  4969\n",
      "trainingstep =  4970\n",
      "trainingstep =  4971\n",
      "trainingstep =  4972\n",
      "trainingstep =  4973\n",
      "trainingstep =  4974\n",
      "trainingstep =  4975\n",
      "trainingstep =  4976\n",
      "trainingstep =  4977\n",
      "trainingstep =  4978\n",
      "trainingstep =  4979\n",
      "trainingstep =  4980\n",
      "trainingstep =  4981\n",
      "trainingstep =  4982\n",
      "trainingstep =  4983\n",
      "trainingstep =  4984\n",
      "trainingstep =  4985\n",
      "trainingstep =  4986\n",
      "trainingstep =  4987\n",
      "trainingstep =  4988\n",
      "trainingstep =  4989\n",
      "trainingstep =  4990\n",
      "trainingstep =  4991\n",
      "trainingstep =  4992\n",
      "trainingstep =  4993\n",
      "trainingstep =  4994\n",
      "trainingstep =  4995\n",
      "trainingstep =  4996\n",
      "trainingstep =  4997\n",
      "trainingstep =  4998\n",
      "trainingstep =  4999\n",
      "Step: 4999, Train accuracy: 100.0000%, Cross entropy: 0.001860, Validation accuracy: 100.0% (N=100)\n",
      "Final test accuracy = 100.0% (N=302)\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--image_dir',\n",
    "        type=str,\n",
    "        default=default_image_dir,\n",
    "        help='Path to folders of labeled images.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--output_graph',\n",
    "        type=str,\n",
    "        default='logs/output_graph.pb',\n",
    "        help='Where to save the trained graph.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--output_labels',\n",
    "        type=str,\n",
    "        default='logs/output_labels.txt',\n",
    "        help='Where to save the trained graph\\'s labels.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--summaries_dir',\n",
    "        type=str,\n",
    "        default='logs/retrain_logs',\n",
    "        help='Where to save summary logs for TensorBoard.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--how_many_training_steps',\n",
    "        type=int,\n",
    "        default=5000,\n",
    "        help='How many training steps to run before ending.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        type=float,\n",
    "        default=0.01,\n",
    "        help='How large a learning rate to use when training.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--testing_percentage',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='What percentage of images to use as a test set.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--validation_percentage',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='What percentage of images to use as a validation set.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--eval_step_interval',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help='How often to evaluate the training results.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--train_batch_size',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help='How many images to train on at a time.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--test_batch_size',\n",
    "        type=int,\n",
    "        default=-1,\n",
    "        help=\"\"\"\\\n",
    "        How many images to test on. This test set is only used once, to evaluate\n",
    "        the final accuracy of the model after training completes.\n",
    "        A value of -1 causes the entire test set to be used, which leads to more\n",
    "        stable results across runs.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--validation_batch_size',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help=\"\"\"\\\n",
    "        How many images to use in an evaluation batch. This validation set is\n",
    "        used much more often than the test set, and is an early indicator of how\n",
    "        accurate the model is during training.\n",
    "        A value of -1 causes the entire validation set to be used, which leads to\n",
    "        more stable results across training iterations, but may be slower on large\n",
    "        training sets.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--print_misclassified_test_images',\n",
    "        default=False,\n",
    "        help=\"\"\"\\\n",
    "        Whether to print out a list of all misclassified test images.\\\n",
    "        \"\"\",\n",
    "        action='store_true'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--model_dir',\n",
    "        type=str,\n",
    "        default='logs/imagenet',\n",
    "        help=\"\"\"\\\n",
    "        Path to classify_image_graph_def.pb,\n",
    "        imagenet_synset_to_human_label_map.txt, and\n",
    "        imagenet_2012_challenge_label_map_proto.pbtxt.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--bottleneck_dir',\n",
    "        type=str,\n",
    "        default='/tmp/bottleneck',\n",
    "        help='Path to cache bottleneck layer values as files.'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--final_tensor_name',\n",
    "        type=str,\n",
    "        default='final_result',\n",
    "        help=\"\"\"\\\n",
    "        The name of the output classification layer in the retrained graph.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--flip_left_right',\n",
    "        default=False,\n",
    "        help=\"\"\"\\\n",
    "        Whether to randomly flip half of the training images horizontally.\\\n",
    "        \"\"\",\n",
    "        action='store_true'\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--random_crop',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"\"\"\\\n",
    "        A percentage determining how much of a margin to randomly crop off the\n",
    "        training images.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--random_scale',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"\"\"\\\n",
    "        A percentage determining how much to randomly scale up the size of the\n",
    "        training images by.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        '--random_brightness',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"\"\"\\\n",
    "        A percentage determining how much to randomly multiply the training image\n",
    "        input pixels up or down by.\\\n",
    "        \"\"\"\n",
    "        )\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
    "\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))\n",
    "\n",
    "# model trainen voor 26 tekens en ongeveer 1400 foto's per teken kost ongeveer 3 uur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the error message that occurs in window above seems to be due to the simple fact that iPython cannot handle the exit statement\n",
    "# probably this error can simply be ignored\n",
    "# for a bit more info on the error, look at the traceback with the magic command %tb:\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disable tensorflow compilation warnings\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "#import tensorflow as tf\n",
    "\n",
    "#image_path = 'C:/GitHub/HandSign_Recognition/00 Data/TEST/label_C _24_9323.png' #sys.argv[1]\n",
    "image_path = 'C:/GitHub/HandSign_Recognition/00 Data/TEST/label_D _0_285.png'\n",
    "print(image_path)\n",
    "\n",
    "# Read the image_data\n",
    "image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "\n",
    "# Loads label file, strips off carriage return\n",
    "label_lines = [line.rstrip() for line\n",
    "                   in tf.gfile.GFile(\"logs/output_labels.txt\")]\n",
    "\n",
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(\"logs/output_graph.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Feed the image_data as input to the graph and get first prediction\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "    predictions = sess.run(softmax_tensor, \\\n",
    "             {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "    # Sort to show labels of first prediction in order of confidence\n",
    "    top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "\n",
    "    for node_id in top_k:\n",
    "        human_string = label_lines[node_id]\n",
    "        score = predictions[0][node_id]\n",
    "        print('%s (score = %.5f)' % (human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
