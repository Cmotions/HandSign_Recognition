{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start: loading the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure matplotlib shows images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import xgboost as xgb\n",
    "\n",
    "# Keras packages\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Input,Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\GitHub\\HandSign_Recognition\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "os.chdir(current_directory)\n",
    "\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some functions we'll use later in the script\n",
    "* read images \n",
    "* resize images\n",
    "\n",
    "ATTENTION: all images should have the same aspect ratio and the same orientation (either all landscape OR all portrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that reads images from a location and uses the image names as labels\n",
    "def read_images(imgloc = ''):\n",
    "    # read all images from file into a numpy array\n",
    "    # cv2 assumes colors are BGR, so we also convert this to RGB\n",
    "    images = np.array([cv2.cvtColor(cv2.imread(imgloc + name), cv2.COLOR_BGR2RGB) \n",
    "                       for name in os.listdir(imgloc)], dtype = np.object)\n",
    "\n",
    "    # use the image names to create a numpy array with the label of each image\n",
    "    labels  = np.array([str(name.rpartition(' ')[0].rpartition('_')[2]) for name in os.listdir(imgloc)])\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train_test(imgloc_train, imgloc_test = '', h5 = False\n",
    "                    , name_train_x = '', name_train_y = '', name_test_x = '', name_test_y = ''):\n",
    "\n",
    "    # check if the images are already split into train and test\n",
    "    # and if images are saved in a folder or in a h5 file\n",
    "    if imgloc_test == '':\n",
    "        if h5:\n",
    "            # read h5 file\n",
    "            # Read the handsign dataset\n",
    "            train_dataset = h5py.File(imgloc_train + '.h5', \"r\")\n",
    "            train_img = np.array(train_dataset[name_train_x][:]) \n",
    "            train_label = np.array(train_dataset[name_train_y][:]) \n",
    "        else: # read images from folder\n",
    "            # images are all in the same folder\n",
    "            data_img, data_label = read_images(imgloc_train)\n",
    "        \n",
    "        # create a train and a testset\n",
    "        nr_records_train = round(.7 * len(data_img))\n",
    "        in_train = np.random.randint(len(data_img) - 1, size = nr_records_train)\n",
    "        \n",
    "        train_img = data_img[in_train]\n",
    "        train_label = data_label[in_train]\n",
    "        \n",
    "        test_img = np.delete(data_img, in_train, axis = 0)\n",
    "        test_label = np.delete(data_label, in_train, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resize images\n",
    "def resize_images(img, basewidth = 64, set_grayscale = False, binarize = False, binarize_min = 135, binarize_max = 255):\n",
    "    # make sure the numpy array contains integers (otherwise we can't convert them to PIL images)\n",
    "    img = img.astype('uint8')\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # convert the numpy array image to PIL image\n",
    "    img = Image.fromarray(img)\n",
    "    #print(type(img))\n",
    "\n",
    "    # calculate the height, based on the preferred width\n",
    "    hsize = int((float(img.size[1]) * float((basewidth / float(img.size[0])))))\n",
    "    #print(hsize)\n",
    "\n",
    "    # resize the image\n",
    "    img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    #print(img.size)\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # convert image to grayscale if parameter is True\n",
    "    if set_grayscale:\n",
    "        img = img.convert(\"L\")\n",
    "           \n",
    "    # convert the image to numpy array\n",
    "    img = np.array(img)\n",
    "    #print(type(img))\n",
    "    \n",
    "    # binarize image if parameter is True\n",
    "    if binarize:\n",
    "        thr, img = cv2.threshold(img, binarize_min, binarize_max, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # if image is converted to grayscale, make sure to set the channels shape parameter\n",
    "    if set_grayscale:\n",
    "        img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read images\n",
    "Load all the images we want to use to train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# read the training data\n",
    "imgloc = current_directory + '/00 Data/TRAIN/'\n",
    "train_img, train_label = read_images(imgloc)\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# read the test data\n",
    "imgloc = current_directory + '/00 Data/TEST/'\n",
    "test_img, test_label = read_images(imgloc)\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_img.shape)\n",
    "print(train_label.shape)\n",
    "print(train_label)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_label.shape)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# Read the handsign dataset\n",
    "train_dataset = h5py.File('00 Data/train_signs.h5', \"r\")\n",
    "train_img_h5 = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_label_h5 = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_dataset = h5py.File('00 Data/test_signs.h5', \"r\")\n",
    "test_img_h5 = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_label_h5 = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "train_label_h5 = train_label_h5.astype('str')\n",
    "test_label_h5 = test_label_h5.astype('str')\n",
    "\n",
    "# change label 0-5 in A-F\n",
    "train_label_h5[train_label_h5 == '0'] = 'A'\n",
    "train_label_h5[train_label_h5 == '1'] = 'B'\n",
    "train_label_h5[train_label_h5 == '2'] = 'C'\n",
    "train_label_h5[train_label_h5 == '3'] = 'D'\n",
    "train_label_h5[train_label_h5 == '4'] = 'E'\n",
    "train_label_h5[train_label_h5 == '5'] = 'F'\n",
    "\n",
    "test_label_h5[test_label_h5 == '0'] = 'A'\n",
    "test_label_h5[test_label_h5 == '1'] = 'B'\n",
    "test_label_h5[test_label_h5 == '2'] = 'C'\n",
    "test_label_h5[test_label_h5 == '3'] = 'D'\n",
    "test_label_h5[test_label_h5 == '4'] = 'E'\n",
    "test_label_h5[test_label_h5 == '5'] = 'F'\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "del train_dataset\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(train_img_h5.shape)\n",
    "print(train_label_h5.shape)\n",
    "print(train_label_h5)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(test_img_h5.shape)\n",
    "print(test_label_h5.shape)\n",
    "print(test_label_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# read the data which is copied from GitHub\n",
    "imgloc = current_directory + '/00 Data/dataset/00_first_test/'\n",
    "img_git, label_git = read_images(imgloc)\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print(img_git.shape)\n",
    "print(label_git.shape)\n",
    "print(label_git)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECIDE WHICH DATA TO USE FOR THE MODELING\n",
    "## the default is our own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_extension = 'own'\n",
    "\n",
    "# USE IMAGES FROM KAGGLE\n",
    "#model_extension = 'h5'\n",
    "#train_img = train_img_h5\n",
    "#train_label = train_label_h5\n",
    "#test_img = test_img_h5\n",
    "#test_label = test_label_h5\n",
    "\n",
    "# USE IMAGES FROM GIT\n",
    "#model_extension = 'git'\n",
    "#train_img = train_img_git\n",
    "#train_label = train_label_git\n",
    "#test_img = test_img_git\n",
    "#test_label = test_label_git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "del train_img_h5\n",
    "del train_label_h5\n",
    "del test_img_h5\n",
    "del test_label_h5\n",
    "\n",
    "del train_img_git\n",
    "del train_label_git\n",
    "del test_img_git\n",
    "del test_label_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (train)\n",
    "\n",
    "# randomly pick 4 of the images\n",
    "samp = random.sample(range(0,len(train_img)-1),4)\n",
    "\n",
    "plt.subplots(2,2)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('train_img[' + str(samp[0]) + '] label : ' + str(train_label[samp[0]]))\n",
    "plt.imshow(train_img[samp[0]].astype('uint8'))\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('train_img[' + str(samp[1]) + '] label : ' + str(train_label[samp[1]]))\n",
    "plt.imshow(train_img[samp[1]].astype('uint8'))\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('train_img[' + str(samp[2]) + '] label : ' + str(train_label[samp[2]]))\n",
    "plt.imshow(train_img[samp[2]].astype('uint8'))\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('train_img[' + str(samp[3]) + '] label : ' + str(train_label[samp[3]]))\n",
    "plt.imshow(train_img[samp[3]].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (test)\n",
    "\n",
    "# randomly pick 2 of the images\n",
    "samp = random.sample(range(0,len(test_img)-1),2)\n",
    "\n",
    "plt.subplots(2,1)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('test_img[' + str(samp[0]) + '] label : ' + str(test_label[samp[0]]))\n",
    "plt.imshow(test_img[samp[0]].astype('uint8'))\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('test_img[' + str(samp[1]) + '] label : ' + str(test_label[samp[1]]))\n",
    "plt.imshow(test_img[samp[1]].astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize images\n",
    "It doesn't matter which size the images are at the start, we'll try to scale them down here for the sake of efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the parameter that decides if images should be converted to grayscale\n",
    "set_img_grayscale = True\n",
    "\n",
    "# set the parameter that decides if images should be binarized (black/white)\n",
    "# and set the binarize boundaries\n",
    "binarize = False\n",
    "binarize_min = 135\n",
    "binarize_max = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# resize the images\n",
    "basewidth = 64\n",
    "img_list = []\n",
    "\n",
    "# loop through all the images in the data and resize them\n",
    "for img in train_img:\n",
    "    # resize the numpy array images\n",
    "    img = resize_images(img, basewidth, set_img_grayscale, binarize, binarize_min, binarize_max)\n",
    "    # add the image to a list of numpy array images\n",
    "    img_list.append(img)\n",
    "\n",
    "#print(img_list)\n",
    "    \n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the list with images back to a numpy array\n",
    "train_img = np.array(img_list)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (train)\n",
    "\n",
    "# randomly pick 4 of the images\n",
    "samp = random.sample(range(0,len(train_img)-1),4)\n",
    "\n",
    "plt.subplots(2,2)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('train_img[' + str(samp[0]) + '] label : ' + str(train_label[samp[0]]))\n",
    "if set_img_grayscale:\n",
    "    plt.imshow(train_img[samp[0]].squeeze(), cmap = 'gray')\n",
    "else:\n",
    "    plt.imshow(train_img[samp[0]])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('train_img[' + str(samp[1]) + '] label : ' + str(train_label[samp[1]]))\n",
    "if set_img_grayscale:\n",
    "    plt.imshow(train_img[samp[1]].squeeze(), cmap = 'gray')\n",
    "else:\n",
    "    plt.imshow(train_img[samp[1]])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('train_img[' + str(samp[2]) + '] label : ' + str(train_label[samp[2]]))\n",
    "if set_img_grayscale:\n",
    "    plt.imshow(train_img[samp[2]].squeeze(), cmap = 'gray')\n",
    "else:\n",
    "    plt.imshow(train_img[samp[2]])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('train_img[' + str(samp[3]) + '] label : ' + str(train_label[samp[3]]))\n",
    "if set_img_grayscale:\n",
    "    plt.imshow(train_img[samp[3]].squeeze(), cmap = 'gray')\n",
    "else:\n",
    "    plt.imshow(train_img[samp[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# resize the images\n",
    "basewidth = 64\n",
    "img_list = []\n",
    "\n",
    "# loop through all the images in the data and resize them\n",
    "for img in test_img:\n",
    "    # resize the numpy array images\n",
    "    img = resize_images(img, basewidth, set_img_grayscale)\n",
    "    # add the image to a list of numpy array images\n",
    "    img_list.append(img)\n",
    "\n",
    "#print(img_list)\n",
    "    \n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the list with images back to a numpy array\n",
    "test_img = np.array(img_list)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (test)\n",
    "\n",
    "# randomly pick 2 of the images\n",
    "samp = random.sample(range(0,len(test_img)-1),2)\n",
    "\n",
    "plt.subplots(2,1)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('test_img[' + str(samp[0]) + '] label : ' + str(test_label[samp[0]]))\n",
    "if set_img_grayscale:\n",
    "    plt.imshow(test_img[samp[0]].squeeze(), cmap = 'gray')\n",
    "else:\n",
    "    plt.imshow(test_img[samp[0]])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('test_img[' + str(samp[1]) + '] label : ' + str(test_label[samp[1]]))\n",
    "if set_img_grayscale:\n",
    "    plt.imshow(test_img[samp[1]].squeeze(), cmap = 'gray')\n",
    "else:\n",
    "    plt.imshow(test_img[samp[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "\n",
    "#print(train_img[1])\n",
    "train_img = train_img / 255\n",
    "#print(train_img[1])\n",
    "\n",
    "#print(test_img[1])\n",
    "test_img = test_img / 255\n",
    "#print(test_img[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label matrix: one hot encoding\n",
    "The model needs a matrix where:\n",
    "* the number of records = the number of images\n",
    "* the number of columns = the number of possible values (labels) the images can represent\n",
    "\n",
    "in this matrix all values will be 0 except for the column where the label is the label that specific image represents, there the value will be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# determine the number of unique labels\n",
    "nr_possible_values = 6 #np.unique(train_label).size #40\n",
    "#print(nr_possible_values)\n",
    "\n",
    "# create a matrice with only zeros\n",
    "# the number of rows = the number of images\n",
    "# the number of columns = the number of possible values we want to recognize\n",
    "label_matrix_train = np.zeros([train_label.shape[0], nr_possible_values])\n",
    "label_matrix_test = np.zeros([test_label.shape[0], nr_possible_values])\n",
    "#print(label_matrix_train)\n",
    "#print(label_matrix_test)\n",
    "\n",
    "# create a dictionary for the labels\n",
    "# we're going to use this dictionary to determine which column in the matrix corresponds to which value\n",
    "#label_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9\n",
    "#              , 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19\n",
    "#              , 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'SPATIE': 26, 'PUNT': 27, 'STREEPJE': 28, '@': 29\n",
    "#              , '1': 30, '2': 31, '3': 32, '4': 33, '5': 34, '6': 35, '7': 36, '8': 37, '9': 38, '0': 39}\n",
    "\n",
    "#label_dict = {'0':0, '1':1, '2':2, '3':3, '4':4, '5':5}\n",
    "#label_dict = {'B':0, 'C':1, 'D':2}\n",
    "label_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}\n",
    "\n",
    "\n",
    "# save the dictionary to file\n",
    "pickle.dump(label_dict, open(current_directory + '/01 Models/LabelDictionary.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# set the value of 1 for each record in the column with the corresponding value\n",
    "count = 0\n",
    "for i in train_label:\n",
    "    label_matrix_train[count, label_dict[str(i)]] = 1\n",
    "    count = count + 1\n",
    "\n",
    "# set the value of 1 for each record in the column with the corresponding value\n",
    "count = 0\n",
    "for i in test_label:\n",
    "    label_matrix_test[count, label_dict[str(i)]] = 1\n",
    "    count = count + 1\n",
    "\n",
    "#print(train_label)\n",
    "#print(label_matrix_train)\n",
    "print(test_label)\n",
    "print(label_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the model\n",
    "* define variables\n",
    "* define funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure to tell keras the channels are the last dimension in the shape of the dataset\n",
    "# full color RGB image = 3 channels\n",
    "# grayscale image = 1 channel\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "def plain_layer(X,n_c):\n",
    "    X_in = X\n",
    "    X = Conv2D(n_c,kernel_size = (3,3), padding = 'same')(X_in)\n",
    "    X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def identity_block(X,F):\n",
    "    X_in = X\n",
    "    \n",
    "    F1,F2,F3 = F\n",
    "    \n",
    "    X = Conv2D(F1,kernel_size = (3,3), padding= 'same')(X_in)\n",
    "    X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #X = Conv2D(F2,kernel_size = (3,3), padding = 'same')(X)\n",
    "    #X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F3,kernel_size = (3,3), padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    \n",
    "    X_in = Conv2D(F3,kernel_size = (3,3), padding = 'same')(X_in)\n",
    "    X_in = BatchNormalization(axis = 3, momentum = .01)(X_in)\n",
    "    \n",
    "    X = Add()([X,X_in])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def Resnet(input_shape = (85,64,3), classes = 6):\n",
    "    X_in = Input(input_shape)\n",
    "    \n",
    "    X = plain_layer(X_in,32)\n",
    "    \n",
    "    F1 = [16,16,32]\n",
    "    X = identity_block(X,F1)\n",
    "    X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "    #F2 = [16,16,32]\n",
    "    #X = identity_block(X,F2)\n",
    "    #X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "    #F3 = [16,16,32]\n",
    "    #X = identity_block(X,F3)\n",
    "    #X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "    X = plain_layer(X,32)\n",
    "    X = AveragePooling2D((2,2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dense(classes,activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs = X_in, outputs = X, name = 'Resnet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a function which makes an array from a matrix\n",
    "def im_to_wide(grey):\n",
    "    y = []\n",
    "    for r in range(0,len(grey)):\n",
    "        for col in range(0,len(grey[r])):\n",
    "            y.append(grey[r][col])\n",
    "    return y\n",
    "            \n",
    "def wide_to_im(x, size):\n",
    "    if size[0] * size[1] != len(x):\n",
    "        print('Size does not match')\n",
    "        raise\n",
    "\n",
    "    x = np.array(x)\n",
    "    x.shape = size\n",
    "\n",
    "    im = Image.fromarray(x)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "\n",
    "print(\"start: define data generator\")\n",
    "# define data preparation\n",
    "datagen = image.ImageDataGenerator(rescale = None #1/255 # normalize the data\n",
    "                                   , rotation_range = 20 # degree range for random rotations\n",
    "                                   , width_shift_range = 0.2 # range for random horizontal shifts\n",
    "                                   , height_shift_range = 0.2 # range for random vertical shifts\n",
    "                                   , shear_range = 0.2 # shear angle in counter-clockwise direction as radians\n",
    "                                   , zoom_range = 0.2 # Range for random zoom\n",
    "                                   , horizontal_flip = False # flip horizontally\n",
    "                                   , vertical_flip = False # flip vertically\n",
    "                                   , fill_mode = \"nearest\"\n",
    "                                  )\n",
    "\n",
    "print(\"start: fit parameters from data\")\n",
    "# fit parameters from data\n",
    "datagen.fit(train_img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine the shape of the images\n",
    "img_shape = train_img.shape[1:4]\n",
    "\n",
    "# declare a resnet model\n",
    "model_resnet = Resnet(input_shape = img_shape, classes = nr_possible_values)\n",
    "model_resnet_datagen = Resnet(input_shape = img_shape, classes = nr_possible_values)\n",
    "\n",
    "\n",
    "# define the training parameters: nr of epochs\n",
    "nr_ep = 20\n",
    "\n",
    "# define the training parameters: batch size\n",
    "btch_sz = min(int(len(train_img) / 2), 32)\n",
    "\n",
    "# define the training parameters: steps per epoch\n",
    "stps = int(len(train_img) / btch_sz)\n",
    "\n",
    "# define the training parameters: optimizer function\n",
    "opt = 'adam'\n",
    "\n",
    "# define the training parameters: loss function\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "# set the parameters for the model\n",
    "model_resnet.compile(optimizer = opt, loss = loss, metrics = ['accuracy'])\n",
    "model_resnet_datagen.compile(optimizer = opt, loss = loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the current date and time\n",
    "start = time.time()\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "# print some of the input parameters\n",
    "print(\"the batch_size is \" + str(btch_sz) + \", the number of steps_per_epoch is \" + \n",
    "      str(stps) + \" and the number of epochs is \" + str(nr_ep) + '\\n')\n",
    "\n",
    "# train the model\n",
    "model_resnet.fit(x = train_img, y = label_matrix_train, epochs = nr_ep, batch_size = btch_sz)\n",
    "\n",
    "# print the current date and time\n",
    "print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the current date and time\n",
    "start = time.time()\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "# print some of the input parameters\n",
    "print(\"the batch_size is \" + str(btch_sz) + \", the number of steps_per_epoch is \" + \n",
    "      str(stps) + \" and the number of epochs is \" + str(nr_ep) + '\\n')\n",
    "\n",
    "# train the model with the datagenerator images\n",
    "model_resnet_datagen.fit_generator(datagen.flow(train_img, label_matrix_train, batch_size = btch_sz\n",
    "                                   # , save_to_dir='images', save_prefix='aug', save_format='png'\n",
    "                                   ), steps_per_epoch = stps, epochs = nr_ep)\n",
    "\n",
    "# print the current date and time\n",
    "print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an array from the image matrix\n",
    "train_img_arr  = np.array([im_to_wide(im) for im in train_img])\n",
    "test_img_arr = np.array([im_to_wide(im) for im in test_img])\n",
    "\n",
    "# remove the last dimension of the array, to make sure it's a 2D array\n",
    "train_img_arr = train_img_arr[:,:,0]\n",
    "test_img_arr = test_img_arr[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the current date and time\n",
    "start = time.time()\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "xb = xgb.XGBClassifier(n_estimators = 500, objective = 'multi:softprob')\n",
    "xgb_model = xb.fit(train_img_arr, train_label)\n",
    "\n",
    "print(xgb_model)\n",
    "\n",
    "# print the current date and time\n",
    "print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modprob = xgb_model.predict_proba(test_img_arr)\n",
    "#print(modprob.shape)\n",
    "#print(modprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the training data\n",
    "eval_model_resnet = model_resnet.evaluate(train_img, label_matrix_train, batch_size = btch_sz)\n",
    "eval_model_resnet_datagen = model_resnet_datagen.evaluate(train_img, label_matrix_train, batch_size = btch_sz)\n",
    "\n",
    "print(\"The accuracy of the resnet model is: \" + str(round(eval_model_resnet[1]*100, 2)) + \"%\")\n",
    "print(\"The accuracy of the resnet datagenerator model is: \" + str(round(eval_model_resnet_datagen[1]*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the training data\n",
    "#eval_my_model = my_model.evaluate(train_img, label_matrix_train, batch_size = None, steps = 100)\n",
    "\n",
    "#print(\"The accuracy of this model is: \" + str(round(eval_my_model[1]*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_prediction(pred, thresh = .4):\n",
    "    thresh = thresh\n",
    "    resulting_labels = []\n",
    "\n",
    "    for i in range(0, pred.shape[0]):\n",
    "\n",
    "        single_pred = pred[i]\n",
    "        #print('\\n the prediction matrix:')\n",
    "        #print(single_pred)\n",
    "\n",
    "        # set all elements below the threshold to zero\n",
    "        single_pred[single_pred < thresh] = 0\n",
    "        #print('\\n the cleaned prediction matrix:')\n",
    "        #print(single_pred)\n",
    "\n",
    "        # if matrix contains all zeros, no prediction can be done\n",
    "        if np.any(single_pred):\n",
    "            #print(\"\\n prediction can be done\")\n",
    "\n",
    "            # check which column contains the highest probability\n",
    "            resulting_labels.append(list(label_dict.keys())[list(label_dict.values()).index(np.argmax(single_pred))])\n",
    "\n",
    "        else:\n",
    "            #print(\"\\n no prediction possible\")\n",
    "            resulting_labels.append(\"Unknown\")\n",
    "\n",
    "        #print('\\n')\n",
    "    \n",
    "    return resulting_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_datagen_resnet = model_resnet.predict_generator(datagen.flow(test_img, label_matrix_test, batch_size = len(test_img)\n",
    "                                   # , save_to_dir='images', save_prefix='aug', save_format='png'\n",
    "                                   ))\n",
    "\n",
    "pred_datagen_resnet_datagen = model_resnet_datagen.predict_generator(datagen.flow(test_img, label_matrix_test, batch_size = len(test_img)\n",
    "                                   # , save_to_dir='images', save_prefix='aug', save_format='png'\n",
    "                                   ))\n",
    "\n",
    "#pred_resnet = model_resnet.predict(test_img, label_matrix_test)\n",
    "\n",
    "#pred_resnet_datagen = model_resnet_datagen.predict(test_img, label_matrix_test)\n",
    "\n",
    "\n",
    "#resnet_result = translate_prediction(pred_resnet)\n",
    "#resnet_datagen_result = translate_prediction(pred_resnet_datagen)\n",
    "pred_datagen_resnet_result = translate_prediction(pred_datagen_resnet)\n",
    "pred_datagen_resnet_datagen_result = translate_prediction(pred_datagen_resnet_datagen)\n",
    "\n",
    "# create a classification report\n",
    "#print(classification_report(test_label, resnet_result))\n",
    "print('\\n')\n",
    "#print(classification_report(test_label, resnet_datagen_result))\n",
    "print('\\n')\n",
    "print(classification_report(test_label, pred_datagen_resnet_result))\n",
    "print('\\n')\n",
    "print(classification_report(test_label, pred_datagen_resnet_datagen_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = .4\n",
    "resulting_labels = []\n",
    "\n",
    "for i in range(0, modprob.shape[0]):\n",
    "   \n",
    "    single_pred = modprob[i]\n",
    "    print('\\n the prediction matrix:')\n",
    "    print(single_pred)\n",
    "    \n",
    "    # set all elements below the threshold to zero\n",
    "    single_pred[single_pred < thresh] = 0\n",
    "    print('\\n the cleaned prediction matrix:')\n",
    "    print(single_pred)\n",
    "    \n",
    "    # if matrix contains all zeros, no prediction can be done\n",
    "    if np.any(single_pred):\n",
    "        print(\"\\n prediction can be done\")\n",
    "        \n",
    "        # check which column contains the highest probability\n",
    "        resulting_labels.append(list(label_dict.keys())[list(label_dict.values()).index(np.argmax(single_pred))])\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n no prediction possible\")\n",
    "        resulting_labels.append(\"Unknown\")\n",
    "    \n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "print('\\n The labels according to the prediction:')\n",
    "print(resulting_labels)\n",
    "print('\\n The labels according to the testset:')\n",
    "print(test_label)\n",
    "\n",
    "# create a classification report\n",
    "print(classification_report(test_label.astype(str), resulting_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model to disk\n",
    "This way we can use the model on other computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# location to save the model\n",
    "imgloc = current_directory + '/01 Models/'\n",
    "\n",
    "# serialize model to JSON and save it\n",
    "model_resnet_json = model_resnet.to_json()\n",
    "with open(imgloc + \"model_resnet_\" + model_extension + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_resnet_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model_resnet.save_weights(imgloc + \"model_resnet_\" + model_extension + \".h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "\n",
    "# serialize model to JSON and save it\n",
    "model_resnet_datagen_json = model_resnet_datagen.to_json()\n",
    "with open(imgloc + \"model_resnet_datagen_\" + model_extension + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_resnet_datagen_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model_resnet_datagen.save_weights(imgloc + \"model_resnet_datagen_\" + model_extension + \".h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# save xgb model\n",
    "pickle.dump(xgb_model, open(imgloc + \"xgb_model_\" + model_extension + \".pickle.dat\", \"wb\"))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://sandipanweb.wordpress.com/2018/01/20/hand-gesture-classification-using-deep-convolution-and-residual-neural-network-with-tensorflow-keras-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
