{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start: loading the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# make sure matplotlib shows images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import xgboost as xgb\n",
    "\n",
    "# Keras packages\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Input,Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\GitHub\\HandSign_Recognition\n"
     ]
    }
   ],
   "source": [
    "# get the directory where this file can be found\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# change the working directory to this directory\n",
    "os.chdir(current_directory)\n",
    "\n",
    "# print the directory\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some functions we'll use later in the script\n",
    "* read images \n",
    "* resize images\n",
    "\n",
    "ATTENTION: all images should have the same aspect ratio and the same orientation (either all landscape OR all portrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that reads images from a location and uses the image names as labels\n",
    "def read_images(imgloc = ''):\n",
    "    # read all images from file into a numpy array\n",
    "    # cv2 assumes colors are BGR, so we also convert this to RGB\n",
    "    images = np.array([cv2.cvtColor(cv2.imread(imgloc + name), cv2.COLOR_BGR2RGB) \n",
    "                       for name in os.listdir(imgloc)], dtype = np.object)\n",
    "\n",
    "    # use the image names to create a numpy array with the label of each image\n",
    "    labels  = np.array([str(name.rpartition(' ')[0].rpartition('_')[2]) for name in os.listdir(imgloc)])\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def resize_images(img, basewidth = 64, set_grayscale = False, binarize = False, binarize_min = 135, binarize_max = 255):\n",
    "    # make sure the numpy array contains integers (otherwise we can't convert them to PIL images)\n",
    "    img = img.astype('uint8')\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # convert the numpy array image to PIL image\n",
    "    img = Image.fromarray(img)\n",
    "    #print(type(img))\n",
    "\n",
    "    # calculate the height, based on the preferred width\n",
    "    hsize = int((float(img.size[1]) * float((basewidth / float(img.size[0])))))\n",
    "    #print(hsize)\n",
    "\n",
    "    # resize the image\n",
    "    img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    #print(img.size)\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # convert image to grayscale if parameter is True\n",
    "    if set_grayscale:\n",
    "        img = img.convert(\"L\")\n",
    "           \n",
    "    # convert the image to numpy array\n",
    "    img = np.array(img)\n",
    "    #print(type(img))\n",
    "    \n",
    "    # binarize image if parameter is True\n",
    "    if binarize:\n",
    "        thr, img = cv2.threshold(img, binarize_min, binarize_max, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # if image is converted to grayscale, make sure to set the channels shape parameter\n",
    "    if set_grayscale:\n",
    "        img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read images\n",
    "Load all the images we want to use to train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Fri Mar 30 15:06:33 2018 \n",
      "\n",
      "finish:  Fri Mar 30 15:06:37 2018 \n",
      "\n",
      "this took --- 3.27 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# read the training data\n",
    "imgloc = current_directory + '/00 Data/TRAIN/'\n",
    "train_img, train_label = read_images(imgloc)\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Fri Mar 30 15:06:50 2018 \n",
      "\n",
      "finish:  Fri Mar 30 15:06:50 2018 \n",
      "\n",
      "this took --- 0.22 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# read the test data\n",
    "imgloc = current_directory + '/00 Data/TEST/'\n",
    "test_img, test_label = read_images(imgloc)\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 480, 640, 3)\n",
      "(158,)\n",
      "['A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'\n",
      " 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C'\n",
      " 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C'\n",
      " 'C' 'C' 'C' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D' 'D'\n",
      " 'D' 'D' 'D' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E' 'E'\n",
      " 'E' 'E' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F'\n",
      " 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F' 'F']\n",
      "\n",
      "\n",
      "(12, 480, 640, 3)\n",
      "(12,)\n",
      "['A' 'A' 'B' 'B' 'C' 'C' 'D' 'D' 'E' 'E' 'F' 'F']\n"
     ]
    }
   ],
   "source": [
    "print(train_img.shape)\n",
    "print(train_label.shape)\n",
    "print(train_label)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_label.shape)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_extension = 'own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (train)\n",
    "\n",
    "# randomly pick 4 of the images\n",
    "samp = random.sample(range(0,len(train_img)-1),4)\n",
    "\n",
    "plt.subplots(2,2)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "for i in range(1,5):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.title('train_img[' + str(samp[i-1]) + '] label : ' + str(train_label[samp[i-1]]))\n",
    "    plt.imshow(train_img[samp[i-1]].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (test)\n",
    "\n",
    "# randomly pick 4 of the images\n",
    "samp = random.sample(range(0,len(test_img)-1),4)\n",
    "\n",
    "plt.subplots(2,2)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "for i in range(1,5):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.title('test_img[' + str(samp[i-1]) + '] label : ' + str(test_label[samp[i-1]]))\n",
    "    plt.imshow(test_img[samp[i-1]].astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize images\n",
    "It doesn't matter which size the images are at the start, we'll try to scale them down here for the sake of efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the parameter that decides if images should be converted to grayscale\n",
    "set_img_grayscale = True\n",
    "\n",
    "# set the parameter that decides if images should be binarized (black/white)\n",
    "# and set the binarize boundaries\n",
    "binarize = False\n",
    "binarize_min = 135\n",
    "binarize_max = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Fri Mar 30 15:07:02 2018 \n",
      "\n",
      "finish:  Fri Mar 30 15:07:05 2018 \n",
      "\n",
      "this took --- 3.51 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# resize the images\n",
    "basewidth = 64\n",
    "img_list = []\n",
    "\n",
    "# loop through all the images in the data and resize them\n",
    "for img in train_img:\n",
    "    # resize the numpy array images\n",
    "    img = resize_images(img, basewidth, set_img_grayscale, binarize, binarize_min, binarize_max)\n",
    "    # add the image to a list of numpy array images\n",
    "    img_list.append(img)\n",
    "\n",
    "#print(img_list)\n",
    "    \n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 48, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert the list with images back to a numpy array\n",
    "train_img = np.array(img_list)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (train)\n",
    "\n",
    "# randomly pick 4 of the images\n",
    "samp = random.sample(range(0,len(train_img)-1),4)\n",
    "\n",
    "plt.subplots(2,2)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "for i in range(1,5):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.title('train_img[' + str(samp[i-1]) + '] label : ' + str(train_label[samp[i-1]]))\n",
    "    if set_img_grayscale:\n",
    "        plt.imshow(train_img[samp[i-1]].squeeze(), cmap = 'gray')\n",
    "    else:\n",
    "        plt.imshow(train_img[samp[i-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Fri Mar 30 15:07:09 2018 \n",
      "\n",
      "finish:  Fri Mar 30 15:07:09 2018 \n",
      "\n",
      "this took --- 0.26 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# resize the images\n",
    "basewidth = 64\n",
    "img_list = []\n",
    "\n",
    "# loop through all the images in the data and resize them\n",
    "for img in test_img:\n",
    "    # resize the numpy array images\n",
    "    img = resize_images(img, basewidth, set_img_grayscale)\n",
    "    # add the image to a list of numpy array images\n",
    "    img_list.append(img)\n",
    "\n",
    "#print(img_list)\n",
    "    \n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 48, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert the list with images back to a numpy array\n",
    "test_img = np.array(img_list)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at some of the images (test)\n",
    "\n",
    "# randomly pick 4 of the images\n",
    "samp = random.sample(range(0,len(test_img)-1),4)\n",
    "\n",
    "plt.subplots(2,2)\n",
    "plt.subplots_adjust(top = 0.92, bottom = 0.08, left = 0.10, right = 0.95, hspace = 0.45, wspace = 0.45)\n",
    "\n",
    "for i in range(1,5):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.title('test_img[' + str(samp[i-1]) + '] label : ' + str(test_label[samp[i-1]]))\n",
    "    if set_img_grayscale:\n",
    "        plt.imshow(test_img[samp[i-1]].squeeze(), cmap = 'gray')\n",
    "    else:\n",
    "        plt.imshow(test_img[samp[i-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: define data generator\n",
      "start: fit parameters from data\n"
     ]
    }
   ],
   "source": [
    "print(\"start: define data generator\")\n",
    "# define data preparation\n",
    "datagen = image.ImageDataGenerator(rescale = None #1/255 # normalize the data\n",
    "                                   , rotation_range = 0 # degree range for random rotations\n",
    "                                   , width_shift_range = 0.2 # range for random horizontal shifts\n",
    "                                   , height_shift_range = 0.2 # range for random vertical shifts\n",
    "                                   , shear_range = 0 # shear angle in counter-clockwise direction as radians\n",
    "                                   , zoom_range = 0.1 # Range for random zoom\n",
    "                                   , horizontal_flip = False # flip horizontally\n",
    "                                   , vertical_flip = False # flip vertically\n",
    "                                   , fill_mode = \"nearest\"\n",
    "                                  )\n",
    "\n",
    "print(\"start: fit parameters from data\")\n",
    "# fit parameters from data\n",
    "datagen.fit(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Fri Mar 30 15:07:20 2018 \n",
      "\n",
      "the label to generate is: A\n",
      "the label to generate is: B\n",
      "the label to generate is: C\n",
      "the label to generate is: D\n",
      "the label to generate is: E\n",
      "the label to generate is: F\n",
      "\n",
      " finish:  Fri Mar 30 15:16:38 2018 \n",
      "\n",
      "this took --- 558.12 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# print the current date and time\n",
    "start = time.time()\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "# loop through each label in the data and generate more images for this label\n",
    "for label in np.unique(train_label):\n",
    "    print('the label to generate is: ' + str(label))\n",
    "    # subset all images of this label\n",
    "    gen_img = train_img[train_label == label]\n",
    "    gen_label = train_label[train_label == label]\n",
    "    \n",
    "    # create an iterator\n",
    "    data_it = datagen.flow(gen_img, gen_label, save_to_dir = 'images', batch_size = len(gen_label)\n",
    "                           , save_prefix = 'label_' + str(label) + ' ', save_format = 'png')\n",
    "    \n",
    "    for i in range(1000):\n",
    "        inputs, outputs = next(data_it)\n",
    "\n",
    "\n",
    "# print the current date and time\n",
    "print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Fri Mar 30 15:16:38 2018 \n",
      "\n",
      "finish:  Fri Mar 30 15:17:26 2018 \n",
      "\n",
      "this took --- 47.52 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# import the generated data and overwrite the previous images\n",
    "\n",
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "start = time.time()\n",
    "\n",
    "# read the data\n",
    "images, labels = read_images('images/')\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150347\n",
      "105243\n",
      "105243\n",
      "74626\n"
     ]
    }
   ],
   "source": [
    "# create a train and a testset from the images\n",
    "nr_records_train = round(.7 * len(images))\n",
    "in_train = np.random.randint(len(images) - 1, size = nr_records_train)\n",
    "\n",
    "print(len(images))\n",
    "print(nr_records_train)\n",
    "#print(in_train)\n",
    "\n",
    "train_img = images[in_train]\n",
    "train_label = labels[in_train]\n",
    "\n",
    "test_img = np.delete(images, in_train, axis = 0)\n",
    "test_label = np.delete(labels, in_train, axis = 0)\n",
    "\n",
    "print(len(train_img))\n",
    "print(len(test_img))\n",
    "\n",
    "# clean environment\n",
    "del(images)\n",
    "del(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "\n",
    "#print(train_img[1])\n",
    "train_img = train_img / 255\n",
    "#print(train_img[1])\n",
    "\n",
    "#print(test_img[1])\n",
    "test_img = test_img / 255\n",
    "#print(test_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'C', 'E', ..., 'F', 'E', 'D'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label matrix: one hot encoding\n",
    "The model needs a matrix where:\n",
    "* the number of records = the number of images\n",
    "* the number of columns = the number of possible values (labels) the images can represent\n",
    "\n",
    "in this matrix all values will be 0 except for the column where the label is the label that specific image represents, there the value will be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'A' 'A' ..., 'F' 'F' 'F']\n",
      "[[ 1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# determine the number of unique labels\n",
    "nr_possible_values = 6 #np.unique(train_label).size #40\n",
    "#print(nr_possible_values)\n",
    "\n",
    "# create a matrice with only zeros\n",
    "# the number of rows = the number of images\n",
    "# the number of columns = the number of possible values we want to recognize\n",
    "label_matrix_train = np.zeros([train_label.shape[0], nr_possible_values])\n",
    "label_matrix_test = np.zeros([test_label.shape[0], nr_possible_values])\n",
    "#print(label_matrix_train)\n",
    "#print(label_matrix_test)\n",
    "\n",
    "# create a dictionary for the labels\n",
    "# we're going to use this dictionary to determine which column in the matrix corresponds to which value\n",
    "#label_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9\n",
    "#              , 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19\n",
    "#              , 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'SPATIE': 26, 'PUNT': 27, 'STREEPJE': 28, '@': 29\n",
    "#              , '1': 30, '2': 31, '3': 32, '4': 33, '5': 34, '6': 35, '7': 36, '8': 37, '9': 38, '0': 39}\n",
    "\n",
    "#label_dict = {'0':0, '1':1, '2':2, '3':3, '4':4, '5':5}\n",
    "#label_dict = {'B':0, 'C':1, 'D':2}\n",
    "label_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}\n",
    "\n",
    "\n",
    "# save the dictionary to file\n",
    "pickle.dump(label_dict, open(current_directory + '/01 Models/LabelDictionary.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# set the value of 1 for each record in the column with the corresponding value\n",
    "count = 0\n",
    "for i in train_label:\n",
    "    label_matrix_train[count, label_dict[str(i)]] = 1\n",
    "    count = count + 1\n",
    "\n",
    "# set the value of 1 for each record in the column with the corresponding value\n",
    "count = 0\n",
    "for i in test_label:\n",
    "    label_matrix_test[count, label_dict[str(i)]] = 1\n",
    "    count = count + 1\n",
    "\n",
    "#print(train_label)\n",
    "#print(label_matrix_train)\n",
    "print(test_label)\n",
    "print(label_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a function which makes an array from a matrix\n",
    "def im_to_wide(grey):\n",
    "    y = []\n",
    "    for r in range(0,len(grey)):\n",
    "        for col in range(0,len(grey[r])):\n",
    "            y.append(grey[r][col])\n",
    "    return y\n",
    "            \n",
    "def wide_to_im(x, size):\n",
    "    if size[0] * size[1] != len(x):\n",
    "        print('Size does not match')\n",
    "        raise\n",
    "\n",
    "    x = np.array(x)\n",
    "    x.shape = size\n",
    "\n",
    "    im = Image.fromarray(x)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_prediction(pred, thresh = .4):\n",
    "    thresh = thresh\n",
    "    resulting_labels = []\n",
    "\n",
    "    for i in range(0, pred.shape[0]):\n",
    "\n",
    "        single_pred = pred[i]\n",
    "        #print('\\n the prediction matrix:')\n",
    "        #print(single_pred)\n",
    "\n",
    "        # set all elements below the threshold to zero\n",
    "        single_pred[single_pred < thresh] = 0\n",
    "        #print('\\n the cleaned prediction matrix:')\n",
    "        #print(single_pred)\n",
    "\n",
    "        # if matrix contains all zeros, no prediction can be done\n",
    "        if np.any(single_pred):\n",
    "            #print(\"\\n prediction can be done\")\n",
    "\n",
    "            # check which column contains the highest probability\n",
    "            resulting_labels.append(list(label_dict.keys())[list(label_dict.values()).index(np.argmax(single_pred))])\n",
    "\n",
    "        else:\n",
    "            #print(\"\\n no prediction possible\")\n",
    "            resulting_labels.append(\"Unknown\")\n",
    "\n",
    "        #print('\\n')\n",
    "    \n",
    "    return resulting_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ce3b1f7f3ae7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create an array from the image matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_img_arr\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim_to_wide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_img_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim_to_wide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# remove the last dimension of the array, to make sure it's a 2D array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-ce3b1f7f3ae7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create an array from the image matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_img_arr\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim_to_wide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_img_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim_to_wide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# remove the last dimension of the array, to make sure it's a 2D array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-982aabee95d8>\u001b[0m in \u001b[0;36mim_to_wide\u001b[1;34m(grey)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create an array from the image matrix\n",
    "train_img_arr  = np.array([im_to_wide(im) for im in train_img])\n",
    "test_img_arr = np.array([im_to_wide(im) for im in test_img])\n",
    "\n",
    "# remove the last dimension of the array, to make sure it's a 2D array\n",
    "train_img_arr = train_img_arr[:,:,0]\n",
    "test_img_arr = test_img_arr[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the current date and time\n",
    "start = time.time()\n",
    "print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "xb = xgb.XGBClassifier(n_estimators = 500, objective = 'multi:softprob')\n",
    "xgb_model = xb.fit(train_img_arr, train_label)\n",
    "\n",
    "print(xgb_model)\n",
    "\n",
    "# print the current date and time\n",
    "print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modprob = xgb_model.predict_proba(test_img_arr)\n",
    "#print(modprob.shape)\n",
    "#print(modprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = .4\n",
    "resulting_labels = []\n",
    "\n",
    "for i in range(0, modprob.shape[0]):\n",
    "   \n",
    "    single_pred = modprob[i]\n",
    "    #print('\\n the prediction matrix:')\n",
    "    #print(single_pred)\n",
    "    \n",
    "    # set all elements below the threshold to zero\n",
    "    single_pred[single_pred < thresh] = 0\n",
    "    #print('\\n the cleaned prediction matrix:')\n",
    "    #print(single_pred)\n",
    "    \n",
    "    # if matrix contains all zeros, no prediction can be done\n",
    "    if np.any(single_pred):\n",
    "        #print(\"\\n prediction can be done\")\n",
    "        \n",
    "        # check which column contains the highest probability\n",
    "        resulting_labels.append(list(label_dict.keys())[list(label_dict.values()).index(np.argmax(single_pred))])\n",
    "        \n",
    "    else:\n",
    "        #print(\"\\n no prediction possible\")\n",
    "        resulting_labels.append(\"Unknown\")\n",
    "    \n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "print('\\n The labels according to the prediction:')\n",
    "print(resulting_labels)\n",
    "print('\\n The labels according to the testset:')\n",
    "print(test_label)\n",
    "\n",
    "# create a classification report\n",
    "print(classification_report(test_label.astype(str), resulting_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save xgb model\n",
    "pickle.dump(xgb_model, open('01 Models/' + \"xgb_model_\" + model_extension + \".pickle.dat\", \"wb\"))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the channels of the model\n",
    "\n",
    "# make sure to tell keras the channels are the last dimension in the shape of the dataset\n",
    "# full color RGB image = 3 channels\n",
    "# grayscale image = 1 channel\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "def plain_layer(X,n_c):\n",
    "    X_in = X\n",
    "    X = Conv2D(n_c,kernel_size = (3,3), padding = 'same')(X_in)\n",
    "    X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def identity_block(X,F):\n",
    "    X_in = X\n",
    "    \n",
    "    F1,F2,F3 = F\n",
    "    \n",
    "    X = Conv2D(F1,kernel_size = (3,3), padding= 'same')(X_in)\n",
    "    X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #X = Conv2D(F2,kernel_size = (3,3), padding = 'same')(X)\n",
    "    #X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F3,kernel_size = (3,3), padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3, momentum = .01)(X)\n",
    "    \n",
    "    X_in = Conv2D(F3,kernel_size = (3,3), padding = 'same')(X_in)\n",
    "    X_in = BatchNormalization(axis = 3, momentum = .01)(X_in)\n",
    "    \n",
    "    X = Add()([X,X_in])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def Resnet(input_shape = (85,64,3), classes = 6):\n",
    "    X_in = Input(input_shape)\n",
    "    \n",
    "    X = plain_layer(X_in,32)\n",
    "    \n",
    "    F1 = [16,16,32]\n",
    "    X = identity_block(X,F1)\n",
    "    X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "    #F2 = [16,16,32]\n",
    "    #X = identity_block(X,F2)\n",
    "    #X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "    #F3 = [16,16,32]\n",
    "    #X = identity_block(X,F3)\n",
    "    #X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "    X = plain_layer(X,32)\n",
    "    X = AveragePooling2D((2,2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dense(classes,activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs = X_in, outputs = X, name = 'Resnet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine the shape of the images\n",
    "img_shape = train_img.shape[1:4]\n",
    "\n",
    "# declare a resnet model\n",
    "model_resnet = Resnet(input_shape = img_shape, classes = nr_possible_values)\n",
    "model_resnet_datagen = Resnet(input_shape = img_shape, classes = nr_possible_values)\n",
    "\n",
    "# define the training parameters: batch size\n",
    "btch_sz = min(int(len(train_img) / 2), 32)\n",
    "\n",
    "# define the training parameters: steps per epoch\n",
    "stps = int(len(train_img) / btch_sz)\n",
    "\n",
    "# define the training parameters: optimizer function\n",
    "opt = 'adam'\n",
    "\n",
    "# define the training parameters: loss function\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "# set the parameters for the model\n",
    "model_resnet.compile(optimizer = opt, loss = loss, metrics = ['accuracy'])\n",
    "model_resnet_datagen.compile(optimizer = opt, loss = loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = [20, 50, 100, 500]\n",
    "\n",
    "for nr_ep in epoch_list:\n",
    "    \n",
    "    # print the current date and time\n",
    "    start = time.time()\n",
    "    print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "    # print some of the input parameters\n",
    "    print(\"the batch_size is \" + str(btch_sz) + \", the number of steps_per_epoch is \" + \n",
    "          str(stps) + \" and the number of epochs is \" + str(nr_ep) + '\\n')\n",
    "\n",
    "    # train the model without a datagenerator\n",
    "    model_resnet.fit(x = train_img, y = label_matrix_train, epochs = nr_ep, batch_size = btch_sz)\n",
    "\n",
    "    # print the current date and time\n",
    "    print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "    print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))\n",
    "    \n",
    "    # wait\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------#\n",
    "    # print the current date and time\n",
    "    start = time.time()\n",
    "    print('start: ', str(time.ctime()), '\\n')\n",
    "\n",
    "    # print some of the input parameters\n",
    "    print(\"the batch_size is \" + str(btch_sz) + \", the number of steps_per_epoch is \" + \n",
    "          str(stps) + \" and the number of epochs is \" + str(nr_ep) + '\\n')\n",
    "\n",
    "    # train the model with the datagenerator images\n",
    "    model_resnet_datagen.fit_generator(datagen.flow(train_img, label_matrix_train, batch_size = btch_sz\n",
    "                                       # , save_to_dir='images', save_prefix='aug', save_format='png'\n",
    "                                       ), steps_per_epoch = stps, epochs = nr_ep)\n",
    "\n",
    "    # print the current date and time\n",
    "    print('\\n', 'finish: ', str(time.ctime()), '\\n')\n",
    "    print(\"this took --- %s seconds ---\" % round(time.time() - start, 2))\n",
    "    \n",
    "    # wait\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------#\n",
    "    # Evaluate both models on the training data\n",
    "    eval_model_resnet = model_resnet.evaluate(train_img, label_matrix_train, batch_size = btch_sz)\n",
    "    eval_model_resnet_datagen = model_resnet_datagen.evaluate(train_img, label_matrix_train, batch_size = btch_sz)\n",
    "\n",
    "    print(\"The accuracy of the resnet model is: \" + str(round(eval_model_resnet[1]*100, 2)) + \"%\")\n",
    "    print(\"The accuracy of the resnet datagenerator model is: \" + str(round(eval_model_resnet_datagen[1]*100, 2)) + \"%\")\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------#\n",
    "    # serialize model to JSON and save it\n",
    "    model_resnet_json = model_resnet.to_json()\n",
    "    with open('01 Models/' + \"model_resnet_\" + model_extension + \"_\" + str(nr_ep) + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_resnet_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model_resnet.save_weights('01 Models/' + \"model_resnet_\" + model_extension + \"_\" + str(nr_ep) + \".h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    # serialize model to JSON and save it\n",
    "    model_resnet_datagen_json = model_resnet_datagen.to_json()\n",
    "    with open('01 Models/' + \"model_resnet_datagen_\" + model_extension + \"_\" + str(nr_ep) + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_resnet_datagen_json)\n",
    "    \n",
    "    # serialize weights to HDF5\n",
    "    model_resnet_datagen.save_weights('01 Models/' + \"model_resnet_datagen_\" + model_extension + \"_\" + str(nr_ep) + \".h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_datagen_resnet = model_resnet.predict_generator(datagen.flow(test_img, label_matrix_test, batch_size = len(test_img)\n",
    "                                   # , save_to_dir='images', save_prefix='aug', save_format='png'\n",
    "                                   ))\n",
    "\n",
    "pred_datagen_resnet_datagen = model_resnet_datagen.predict_generator(datagen.flow(test_img, label_matrix_test, batch_size = len(test_img)\n",
    "                                   # , save_to_dir='images', save_prefix='aug', save_format='png'\n",
    "                                   ))\n",
    "\n",
    "#pred_resnet = model_resnet.predict(test_img, label_matrix_test)\n",
    "\n",
    "#pred_resnet_datagen = model_resnet_datagen.predict(test_img, label_matrix_test)\n",
    "\n",
    "\n",
    "#resnet_result = translate_prediction(pred_resnet)\n",
    "#resnet_datagen_result = translate_prediction(pred_resnet_datagen)\n",
    "pred_datagen_resnet_result = translate_prediction(pred_datagen_resnet)\n",
    "pred_datagen_resnet_datagen_result = translate_prediction(pred_datagen_resnet_datagen)\n",
    "\n",
    "# create a classification report\n",
    "#print(classification_report(test_label, resnet_result))\n",
    "print('\\n')\n",
    "#print(classification_report(test_label, resnet_datagen_result))\n",
    "print('\\n')\n",
    "print(classification_report(test_label, pred_datagen_resnet_result))\n",
    "print('\\n')\n",
    "print(classification_report(test_label, pred_datagen_resnet_datagen_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
