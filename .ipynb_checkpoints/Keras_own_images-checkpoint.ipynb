{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# make sure matplotlib shows images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Keras packages\n",
    "from keras import layers\n",
    "from keras.layers import Input,Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Tue Feb  6 12:55:37 2018\n",
      "finish:  Tue Feb  6 12:55:59 2018\n"
     ]
    }
   ],
   "source": [
    "# location of the images\n",
    "#imgloc = 'D:/Documents/GitHub/HandSign_Recognition/00 Data/Own/'\n",
    "imgloc = 'C:/Users/cmoserveradmin/Desktop/HandSign_Recognition/00 Data/Own/'\n",
    "\n",
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()))\n",
    "\n",
    "# read all images from file into a numpy array\n",
    "# cv2 assumes colors are BGR, so we also convert this to RGB\n",
    "train_img = np.array([cv2.cvtColor(cv2.imread(imgloc + name), cv2.COLOR_BGR2RGB) for name in os.listdir(imgloc)], dtype = np.object)\n",
    "\n",
    "# use the image names to create a numpy array with the label of each image\n",
    "train_label  = np.array([str(name.rpartition(' ')[0].rpartition('_')[2]) for name in os.listdir(imgloc)])\n",
    "\n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 3968, 2976, 3)\n",
      "(37,)\n",
      "['A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B']\n"
     ]
    }
   ],
   "source": [
    "print(train_img.shape)\n",
    "print(train_label.shape)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  Tue Feb  6 12:57:52 2018\n",
      "(37, 85, 64, 3)\n",
      "finish:  Tue Feb  6 12:58:32 2018\n"
     ]
    }
   ],
   "source": [
    "# print the current datetime\n",
    "print('start: ', str(time.ctime()))\n",
    "\n",
    "# resize the images\n",
    "basewidth = 64\n",
    "\n",
    "img_list = []\n",
    "\n",
    "# loop through all the images in the data\n",
    "for img in train_img:\n",
    "    \n",
    "    # make sure the numpy array contains integers (otherwise we can't convert them to PIL images)\n",
    "    img = img.astype('uint8')\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # convert the numpy array image to PIL image\n",
    "    img = Image.fromarray(img)\n",
    "    #print(type(img))\n",
    "\n",
    "    # calculate the height, based on the preferred width\n",
    "    hsize = int((float(img.size[1]) * float((basewidth / float(img.size[0])))))\n",
    "    #print(hsize)\n",
    "\n",
    "    # resize the image\n",
    "    img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    #print(img.size)\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # convert the image to numpy array\n",
    "    img = np.array(img)\n",
    "    #print(type(img))\n",
    "    \n",
    "    # add the image to a list of numpy array images\n",
    "    img_list.append(img)\n",
    "    #print('\\n')\n",
    "\n",
    "\n",
    "# convert the list of numpy array images into a numpy array again\n",
    "#print(img_list)\n",
    "train_img = np.array(img_list)\n",
    "print(train_img.shape)\n",
    "    \n",
    "# print the current datetime\n",
    "print('finish: ', str(time.ctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# determine the number of unique labels\n",
    "nr_possible_values = np.unique(train_label).size\n",
    "\n",
    "# create a matrice with only zeros\n",
    "# the number of rows = the number of images\n",
    "# the number of columns = the number of possible values we want to recognize\n",
    "label_matrix_train = np.zeros([train_label.shape[0], nr_possible_values])\n",
    "\n",
    "# create a dictionary for the labels\n",
    "# we're going to use this dictionary to determine which column in the matrix corresponds to which value\n",
    "label_dict = {'A': 0, 'B': 1}\n",
    "\n",
    "# set the value of 1 for each record in the column with the corresponding value\n",
    "count = 0\n",
    "for i in train_label:\n",
    "    label_matrix_train[count, label_dict[i]] = 1\n",
    "    count = count + 1\n",
    "    \n",
    "#print(label_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# normalize the data (set all values between [0,1])\n",
    "train_img_norm = train_img / 255\n",
    "\n",
    "#print(train_img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to tell keras the channels are the last dimension in the shape of the dataset\n",
    "# in this case the channel = 3, since we have full color images with 3 RGB channels\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "\n",
    "def plain_layer(X,n_c):\n",
    "    X_in = X\n",
    "    X = Conv2D(n_c,kernel_size = (3,3), padding = 'same')(X_in)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(X,F):\n",
    "    X_in = X\n",
    "    \n",
    "    F1,F2,F3 = F\n",
    "    \n",
    "    X = Conv2D(F1,kernel_size=(3,3),padding='same')(X_in)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F2,kernel_size=(3,3),padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F3,kernel_size=(3,3),padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    X_in = Conv2D(F3,kernel_size=(3,3),padding='same')(X_in)\n",
    "    X_in = BatchNormalization(axis=3)(X_in)\n",
    "    \n",
    "    X = Add()([X,X_in])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def Resnet(input_shape = (64,64,3), classes = 6):\n",
    "    X_in = Input(input_shape)\n",
    "    \n",
    "    X = plain_layer(X_in,32)\n",
    "    \n",
    "    F1 = [16,16,32]\n",
    "    X = identity_block(X,F1)\n",
    "    #X = MaxPooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    F2 = [16,16,32]\n",
    "    X = identity_block(X,F2)\n",
    "    #X = MaxPooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    F3 = [16,16,32]\n",
    "    X = identity_block(X,F3)\n",
    "    #X = MaxPooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    #X = plain_layer(X,32)\n",
    "    X = AveragePooling2D((2,2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dense(classes,activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=X_in,outputs=X,name='Resnet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 64, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_norm.shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the shape of the images\n",
    "img_shape = train_img_norm.shape[1:4]\n",
    "\n",
    "# declare a resnet model\n",
    "my_model = Resnet(input_shape = img_shape)\n",
    "\n",
    "# print the current date and time\n",
    "print(time.ctime())\n",
    "\n",
    "my_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "my_model.fit(x = train_img_norm, y = label_matrix_train, epochs = 20, batch_size = 32)\n",
    "\n",
    "# print the current date and time\n",
    "print(time.ctime())\n",
    "\n",
    "time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
