{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure matplotlib shows images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Keras packages\n",
    "from keras import layers\n",
    "from keras.layers import Input,Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 30 20:13:03 2018\n",
      "Tue Jan 30 20:13:36 2018\n"
     ]
    }
   ],
   "source": [
    "# location of the images\n",
    "imgloc = 'D:/Documents/GitHub/HandSign_Recognition/00 Data/Own/'\n",
    "\n",
    "# print the current datetime\n",
    "print(time.ctime())\n",
    "\n",
    "# read all images from file into a numpy array\n",
    "# cv2 assumes colors are BGR, so we also convert this to RGB\n",
    "train_img = np.array([cv2.cvtColor(cv2.imread(imgloc + name), cv2.COLOR_BGR2RGB) for name in os.listdir(imgloc)], dtype = np.object)\n",
    "\n",
    "# use the image names to create a numpy array with the label of each image\n",
    "train_label  = np.array([int(name.rpartition(' ')[0].rpartition('_')[2]) for name in os.listdir(imgloc)])\n",
    "\n",
    "# print the current datetime\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3968, 2976, 3)\n",
      "(10,)\n",
      "[1 1 1 1 1 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_img.shape)\n",
    "print(train_label.shape)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3968, 2976, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 35426304 into shape (64,64,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-61e0e5224128>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#plt.imshow(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 35426304 into shape (64,64,3)"
     ]
    }
   ],
   "source": [
    "# resize the images\n",
    "#np.reshape(train_img, (10,64,64,3))\n",
    "#print(train_img.shape)\n",
    "\n",
    "\n",
    "img = train_img[1].astype('uint8')\n",
    "Image.fromarray(img)\n",
    "print(img.shape)\n",
    "img = img.reshape(64,64,3)\n",
    "#plt.imshow(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# determine the number of unique labels\n",
    "nr_possible_values = np.unique(train_label).size\n",
    "\n",
    "# create a matrice with only zeros\n",
    "# the number of rows = the number of images\n",
    "# the number of columns = the number of possible values we want to recognize\n",
    "label_matrix_train = np.zeros([train_label.shape[0], nr_possible_values])\n",
    "\n",
    "# create a dictionary for the labels\n",
    "# we're going to use this dictionary to determine which column in the matrix corresponds to which value\n",
    "label_dict = {1: 0, 2: 1}\n",
    "\n",
    "# set the value of 1 for each record in the column with the corresponding value\n",
    "count = 0\n",
    "for i in train_label:\n",
    "    label_matrix_train[count, label_dict[i]] = 1\n",
    "    count = count + 1\n",
    "    \n",
    "#print(label_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# normalize the data (set all values between [0,1])\n",
    "train_img_norm = train_img / 255\n",
    "#print(train_img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure to tell keras the channels are the last dimension in the shape of the dataset\n",
    "# in this case the channel = 3, since we have full color images with 3 RGB channels\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "\n",
    "def plain_layer(X,n_c):\n",
    "    X_in = X\n",
    "    X = Conv2D(n_c,kernel_size = (3,3), padding = 'same')(X_in)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size = (2,2))(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(X,F):\n",
    "    X_in = X\n",
    "    \n",
    "    F1,F2,F3 = F\n",
    "    \n",
    "    X = Conv2D(F1,kernel_size=(3,3),padding='same')(X_in)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F2,kernel_size=(3,3),padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F3,kernel_size=(3,3),padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    X_in = Conv2D(F3,kernel_size=(3,3),padding='same')(X_in)\n",
    "    X_in = BatchNormalization(axis=3)(X_in)\n",
    "    \n",
    "    X = Add()([X,X_in])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def Resnet(input_shape=(64,64,3),classes=6):\n",
    "    X_in = Input(input_shape)\n",
    "    \n",
    "    X = plain_layer(X_in,32)\n",
    "    \n",
    "    F1 = [16,16,32]\n",
    "    X = identity_block(X,F1)\n",
    "    #X = MaxPooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    F2 = [16,16,32]\n",
    "    X = identity_block(X,F2)\n",
    "    #X = MaxPooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    F3 = [16,16,32]\n",
    "    X = identity_block(X,F3)\n",
    "    #X = MaxPooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    #X = plain_layer(X,32)\n",
    "    X = AveragePooling2D((2,2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512,activation='relu')(X)\n",
    "    X = Dense(128,activation='relu')(X)\n",
    "    X = Dense(classes,activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=X_in,outputs=X,name='Resnet')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# declare a resnet model\n",
    "my_model = Resnet()\n",
    "\n",
    "# print the current date and time\n",
    "print(time.ctime())\n",
    "\n",
    "my_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "my_model.fit(x = X_train, y = Y_train, epochs = 20, batch_size = 32)\n",
    "\n",
    "# print the current date and time\n",
    "print(time.ctime())\n",
    "\n",
    "time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
