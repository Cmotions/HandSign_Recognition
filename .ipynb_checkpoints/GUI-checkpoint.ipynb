{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "from PIL import Image, ImageTk\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "\n",
    "# make sure matplotlib shows images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set directory\n",
    "os.chdir(\"C:/GitHub/HandSign_Recognition\")\n",
    "#os.chdir(\"C:/Users/e.v.nistelrooij/Desktop/SSGN_2703/GUI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the location of the cascade files we will use to detect hands\n",
    "#fist_cascade_path = '00 Data/Haarcascades/fist.xml' \n",
    "#palm_cascade_path =  '00 Data/Haarcascades/palm.xml'\n",
    "#closed_frontal_palm_cascade_path =  '00 Data/Haarcascades/closed_frontal_palm.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load cascade file\n",
    "#fistCascade = cv2.CascadeClassifier(fist_cascade_path)\n",
    "#palmCascade = cv2.CascadeClassifier(palm_cascade_path)\n",
    "#closedFrontalPalmCascade = cv2.CascadeClassifier(closed_frontal_palm_cascade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('01 Models/model_resnet_datagen_git.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"01 Models/model_resnet_datagen_git.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x22b65523d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.v.nistelrooij\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:312: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# load pickle with XGB model\n",
    "#loaded_model = pickle.load(open('01 Models/xgb_model_own.pickle.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=nan, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dictionary that translates the label matrix to values\n",
    "label_dict = pickle.load(open('01 Models/LabelDictionary.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def im_to_wide(grey):\n",
    "    y = []\n",
    "    for r in range(0,len(grey)):\n",
    "        for col in range(0,len(grey[r])):\n",
    "            y.append(grey[r][col])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the threshold for the minimum probability a prediction must have\n",
    "thresh = .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function to predict which letter is shown with handsigns\n",
    "def predict_letter(model, img, target_size, xgboost = False):\n",
    "    #    model: keras model\n",
    "    #    img: PIL format image\n",
    "    #    target_size: (width, height) tuple\n",
    "    #    predict xgboost model or not\n",
    "    \n",
    "    if img.size != target_size:\n",
    "        print(\"the original size of the image is: \" + str(img.size))\n",
    "        img = img.resize(target_size)\n",
    "        print(\"the new size of the image is: \" + str(img.size))\n",
    "\n",
    "    # convert to numpy array\n",
    "    x = np.array(img)\n",
    "    # add a shape parameter which defines the number of images (which is 1)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    # convert to float\n",
    "    x = x.astype(float)\n",
    "    # normalize\n",
    "    x = x / 255\n",
    "    #print(x)\n",
    "    #print(x.shape)\n",
    "    \n",
    "    # for xgboost: turn matrix into array\n",
    "    if xgboost:\n",
    "        x  = np.array([im_to_wide(x)])\n",
    "        x = x[:,:,0]\n",
    "        \n",
    "    # set the channels when necessary\n",
    "    elif(len(x.shape) == 3): # number of channels = 1\n",
    "        x = x.reshape((x.shape[0], x.shape[1], x.shape[2], 1))\n",
    "        #print(x.shape)\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    if xgboost:\n",
    "        pred = model.predict_proba(x)\n",
    "    else:\n",
    "        pred = model.predict(x)\n",
    "    \n",
    "    #print(pred)\n",
    "    #print(pred < thresh)\n",
    "    #print(x.shape)\n",
    "    \n",
    "    # set all elements below the threshold to zero\n",
    "    pred[pred < thresh] = 0\n",
    "    #print(pred)\n",
    "    \n",
    "    # if matrix contains all zeros, no prediction can be done\n",
    "    if np.any(pred):\n",
    "        print(\"prediction can be done\")\n",
    "        # check which column contains the highest probability\n",
    "        # translate that label to the letter, using the label dictionary\n",
    "        label = list(label_dict.keys())[list(label_dict.values()).index(np.argmax(pred))]\n",
    "        \n",
    "    else:\n",
    "        print(\"no prediction possible\")\n",
    "        label = \"Unknown\"    \n",
    "    \n",
    "    # return the label of the prediction\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function for showing the webcam screen\n",
    "def show_frame():\n",
    "    _, frame = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image = img)\n",
    "    lmain.imgtk = imgtk\n",
    "    lmain.configure(image = imgtk)\n",
    "    lmain.after(10, show_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-26 13:17:01.166981\n",
      "the original size of the image is: (640, 480)\n",
      "the new size of the image is: (64, 85)\n",
      "[[  1.10011752e-05   7.90103525e-02   9.14084092e-02   8.29545259e-01\n",
      "    2.47349926e-05   3.07476654e-07]]\n",
      "[[ True  True  True False  True  True]]\n",
      "(1, 85, 64, 1)\n",
      "prediction can be done\n",
      "D\n",
      "the sentence now is: de D\n",
      "2018-03-26 13:17:14.126963\n",
      "the original size of the image is: (640, 480)\n",
      "the new size of the image is: (64, 85)\n",
      "[[  1.39611902e-05   8.50935932e-03   9.70486104e-01   2.09734030e-02\n",
      "    1.64949324e-05   7.13464715e-07]]\n",
      "[[ True  True False  True  True  True]]\n",
      "(1, 85, 64, 1)\n",
      "prediction can be done\n",
      "C\n",
      "the sentence now is: de C\n",
      "2018-03-26 13:17:20.574960\n",
      "the original size of the image is: (640, 480)\n",
      "the new size of the image is: (64, 85)\n",
      "[[  1.30622269e-04   2.51854420e-01   4.42388088e-01   3.05463701e-01\n",
      "    1.59932664e-04   3.22925894e-06]]\n",
      "[[ True  True False  True  True  True]]\n",
      "(1, 85, 64, 1)\n",
      "prediction can be done\n",
      "C\n",
      "WRONG!\n"
     ]
    }
   ],
   "source": [
    "# define the webcam screen\n",
    "width, height = 850, 640\n",
    "camera = cv2.VideoCapture(0)\n",
    "camera.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "camera.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "# create the GUI screen\n",
    "root = tk.Tk()\n",
    "#root = tk.Toplevel()\n",
    "\n",
    "# create an empty variable to save the sentence and the new letter\n",
    "the_sentence = \"de \"\n",
    "new_letter = \"\"\n",
    "\n",
    "# configure the GUI\n",
    "root.configure(bg = '#%02x%02x%02x' % (101, 116, 129))\n",
    "\n",
    "# configure the number of columns and rows in the grid\n",
    "root.columnconfigure(3, pad = 7)\n",
    "root.rowconfigure(5, pad = 7)\n",
    "\n",
    "# make column(s) and/or(s) row expandable\n",
    "root.columnconfigure(1, weight = 1)\n",
    "root.rowconfigure(1, weight = 1)\n",
    "root.rowconfigure(4, weight = 1)\n",
    "\n",
    "# make sure the GUI is in fullscreen mode\n",
    "root.state(\"zoom\")\n",
    "\n",
    "# Define the title of the GUI\n",
    "root.title(\"Gebarentaal herkenning met behulp van Artificial Intelligence\")\n",
    "\n",
    "# put a logo on the GUI\n",
    "#logo = tk.PhotoImage(file = 'Logo.png')\n",
    "#img = tk.Label(root, image = logo, bg = '#%02x%02x%02x' % (101, 116, 129))\n",
    "#img.image = logo\n",
    "#img.grid(row = 0, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "# create a placeholder for the webcam screen\n",
    "lmain = tk.Label(root)\n",
    "lmain.grid(row = 1, column = 1)\n",
    "\n",
    "# create a placeholder textbox for the complete sentence\n",
    "text = tk.Text(root\n",
    "               , bd = 0 # size of the border\n",
    "               , bg = '#%02x%02x%02x' % (218, 218, 222) # background color\n",
    "               , height = 5 # number of lines\n",
    "               , padx = 5 # left and right padding in pixels\n",
    "               , pady = 5 # top and bottom padding in pixels\n",
    "               , relief = \"solid\" # 3D appearance of widget: flat, groove, raised, ridge, solid, or sunken\n",
    "               , wrap = \"word\" # truncate line after last whole word that fits\n",
    "               , font = ('Verdana', 20, 'bold')\n",
    "               , fg = '#%02x%02x%02x' % (4, 55, 133) # textcolor (Cmotions darkblue)\n",
    "               , width = 40 # the number of characters that fit on a single line\n",
    "              )\n",
    "text.grid(row = 4, column = 1)\n",
    "\n",
    "# show the sentence\n",
    "text.insert(tk.INSERT, the_sentence)\n",
    "\n",
    "\n",
    "# create a function that calls the model and processes the outcome\n",
    "def call_model(the_sentence = the_sentence):\n",
    "    return_value, image = camera.read()\n",
    "    print(datetime.now())\n",
    "    \n",
    "    # check if the camera gives an image\n",
    "    if return_value:\n",
    "        \n",
    "        # flip the image\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "        # make sure the image is read as an RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGBA)\n",
    "        \n",
    "        # set to grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # binarize (image to black and white)\n",
    "        #thr, image = cv2.threshold(image, 135, 300, cv2.THRESH_BINARY)\n",
    "              \n",
    "        # convert opencv image to PIL\n",
    "        pil_im = Image.fromarray(image)\n",
    "        pil_im.show()\n",
    "        \n",
    "        \n",
    "        # try to define the letter from the handsign\n",
    "        new_letter = predict_letter(loaded_model, pil_im, (64,64), False)\n",
    "        print(new_letter)\n",
    "        \n",
    "        # let the user decide if the letter should be added to the sentence\n",
    "        add_letter = messagebox.askyesno(title = \"Bevestig toevoegen van letter aan zin\"\n",
    "                                         , message = \"Ik heb de nieuwe letter herkend als een:\\n\\n\" + str(new_letter)\n",
    "                                         + \"\\n\\nWil je deze toevoegen aan de zin?\")\n",
    "        \n",
    "        # check is letter should be added and act accordingly\n",
    "        if add_letter:\n",
    "            \n",
    "            # make sure the text is editable\n",
    "            #text.configure(state = 'normal')\n",
    "            \n",
    "            # update the value of the complete sentence\n",
    "            the_sentence = the_sentence + new_letter\n",
    "            print('the sentence now is: ' + the_sentence)\n",
    "            \n",
    "            # show the complete sentence that has been created so far\n",
    "            text.insert(tk.INSERT, new_letter)\n",
    "            root.update_idletasks()\n",
    "            \n",
    "            # make sure the text isn't editable\n",
    "            #text.configure(state = 'disabled')\n",
    "        else:\n",
    "            print('WRONG!')\n",
    "\n",
    "# create a button that calls the model\n",
    "startButton = tk.Button(root, text = 'Bepaal letter', command = call_model\n",
    "                        , height = 5, width = 20, bg = 'red', foreground = 'white'\n",
    "                       , relief = 'raised', justify = 'center', font = ('Verdana', 15, 'bold'))\n",
    "startButton.grid(row = 1, column = 0)\n",
    "\n",
    "# show the webcam stream\n",
    "show_frame()\n",
    "\n",
    "# start the GUI\n",
    "root.mainloop()  \n",
    "\n",
    "# turn off the camera\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn off the camera\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=nan, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
